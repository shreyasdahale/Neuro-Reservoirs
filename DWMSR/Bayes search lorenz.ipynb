{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-06-11T16:02:39.343201Z",
     "iopub.status.busy": "2025-06-11T16:02:39.342848Z",
     "iopub.status.idle": "2025-06-11T16:02:40.667764Z",
     "shell.execute_reply": "2025-06-11T16:02:40.666735Z",
     "shell.execute_reply.started": "2025-06-11T16:02:39.343175Z"
    },
    "papermill": {
     "duration": 1.654633,
     "end_time": "2025-06-02T12:10:39.772629",
     "exception": false,
     "start_time": "2025-06-02T12:10:38.117996",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.integrate import odeint\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import Ridge\n",
    "import json\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "from skopt import gp_minimize\n",
    "from skopt.space import Real\n",
    "from skopt.utils import use_named_args\n",
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T16:02:40.670143Z",
     "iopub.status.busy": "2025-06-11T16:02:40.669606Z",
     "iopub.status.idle": "2025-06-11T16:02:40.676768Z",
     "shell.execute_reply": "2025-06-11T16:02:40.675969Z",
     "shell.execute_reply.started": "2025-06-11T16:02:40.670107Z"
    },
    "papermill": {
     "duration": 0.012055,
     "end_time": "2025-06-02T12:10:39.787851",
     "exception": false,
     "start_time": "2025-06-02T12:10:39.775796",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def lorenz_deriv(state, t, sigma=10.0, rho=28.0, beta=8.0/3.0):\n",
    "    x, y, z = state\n",
    "    dxdt = sigma * (y - x)\n",
    "    dydt = x*(rho - z) - y\n",
    "    dzdt = x*y - beta*z\n",
    "    return [dxdt, dydt, dzdt]\n",
    "\n",
    "def generate_lorenz_data(\n",
    "    initial_state=[1.0, 1.0, 1.0],\n",
    "    tmax=25.0,\n",
    "    dt=0.01,\n",
    "    sigma=10.0,\n",
    "    rho=28.0,\n",
    "    beta=8.0/3.0\n",
    "):\n",
    "    num_steps = int(tmax / dt)\n",
    "    t_vals = np.linspace(0, tmax, num_steps+1)\n",
    "    sol = odeint(lorenz_deriv, initial_state, t_vals, args=(sigma, rho, beta))\n",
    "    return t_vals, sol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T16:02:40.678314Z",
     "iopub.status.busy": "2025-06-11T16:02:40.677964Z",
     "iopub.status.idle": "2025-06-11T16:02:40.699259Z",
     "shell.execute_reply": "2025-06-11T16:02:40.698402Z",
     "shell.execute_reply.started": "2025-06-11T16:02:40.678252Z"
    },
    "papermill": {
     "duration": 0.012858,
     "end_time": "2025-06-02T12:10:39.803577",
     "exception": false,
     "start_time": "2025-06-02T12:10:39.790719",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def compute_valid_prediction_time(y_true, y_pred, t_vals, threshold, lambda_max, dt):\n",
    "    \"\"\"\n",
    "    Compute the Valid Prediction Time (VPT) and compare it to Lyapunov time T_lambda = 1 / lambda_max.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true : ndarray of shape (N, dim)\n",
    "        True trajectory over time.\n",
    "    y_pred : ndarray of shape (N, dim)\n",
    "        Model's predicted trajectory over time (closed-loop).\n",
    "    t_vals : ndarray of shape (N,)\n",
    "        Time values corresponding to the trajectory steps.\n",
    "    threshold : float, optional\n",
    "        The error threshold, default is 0.4 as in your snippet.\n",
    "    lambda_max : float, optional\n",
    "        Largest Lyapunov exponent. Default=0.9 for Lorenz.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    T_VPT : float\n",
    "        Valid prediction time. The earliest time at which normalized error surpasses threshold\n",
    "        (or the last time if never surpassed).\n",
    "    T_lambda : float\n",
    "        Lyapunov time = 1 / lambda_max\n",
    "    ratio : float\n",
    "        How many Lyapunov times the model prediction remains valid, i.e. T_VPT / T_lambda.\n",
    "    \"\"\"\n",
    "    # 1) Average of y_true\n",
    "    y_mean = np.mean(y_true, axis=0)  # shape (dim,)\n",
    "    \n",
    "    # 2) Time-averaged norm^2 of (y_true - y_mean)\n",
    "    y_centered = y_true - y_mean\n",
    "    denom = np.mean(np.sum(y_centered**2, axis=1))  # scalar\n",
    "    \n",
    "    # 3) Compute the normalized error delta_gamma(t) = ||y_true - y_pred||^2 / denom\n",
    "    diff = y_true - y_pred\n",
    "    err_sq = np.sum(diff**2, axis=1)  # shape (N,)\n",
    "    delta_gamma = err_sq / denom      # shape (N,)\n",
    "    \n",
    "    # 4) Find the first time index where delta_gamma(t) exceeds threshold\n",
    "    idx_exceed = np.where(delta_gamma > threshold)[0]\n",
    "    if len(idx_exceed) == 0:\n",
    "        # never exceeds threshold => set T_VPT to the final time\n",
    "        T_VPT = t_vals[-1]\n",
    "    else:\n",
    "        T_VPT = t_vals[idx_exceed[0]]\n",
    "    \n",
    "    # 5) Compute T_lambda and ratio\n",
    "    T_lambda = 1.0 / lambda_max\n",
    "\n",
    "    # print(f\"\\n--- Valid Prediction Time (VPT) with threshold={threshold}, lambda_max={lambda_max} ---\")\n",
    "\n",
    "    T_VPT = (T_VPT - t_vals[0])  # Adjust T_VPT to be relative to the start time\n",
    "    ratio = T_VPT / T_lambda\n",
    "\n",
    "    return T_VPT, T_lambda, ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_nrmse(all_preds, test_target, horizons):\n",
    "    \"\"\"\n",
    "    Evaluate model performance over multiple prediction horizons for Teacher-forced Single-step Forecasting\n",
    "    \"\"\"\n",
    "    horizon_nrmse = {}\n",
    "    \n",
    "    for horizon in horizons:\n",
    "        preds = all_preds[:horizon]\n",
    "        targets = test_target[:horizon]\n",
    "        squared_errors = (preds - targets)**2\n",
    "        variance = np.var(targets, axis=0)\n",
    "        nrmse = np.sqrt(np.sum(squared_errors) / (horizon * variance))\n",
    "        horizon_nrmse[horizon] = nrmse\n",
    "\n",
    "    return horizon_nrmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_attractor_deviation(predictions, targets, cube_size=(0.1, 0.1, 0.1)):\n",
    "    \"\"\"\n",
    "    Compute the Attractor Deviation (ADev) metric.\n",
    "\n",
    "    Parameters:\n",
    "        predictions (numpy.ndarray): Predicted trajectories of shape (n, 3).\n",
    "        targets (numpy.ndarray): True trajectories of shape (n, 3).\n",
    "        cube_size (tuple): Dimensions of the cube (dx, dy, dz).\n",
    "\n",
    "    Returns:\n",
    "        float: The ADev metric.\n",
    "    \"\"\"\n",
    "    # Define the cube grid based on the range of the data and cube size\n",
    "    min_coords = np.min(np.vstack((predictions, targets)), axis=0)\n",
    "    max_coords = np.max(np.vstack((predictions, targets)), axis=0)\n",
    "\n",
    "    # Create a grid of cubes\n",
    "    grid_shape = ((max_coords - min_coords) / cube_size).astype(int) + 1\n",
    "\n",
    "    # Initialize the cube occupancy arrays\n",
    "    pred_cubes = np.zeros(grid_shape, dtype=int)\n",
    "    target_cubes = np.zeros(grid_shape, dtype=int)\n",
    "\n",
    "    # Map trajectories to cubes\n",
    "    pred_indices = ((predictions - min_coords) / cube_size).astype(int)\n",
    "    target_indices = ((targets - min_coords) / cube_size).astype(int)\n",
    "\n",
    "    # Mark cubes visited by predictions and targets\n",
    "    for idx in pred_indices:\n",
    "        pred_cubes[tuple(idx)] = 1\n",
    "    for idx in target_indices:\n",
    "        target_cubes[tuple(idx)] = 1\n",
    "\n",
    "    # Compute the ADev metric\n",
    "    adev = np.sum(np.abs(pred_cubes - target_cubes))\n",
    "    return adev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T16:02:44.115781Z",
     "iopub.status.busy": "2025-06-11T16:02:44.115481Z",
     "iopub.status.idle": "2025-06-11T16:02:44.140386Z",
     "shell.execute_reply": "2025-06-11T16:02:44.139452Z",
     "shell.execute_reply.started": "2025-06-11T16:02:44.115758Z"
    },
    "papermill": {
     "duration": 0.104497,
     "end_time": "2025-06-02T12:10:39.910805",
     "exception": false,
     "start_time": "2025-06-02T12:10:39.806308",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Diffusion-Wavelet Multi-Scale Reservoir (DW-MSR)\n",
    "===============================================\n",
    "\n",
    "-----------------------------------------------------------------------\n",
    "Notation recap\n",
    "-----------------------------------------------------------------------\n",
    "* Base graph         G = (V,E), |V| = n0\n",
    "* Laplacian          L = D − A\n",
    "* Diffusion kernel   P_s = exp(− 2**s · τ0 · L)      for s = 0 … S\n",
    "* State vector       x_t = [x_t^{(0)} ; … ; x_t^{(S)}] ∈ R^{N}\n",
    "                      where   N = (S+1) · n0\n",
    "* Update (per scale) see equations in the methodology.\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "from scipy.sparse.linalg import expm\n",
    "from sklearn.linear_model import Ridge\n",
    "from typing import Sequence\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------- #\n",
    "#                          Helper functions                             #\n",
    "# --------------------------------------------------------------------- #\n",
    "def _build_laplacian(adj: sparse.spmatrix) -> sparse.spmatrix:\n",
    "    \"\"\"Combinatorial Laplacian L = D − A   (sparse CSR).\"\"\"\n",
    "    deg = np.asarray(adj.sum(axis=1)).ravel()\n",
    "    D = sparse.diags(deg, format=\"csr\")\n",
    "    return D - adj\n",
    "\n",
    "\n",
    "def _default_sequence(val: float, length: int) -> list[float]:\n",
    "    \"\"\"Repeat *val* 'length' times, return as list.\"\"\"\n",
    "    return [val] * length\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------- #\n",
    "#                     Diffusion-Wavelet Reservoir ESN                   #\n",
    "# --------------------------------------------------------------------- #\n",
    "class DiffusionWaveletReservoirESN:\n",
    "    \"\"\"\n",
    "    DW-MSR Echo-State Network.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    adj                   : scipy.sparse matrix (shape [n0,n0])\n",
    "        Symmetric, unweighted or weighted adjacency of the base graph.\n",
    "    num_scales            : int,   S ≥ 0   (# coarse levels)\n",
    "    tau0                  : float, base diffusion time   (τ₀)\n",
    "    betas                 : Sequence[float] length S,   funnel strengths β_s\n",
    "    alphas                : Sequence[float] length S+1, leak per scale α_s\n",
    "    input_scale           : float, scale of random W_in entries\n",
    "    ridge_alpha           : float, ℓ₂ penalty in ridge read-out\n",
    "    detail_features       : bool,  include Δ_s = x^{(s-1)}−x^{(s)} in Φ(x)?\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    * Reservoir size  N = (S+1) * n0\n",
    "    * P_s are pre-computed once with sparse expm; they share sparsity of *adj*.\n",
    "    \"\"\"\n",
    "\n",
    "    # ------------------------------------------------------------------ #\n",
    "    def __init__(\n",
    "        self,\n",
    "        adj: sparse.spmatrix,\n",
    "        num_scales: int = 2,\n",
    "        tau0: float = 0.1,\n",
    "        betas: Sequence[float] | None = None,\n",
    "        alphas: Sequence[float] | None = None,\n",
    "        input_scale: float = 0.5,\n",
    "        ridge_alpha: float = 1e-6,\n",
    "        detail_features: bool = True,\n",
    "        seed: int = 42,\n",
    "    ):\n",
    "        # -------- basics -------------------------------------------------\n",
    "        if adj.shape[0] != adj.shape[1]:\n",
    "            raise ValueError(\"adjacency must be square\")\n",
    "        if not sparse.isspmatrix(adj):\n",
    "            adj = sparse.csr_matrix(adj)\n",
    "        self.n0 = adj.shape[0]\n",
    "        self.S = int(num_scales)\n",
    "        if self.S < 0:\n",
    "            raise ValueError(\"num_scales must be ≥ 0\")\n",
    "\n",
    "        self.N = (self.S + 1) * self.n0\n",
    "        self.tau0 = float(tau0)\n",
    "        self.input_scale = input_scale\n",
    "        self.ridge_alpha = ridge_alpha\n",
    "        self.detail_features = detail_features\n",
    "        self.seed = seed\n",
    "\n",
    "        # -------- leak & funnel parameters ------------------------------\n",
    "        self.betas = list(betas) if betas is not None else _default_sequence(0.5, self.S)\n",
    "        if len(self.betas) != self.S:\n",
    "            raise ValueError(\"betas must have length S\")\n",
    "\n",
    "        self.alphas = (\n",
    "            list(alphas)\n",
    "            if alphas is not None\n",
    "            else [0.5] + _default_sequence(1.0, self.S)  # finer quicker, coarse slow\n",
    "        )\n",
    "        if len(self.alphas) != self.S + 1:\n",
    "            raise ValueError(\"alphas must have length S+1\")\n",
    "\n",
    "        # -------- internal matrices -------------------------------------\n",
    "        self.Ps: list[sparse.spmatrix] = []\n",
    "        self.Vs: list[np.ndarray] = []  # just β_s I, store scalars\n",
    "        self._precompute_operators(adj)\n",
    "\n",
    "        self.W_in: np.ndarray | None = None      # set in fit_readout\n",
    "        self.W_out: np.ndarray | None = None\n",
    "\n",
    "        # state block list for convenience (each block length n0)\n",
    "        self.x_blocks = [np.zeros(self.n0, dtype=np.float32) for _ in range(self.S + 1)]\n",
    "\n",
    "    # ------------------------------------------------------------------ #\n",
    "    #                    Pre-computation of diffusion kernels            #\n",
    "    # ------------------------------------------------------------------ #\n",
    "    def _precompute_operators(self, adj: sparse.spmatrix):\n",
    "        \"\"\"Compute P_s and store funnel scalars β_s.\"\"\"\n",
    "        L = _build_laplacian(adj).tocsr()\n",
    "        # largest eigenvalue bound (Gershgorin): max row sum of |L|\n",
    "        lam_max = L.max(axis=1).toarray().ravel().max() + 1e-9\n",
    "        if self.tau0 * (2 ** self.S) * lam_max > 50:\n",
    "            print(\n",
    "                \"Warning: very large diffusion times may cause underflow in expm; \"\n",
    "                \"consider reducing tau0.\"\n",
    "            )\n",
    "\n",
    "        for s in range(self.S + 1):\n",
    "            tau_s = (2 ** s) * self.tau0\n",
    "            Ps = expm((-tau_s) * L)  # still sparse CSR\n",
    "            self.Ps.append(Ps)\n",
    "\n",
    "        self.Vs = self.betas  # just scalars\n",
    "\n",
    "    # ------------------------------------------------------------------ #\n",
    "    #                            Core update                             #\n",
    "    # ------------------------------------------------------------------ #\n",
    "    def _single_step(self, u_t: np.ndarray):\n",
    "        \"\"\"\n",
    "        Update all scales in causal order (fine → coarse) per eq. (1).\n",
    "        \"\"\"\n",
    "        new_blocks = []\n",
    "\n",
    "        # scale 0 (fine)\n",
    "        z0 = self.Ps[0].dot(self.x_blocks[0]) + self.W_in.dot(u_t)\n",
    "        x0_new = np.tanh(z0)\n",
    "        x0_next = (1.0 - self.alphas[0]) * self.x_blocks[0] + self.alphas[0] * x0_new\n",
    "        new_blocks.append(x0_next)\n",
    "\n",
    "        # coarser scales\n",
    "        for s in range(1, self.S + 1):\n",
    "            z = self.Ps[s].dot(self.x_blocks[s]) + self.Vs[s - 1] * new_blocks[s - 1]\n",
    "            xs_new = np.tanh(z)\n",
    "            xs_next = (1.0 - self.alphas[s]) * self.x_blocks[s] + self.alphas[s] * xs_new\n",
    "            new_blocks.append(xs_next)\n",
    "\n",
    "        # commit\n",
    "        self.x_blocks = new_blocks\n",
    "\n",
    "    def reset_state(self):\n",
    "        for blk in self.x_blocks:\n",
    "            blk.fill(0.0)\n",
    "\n",
    "    # ------------------------------------------------------------------ #\n",
    "    #                        Read-out training                            #\n",
    "    # ------------------------------------------------------------------ #\n",
    "    def fit_readout(self, inputs: np.ndarray, targets: np.ndarray, discard: int = 100):\n",
    "        \"\"\"\n",
    "        Teacher-forcing to train W_out (ridge).\n",
    "\n",
    "        inputs  shape [T, d_in]\n",
    "        targets shape [T, d_out]\n",
    "        \"\"\"\n",
    "        T, d_in = inputs.shape\n",
    "        if T <= discard + 1:\n",
    "            raise ValueError(\"Not enough data for training\")\n",
    "\n",
    "        # random W_in\n",
    "        rng = np.random.default_rng(self.seed)\n",
    "        self.W_in = (\n",
    "            rng.uniform(-1.0, 1.0, size=(self.n0, d_in)) * self.input_scale\n",
    "        ).astype(np.float32)\n",
    "\n",
    "        # roll through data\n",
    "        self.reset_state()\n",
    "        states, details = [], []\n",
    "        for t in range(T):\n",
    "            self._single_step(inputs[t])\n",
    "            if t >= discard:\n",
    "                flat_state = np.concatenate(self.x_blocks)\n",
    "                states.append(flat_state)\n",
    "\n",
    "                if self.detail_features and self.S > 0:\n",
    "                    # Δ_s = x^{(s-1)} − x^{(s)}\n",
    "                    delta_list = [\n",
    "                        self.x_blocks[s - 1] - self.x_blocks[s] for s in range(1, self.S + 1)\n",
    "                    ]\n",
    "                    details.append(np.concatenate(delta_list))\n",
    "\n",
    "        X_main = np.asarray(states, dtype=np.float32)  # [T-d, N]\n",
    "        Y = targets[discard:]\n",
    "\n",
    "        # feature map Φ\n",
    "        if self.detail_features and self.S > 0:\n",
    "            X_det = np.asarray(details, dtype=np.float32)  # same rows\n",
    "            feats = np.concatenate(\n",
    "                [X_main, X_det, np.ones((X_main.shape[0], 1), dtype=np.float32)], axis=1\n",
    "            )\n",
    "        else:\n",
    "            feats = np.concatenate(\n",
    "                [X_main, np.ones((X_main.shape[0], 1), dtype=np.float32)], axis=1\n",
    "            )\n",
    "\n",
    "        reg = Ridge(alpha=self.ridge_alpha, fit_intercept=False)\n",
    "        reg.fit(feats, Y)\n",
    "        self.W_out = reg.coef_.astype(np.float32)\n",
    "\n",
    "    # ------------------------------------------------------------------ #\n",
    "    #                       Autoregressive rollout                        #\n",
    "    # ------------------------------------------------------------------ #\n",
    "    def predict_autoregressive(\n",
    "        self, initial_input: np.ndarray, n_steps: int\n",
    "    ) -> np.ndarray:\n",
    "        if self.W_out is None:\n",
    "            raise RuntimeError(\"fit_readout() must be called first\")\n",
    "\n",
    "        d_in = initial_input.shape[0]\n",
    "        d_out = self.W_out.shape[0]\n",
    "        preds = np.empty((n_steps, d_out), dtype=np.float32)\n",
    "\n",
    "        #self.reset_state()\n",
    "        current_u = initial_input.astype(np.float32).copy()\n",
    "\n",
    "        for t in range(n_steps):\n",
    "            self._single_step(current_u)\n",
    "\n",
    "            flat_state = np.concatenate(self.x_blocks)\n",
    "            if self.detail_features and self.S > 0:\n",
    "                delta_list = [\n",
    "                    self.x_blocks[s - 1] - self.x_blocks[s] for s in range(1, self.S + 1)\n",
    "                ]\n",
    "                feat_vec = np.concatenate([flat_state, *delta_list, [1.0]])\n",
    "            else:\n",
    "                feat_vec = np.concatenate([flat_state, [1.0]])\n",
    "\n",
    "            y_t = (self.W_out @ feat_vec).astype(np.float32)\n",
    "            preds[t] = y_t\n",
    "            current_u = y_t[:d_in]\n",
    "\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n0      = 128               # number of nodes\n",
    "p_edge  = 4 / n0            # expected degree ≈ 4\n",
    "\n",
    "rng  = np.random.default_rng(123)\n",
    "rows = rng.choice(n0, size=int(p_edge * n0 * (n0 - 1) // 2))\n",
    "cols = rng.choice(n0, size=rows.size)\n",
    "mask = rows != cols         # avoid self-loops\n",
    "rows, cols = rows[mask], cols[mask]\n",
    "\n",
    "# build upper triangle, then symmetrise\n",
    "adj = sparse.csr_matrix((np.ones_like(rows), (rows, cols)), shape=(n0, n0))\n",
    "adj = adj + adj.T\n",
    "adj[adj > 0] = 1.0          # make unweighted (0/1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T19:03:06.082758Z",
     "iopub.status.busy": "2025-06-11T19:03:06.082429Z",
     "iopub.status.idle": "2025-06-11T19:03:06.094537Z",
     "shell.execute_reply": "2025-06-11T19:03:06.093563Z",
     "shell.execute_reply.started": "2025-06-11T19:03:06.082738Z"
    },
    "papermill": {
     "duration": 0.016065,
     "end_time": "2025-06-02T12:10:39.943473",
     "exception": false,
     "start_time": "2025-06-02T12:10:39.927408",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def run_bayesian_search(model_class, model_name, output_path=\"bayes_search_results.json\", n_calls=150):\n",
    "\n",
    "    # Define the search space\n",
    "    search_space = [\n",
    "        Real(0.0, 0.1, name='tau0'),\n",
    "        Real(0.0, 1.0, name='input_scale'),\n",
    "        Real(0.0, 1.0, name='alpha1'),\n",
    "        Real(0.0, 1.0, name='alpha2'),\n",
    "        Real(0.0, 1.0, name='alpha3'),\n",
    "        Real(0.0, 1.0, name='beta1'),\n",
    "        Real(0.0, 1.0, name='beta2')\n",
    "    ]\n",
    "    horizons = [200,400,600,800,1000]\n",
    "    all_results=[]\n",
    "\n",
    "    @use_named_args(search_space)\n",
    "    def objective(**params):\n",
    "        seed_scores = []\n",
    "        horizon_nrmse_all ={\n",
    "            200:[],\n",
    "            400:[],\n",
    "            600:[],\n",
    "            800:[],\n",
    "            1000:[]\n",
    "        }\n",
    "        # adev_scores=[]\n",
    "        alphas = [params.pop('alpha1'), params.pop('alpha2'), params.pop('alpha3')]\n",
    "        betas=[params.pop('beta1'),params.pop('beta2')]\n",
    "\n",
    "        for initial_state in [[1.0,1.0,1.0],[1.0,2.0,3.0],[2.0,1.5,4.0]]:\n",
    "            tmax = 250\n",
    "            dt   = 0.02\n",
    "            t_vals, rossler_traj = generate_lorenz_data(\n",
    "                initial_state=initial_state,\n",
    "                tmax=tmax,\n",
    "                dt=dt\n",
    "            )\n",
    "\n",
    "            washout = 2000\n",
    "            t_vals = t_vals[washout:]\n",
    "            rossler_traj = rossler_traj[washout:]\n",
    "\n",
    "            # normalize\n",
    "            scaler = MinMaxScaler()\n",
    "            scaler.fit(rossler_traj)\n",
    "            rossler_traj = scaler.transform(rossler_traj)\n",
    "\n",
    "            T_data = len(rossler_traj)\n",
    "            for train_frac in [0.75, 0.8]:\n",
    "                train_end = int(train_frac * (T_data - 1))\n",
    "                train_input  = rossler_traj[:train_end]\n",
    "                train_target = rossler_traj[1:train_end + 1]\n",
    "                test_input   = rossler_traj[train_end:-1]\n",
    "                test_target  = rossler_traj[train_end + 1:]\n",
    "                n_test_steps = len(test_input)\n",
    "                initial_in = test_input[0]\n",
    "\n",
    "                for seed in np.arange(1, 6):\n",
    "                    model = model_class(\n",
    "                        adj              = adj,                 # (required) sparse CSR adjacency\n",
    "                        num_scales       = 2,                   # S – number of coarse levels\n",
    "                        tau0             = params['tau0'],                # base diffusion time τ₀\n",
    "                        betas            = betas,     # funnel strengths β₁…β_S\n",
    "                        alphas           = alphas,# leak rates α₀…α_S  (len = S+1)\n",
    "                        input_scale      = params['input_scale'],                 # scaling of random W_in\n",
    "                        ridge_alpha      = 1e-8,                #  penalty in ridge read-out\n",
    "                        detail_features  = True,                # include Δ_s features?\n",
    "                        seed             = seed\n",
    "                    )\n",
    "                    model.fit_readout(train_input, train_target, discard=100)\n",
    "                    preds = model.predict_autoregressive(initial_in, n_test_steps)\n",
    "                    _, _, T_VPT_s = compute_valid_prediction_time(test_target, preds, t_vals, 0.4, 0.9, dt)\n",
    "                    seed_scores.append(T_VPT_s)\n",
    "                    horizon_nrmse = evaluate_nrmse(preds, test_target, horizons)\n",
    "                    for h in horizons:\n",
    "                        horizon_nrmse_all[h].append(horizon_nrmse[h])\n",
    "\n",
    "                    # adev = compute_attractor_deviation(preds, test_target)\n",
    "                    # adev_scores.append(adev)\n",
    "\n",
    "\n",
    "        mean_score = float(np.mean(seed_scores))\n",
    "        std_score = float(np.std(seed_scores))\n",
    "        mean_nrmse_dict = {str(h): float(np.mean(horizon_nrmse_all[h])) for h in horizons}\n",
    "        std_nrmse_dict  = {str(h): float(np.std(horizon_nrmse_all[h]))  for h in horizons}\n",
    "        # mean_adev = float(np.mean(adev_scores))\n",
    "        # std_adev = float(np.std(adev_scores))\n",
    "\n",
    "\n",
    "        trial_result = {\n",
    "            \"params\": params,\n",
    "            \"seed_scores\": seed_scores,\n",
    "            \"mean_T_VPT\": mean_score,\n",
    "            \"std_dev\": std_score,\n",
    "            \"mean_NRMSEs\": mean_nrmse_dict,\n",
    "            \"std_NRMSEs\": std_nrmse_dict,\n",
    "            # \"mean_ADev\": mean_adev,\n",
    "            # \"std_ADev\": std_adev,\n",
    "\n",
    "        }\n",
    "        all_results.append(trial_result)\n",
    "\n",
    "        return -mean_score  # We negate because gp_minimize minimizes the function\n",
    "\n",
    "    res = gp_minimize(objective, search_space, n_calls=n_calls, verbose=True)\n",
    "\n",
    "    # Save all results\n",
    "    with open(output_path, \"w\") as f:\n",
    "        json.dump(all_results, f, indent=2)\n",
    "    print(f\"\\nAll results saved to {output_path}\")\n",
    "\n",
    "    return all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T19:03:06.387446Z",
     "iopub.status.busy": "2025-06-11T19:03:06.387126Z"
    },
    "papermill": {
     "duration": 13488.978805,
     "end_time": "2025-06-02T15:55:28.924887",
     "exception": false,
     "start_time": "2025-06-02T12:10:39.946082",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 1 started. Evaluating function at random point.\n",
      "Iteration No: 1 ended. Evaluation done at random point.\n",
      "Time taken: 51.3731\n",
      "Function value obtained: -8.4882\n",
      "Current minimum: -8.4882\n",
      "Iteration No: 2 started. Evaluating function at random point.\n",
      "Iteration No: 2 ended. Evaluation done at random point.\n",
      "Time taken: 48.1224\n",
      "Function value obtained: -7.0092\n",
      "Current minimum: -8.4882\n",
      "Iteration No: 3 started. Evaluating function at random point.\n",
      "Iteration No: 3 ended. Evaluation done at random point.\n",
      "Time taken: 49.1839\n",
      "Function value obtained: -2.2836\n",
      "Current minimum: -8.4882\n",
      "Iteration No: 4 started. Evaluating function at random point.\n",
      "Iteration No: 4 ended. Evaluation done at random point.\n",
      "Time taken: 49.6750\n",
      "Function value obtained: -0.1404\n",
      "Current minimum: -8.4882\n",
      "Iteration No: 5 started. Evaluating function at random point.\n",
      "Iteration No: 5 ended. Evaluation done at random point.\n",
      "Time taken: 50.7950\n",
      "Function value obtained: -8.5800\n",
      "Current minimum: -8.5800\n",
      "Iteration No: 6 started. Evaluating function at random point.\n",
      "Iteration No: 6 ended. Evaluation done at random point.\n",
      "Time taken: 50.0788\n",
      "Function value obtained: -8.8986\n",
      "Current minimum: -8.8986\n",
      "Iteration No: 7 started. Evaluating function at random point.\n",
      "Iteration No: 7 ended. Evaluation done at random point.\n",
      "Time taken: 48.7110\n",
      "Function value obtained: -3.1584\n",
      "Current minimum: -8.8986\n",
      "Iteration No: 8 started. Evaluating function at random point.\n",
      "Iteration No: 8 ended. Evaluation done at random point.\n",
      "Time taken: 50.5983\n",
      "Function value obtained: -8.1930\n",
      "Current minimum: -8.8986\n",
      "Iteration No: 9 started. Evaluating function at random point.\n",
      "Iteration No: 9 ended. Evaluation done at random point.\n",
      "Time taken: 51.2349\n",
      "Function value obtained: -7.4196\n",
      "Current minimum: -8.8986\n",
      "Iteration No: 10 started. Evaluating function at random point.\n",
      "Iteration No: 10 ended. Evaluation done at random point.\n",
      "Time taken: 49.9577\n",
      "Function value obtained: -8.2740\n",
      "Current minimum: -8.8986\n",
      "Iteration No: 11 started. Searching for the next optimal point.\n",
      "Iteration No: 11 ended. Search finished for the next optimal point.\n",
      "Time taken: 52.9413\n",
      "Function value obtained: -8.2596\n",
      "Current minimum: -8.8986\n",
      "Iteration No: 12 started. Searching for the next optimal point.\n",
      "Iteration No: 12 ended. Search finished for the next optimal point.\n",
      "Time taken: 50.7754\n",
      "Function value obtained: -7.1682\n",
      "Current minimum: -8.8986\n",
      "Iteration No: 13 started. Searching for the next optimal point.\n",
      "Iteration No: 13 ended. Search finished for the next optimal point.\n",
      "Time taken: 49.6753\n",
      "Function value obtained: -8.5542\n",
      "Current minimum: -8.8986\n",
      "Iteration No: 14 started. Searching for the next optimal point.\n",
      "Iteration No: 14 ended. Search finished for the next optimal point.\n",
      "Time taken: 52.0462\n",
      "Function value obtained: -7.6590\n",
      "Current minimum: -8.8986\n",
      "Iteration No: 15 started. Searching for the next optimal point.\n",
      "Iteration No: 15 ended. Search finished for the next optimal point.\n",
      "Time taken: 50.2340\n",
      "Function value obtained: -8.2632\n",
      "Current minimum: -8.8986\n",
      "Iteration No: 16 started. Searching for the next optimal point.\n",
      "Iteration No: 16 ended. Search finished for the next optimal point.\n",
      "Time taken: 52.2782\n",
      "Function value obtained: -8.4348\n",
      "Current minimum: -8.8986\n",
      "Iteration No: 17 started. Searching for the next optimal point.\n",
      "Iteration No: 17 ended. Search finished for the next optimal point.\n",
      "Time taken: 51.5843\n",
      "Function value obtained: -8.4900\n",
      "Current minimum: -8.8986\n",
      "Iteration No: 18 started. Searching for the next optimal point.\n",
      "Iteration No: 18 ended. Search finished for the next optimal point.\n",
      "Time taken: 52.0571\n",
      "Function value obtained: -8.4228\n",
      "Current minimum: -8.8986\n",
      "Iteration No: 19 started. Searching for the next optimal point.\n",
      "Iteration No: 19 ended. Search finished for the next optimal point.\n",
      "Time taken: 51.9682\n",
      "Function value obtained: -8.5320\n",
      "Current minimum: -8.8986\n",
      "Iteration No: 20 started. Searching for the next optimal point.\n",
      "Iteration No: 20 ended. Search finished for the next optimal point.\n",
      "Time taken: 52.3316\n",
      "Function value obtained: -8.0610\n",
      "Current minimum: -8.8986\n",
      "Iteration No: 21 started. Searching for the next optimal point.\n",
      "Iteration No: 21 ended. Search finished for the next optimal point.\n",
      "Time taken: 53.5945\n",
      "Function value obtained: -8.4576\n",
      "Current minimum: -8.8986\n",
      "Iteration No: 22 started. Searching for the next optimal point.\n",
      "Iteration No: 22 ended. Search finished for the next optimal point.\n",
      "Time taken: 52.8073\n",
      "Function value obtained: -8.7090\n",
      "Current minimum: -8.8986\n",
      "Iteration No: 23 started. Searching for the next optimal point.\n",
      "Iteration No: 23 ended. Search finished for the next optimal point.\n",
      "Time taken: 50.6175\n",
      "Function value obtained: -8.4924\n",
      "Current minimum: -8.8986\n",
      "Iteration No: 24 started. Searching for the next optimal point.\n",
      "Iteration No: 24 ended. Search finished for the next optimal point.\n",
      "Time taken: 53.5505\n",
      "Function value obtained: -7.9452\n",
      "Current minimum: -8.8986\n",
      "Iteration No: 25 started. Searching for the next optimal point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.28617e-12): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.28617e-12): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.28617e-12): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.28617e-12): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.28617e-12): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.20482e-12): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.20482e-12): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.20482e-12): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.20482e-12): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.20482e-12): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.28617e-12): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.28617e-12): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.28617e-12): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.28617e-12): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.28617e-12): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.20482e-12): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.20482e-12): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.20482e-12): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.20482e-12): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.20482e-12): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.28617e-12): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.28617e-12): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.28617e-12): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.28617e-12): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.28617e-12): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.20482e-12): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.20482e-12): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.20482e-12): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.20482e-12): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.20482e-12): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 25 ended. Search finished for the next optimal point.\n",
      "Time taken: 38.1539\n",
      "Function value obtained: -0.0270\n",
      "Current minimum: -8.8986\n",
      "Iteration No: 26 started. Searching for the next optimal point.\n",
      "Iteration No: 26 ended. Search finished for the next optimal point.\n",
      "Time taken: 52.1293\n",
      "Function value obtained: -7.8162\n",
      "Current minimum: -8.8986\n",
      "Iteration No: 27 started. Searching for the next optimal point.\n",
      "Iteration No: 27 ended. Search finished for the next optimal point.\n",
      "Time taken: 52.3089\n",
      "Function value obtained: -8.6622\n",
      "Current minimum: -8.8986\n",
      "Iteration No: 28 started. Searching for the next optimal point.\n",
      "Iteration No: 28 ended. Search finished for the next optimal point.\n",
      "Time taken: 54.0172\n",
      "Function value obtained: -8.6490\n",
      "Current minimum: -8.8986\n",
      "Iteration No: 29 started. Searching for the next optimal point.\n",
      "Iteration No: 29 ended. Search finished for the next optimal point.\n",
      "Time taken: 51.8872\n",
      "Function value obtained: -8.4966\n",
      "Current minimum: -8.8986\n",
      "Iteration No: 30 started. Searching for the next optimal point.\n",
      "Iteration No: 30 ended. Search finished for the next optimal point.\n",
      "Time taken: 54.1391\n",
      "Function value obtained: -8.3622\n",
      "Current minimum: -8.8986\n",
      "Iteration No: 31 started. Searching for the next optimal point.\n",
      "Iteration No: 31 ended. Search finished for the next optimal point.\n",
      "Time taken: 53.2471\n",
      "Function value obtained: -8.2944\n",
      "Current minimum: -8.8986\n",
      "Iteration No: 32 started. Searching for the next optimal point.\n",
      "Iteration No: 32 ended. Search finished for the next optimal point.\n",
      "Time taken: 52.6503\n",
      "Function value obtained: -8.0874\n",
      "Current minimum: -8.8986\n",
      "Iteration No: 33 started. Searching for the next optimal point.\n",
      "Iteration No: 33 ended. Search finished for the next optimal point.\n",
      "Time taken: 53.0874\n",
      "Function value obtained: -8.4588\n",
      "Current minimum: -8.8986\n",
      "Iteration No: 34 started. Searching for the next optimal point.\n",
      "Iteration No: 34 ended. Search finished for the next optimal point.\n",
      "Time taken: 53.4136\n",
      "Function value obtained: -8.4546\n",
      "Current minimum: -8.8986\n",
      "Iteration No: 35 started. Searching for the next optimal point.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.28617e-12): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.28617e-12): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.28617e-12): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.28617e-12): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.28617e-12): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.20482e-12): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.20482e-12): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.20482e-12): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.20482e-12): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.20482e-12): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.28617e-12): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.28617e-12): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.28617e-12): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.28617e-12): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.28617e-12): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.20482e-12): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.20482e-12): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.20482e-12): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.20482e-12): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.20482e-12): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.28617e-12): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.28617e-12): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.28617e-12): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.28617e-12): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.28617e-12): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.20482e-12): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.20482e-12): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.20482e-12): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.20482e-12): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=1.20482e-12): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 35 ended. Search finished for the next optimal point.\n",
      "Time taken: 38.1085\n",
      "Function value obtained: -0.0270\n",
      "Current minimum: -8.8986\n",
      "Iteration No: 36 started. Searching for the next optimal point.\n",
      "Iteration No: 36 ended. Search finished for the next optimal point.\n",
      "Time taken: 50.9260\n",
      "Function value obtained: -8.6040\n",
      "Current minimum: -8.8986\n",
      "Iteration No: 37 started. Searching for the next optimal point.\n",
      "Iteration No: 37 ended. Search finished for the next optimal point.\n",
      "Time taken: 53.5706\n",
      "Function value obtained: -8.0202\n",
      "Current minimum: -8.8986\n",
      "Iteration No: 38 started. Searching for the next optimal point.\n",
      "Iteration No: 38 ended. Search finished for the next optimal point.\n",
      "Time taken: 51.6999\n",
      "Function value obtained: -8.6568\n",
      "Current minimum: -8.8986\n",
      "Iteration No: 39 started. Searching for the next optimal point.\n",
      "Iteration No: 39 ended. Search finished for the next optimal point.\n",
      "Time taken: 52.0979\n",
      "Function value obtained: -8.5038\n",
      "Current minimum: -8.8986\n",
      "Iteration No: 40 started. Searching for the next optimal point.\n",
      "Iteration No: 40 ended. Search finished for the next optimal point.\n",
      "Time taken: 54.2571\n",
      "Function value obtained: -8.0820\n",
      "Current minimum: -8.8986\n",
      "Iteration No: 41 started. Searching for the next optimal point.\n",
      "Iteration No: 41 ended. Search finished for the next optimal point.\n",
      "Time taken: 49.9092\n",
      "Function value obtained: -7.7376\n",
      "Current minimum: -8.8986\n",
      "Iteration No: 42 started. Searching for the next optimal point.\n",
      "Iteration No: 42 ended. Search finished for the next optimal point.\n",
      "Time taken: 52.3331\n",
      "Function value obtained: -8.7174\n",
      "Current minimum: -8.8986\n",
      "Iteration No: 43 started. Searching for the next optimal point.\n",
      "Iteration No: 43 ended. Search finished for the next optimal point.\n",
      "Time taken: 51.9388\n",
      "Function value obtained: -8.1750\n",
      "Current minimum: -8.8986\n",
      "Iteration No: 44 started. Searching for the next optimal point.\n",
      "Iteration No: 44 ended. Search finished for the next optimal point.\n",
      "Time taken: 50.1029\n",
      "Function value obtained: -8.4924\n",
      "Current minimum: -8.8986\n",
      "Iteration No: 45 started. Searching for the next optimal point.\n",
      "Iteration No: 45 ended. Search finished for the next optimal point.\n",
      "Time taken: 51.7217\n",
      "Function value obtained: -7.9416\n",
      "Current minimum: -8.8986\n",
      "Iteration No: 46 started. Searching for the next optimal point.\n",
      "Iteration No: 46 ended. Search finished for the next optimal point.\n",
      "Time taken: 50.4549\n",
      "Function value obtained: -7.7796\n",
      "Current minimum: -8.8986\n",
      "Iteration No: 47 started. Searching for the next optimal point.\n",
      "Iteration No: 47 ended. Search finished for the next optimal point.\n",
      "Time taken: 53.8193\n",
      "Function value obtained: -7.3650\n",
      "Current minimum: -8.8986\n",
      "Iteration No: 48 started. Searching for the next optimal point.\n",
      "Iteration No: 48 ended. Search finished for the next optimal point.\n",
      "Time taken: 53.4437\n",
      "Function value obtained: -8.2818\n",
      "Current minimum: -8.8986\n",
      "Iteration No: 49 started. Searching for the next optimal point.\n",
      "Iteration No: 49 ended. Search finished for the next optimal point.\n",
      "Time taken: 52.5492\n",
      "Function value obtained: -7.9938\n",
      "Current minimum: -8.8986\n",
      "Iteration No: 50 started. Searching for the next optimal point.\n",
      "Iteration No: 50 ended. Search finished for the next optimal point.\n",
      "Time taken: 53.3562\n",
      "Function value obtained: -8.6688\n",
      "Current minimum: -8.8986\n",
      "Iteration No: 51 started. Searching for the next optimal point.\n",
      "Iteration No: 51 ended. Search finished for the next optimal point.\n",
      "Time taken: 51.5499\n",
      "Function value obtained: -8.8368\n",
      "Current minimum: -8.8986\n",
      "Iteration No: 52 started. Searching for the next optimal point.\n",
      "Iteration No: 52 ended. Search finished for the next optimal point.\n",
      "Time taken: 52.9281\n",
      "Function value obtained: -8.4810\n",
      "Current minimum: -8.8986\n",
      "Iteration No: 53 started. Searching for the next optimal point.\n",
      "Iteration No: 53 ended. Search finished for the next optimal point.\n",
      "Time taken: 53.2965\n",
      "Function value obtained: -8.7246\n",
      "Current minimum: -8.8986\n",
      "Iteration No: 54 started. Searching for the next optimal point.\n",
      "Iteration No: 54 ended. Search finished for the next optimal point.\n",
      "Time taken: 51.9898\n",
      "Function value obtained: -8.7210\n",
      "Current minimum: -8.8986\n",
      "Iteration No: 55 started. Searching for the next optimal point.\n",
      "Iteration No: 55 ended. Search finished for the next optimal point.\n",
      "Time taken: 54.0043\n",
      "Function value obtained: -8.9556\n",
      "Current minimum: -8.9556\n",
      "Iteration No: 56 started. Searching for the next optimal point.\n",
      "Iteration No: 56 ended. Search finished for the next optimal point.\n",
      "Time taken: 53.9984\n",
      "Function value obtained: -8.4780\n",
      "Current minimum: -8.9556\n",
      "Iteration No: 57 started. Searching for the next optimal point.\n"
     ]
    }
   ],
   "source": [
    "run_bayesian_search(DiffusionWaveletReservoirESN, \"DWMSR\", output_path=\"lorenz_DWMSR_bayes.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.025218,
     "end_time": "2025-06-02T15:55:28.978478",
     "exception": false,
     "start_time": "2025-06-02T15:55:28.95326",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 13496.185164,
   "end_time": "2025-06-02T15:55:29.637237",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-06-02T12:10:33.452073",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
