{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-06-21T06:02:31.281287Z",
     "iopub.status.busy": "2025-06-21T06:02:31.280924Z",
     "iopub.status.idle": "2025-06-21T06:02:31.286520Z",
     "shell.execute_reply": "2025-06-21T06:02:31.285480Z",
     "shell.execute_reply.started": "2025-06-21T06:02:31.281261Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.integrate import odeint\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import Ridge\n",
    "import json\n",
    "import itertools\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-21T06:02:31.288478Z",
     "iopub.status.busy": "2025-06-21T06:02:31.288195Z",
     "iopub.status.idle": "2025-06-21T06:02:31.307455Z",
     "shell.execute_reply": "2025-06-21T06:02:31.306546Z",
     "shell.execute_reply.started": "2025-06-21T06:02:31.288458Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def rossler_derivatives(state, t, a=0.2, b=0.2, c=5.7):\n",
    "    \"\"\"Compute time derivatives [dx/dt, dy/dt, dz/dt] for the Rössler system.\"\"\"\n",
    "    x, y, z = state\n",
    "    dxdt = -y - z\n",
    "    dydt = x + a * y\n",
    "    dzdt = b + z * (x - c)\n",
    "    return [dxdt, dydt, dzdt]\n",
    "\n",
    "def generate_rossler_data(\n",
    "    initial_state=[1.0, 0.0, 0.0],\n",
    "    tmax=25.0,\n",
    "    dt=0.01,\n",
    "    a=0.2,\n",
    "    b=0.2,\n",
    "    c=5.7\n",
    "):\n",
    "    \"\"\"\n",
    "    Numerically integrate Rössler equations x'(t), y'(t), z'(t) using odeint.\n",
    "    Returns:\n",
    "       t_vals: array of time points\n",
    "       sol   : array shape [num_steps, 3] of [x(t), y(t), z(t)]\n",
    "    \"\"\"\n",
    "    num_steps = int(tmax / dt)\n",
    "    t_vals = np.linspace(0, tmax, num_steps)\n",
    "    sol = odeint(rossler_derivatives, initial_state, t_vals, args=(a, b, c))\n",
    "    return t_vals, sol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-21T06:02:31.325981Z",
     "iopub.status.busy": "2025-06-21T06:02:31.325709Z",
     "iopub.status.idle": "2025-06-21T06:02:31.342017Z",
     "shell.execute_reply": "2025-06-21T06:02:31.341070Z",
     "shell.execute_reply.started": "2025-06-21T06:02:31.325962Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def evaluate_nrmse(all_preds, test_target, horizons):\n",
    "    \"\"\"\n",
    "    Evaluate model performance over multiple prediction horizons\n",
    "    for teacher-forced single-step forecasting or autoregressive rollout.\n",
    "    \"\"\"\n",
    "    horizon_nrmse = {}\n",
    "    for horizon in horizons:\n",
    "        preds = all_preds[:horizon]\n",
    "        targets = test_target[:horizon]\n",
    "        squared_errors = (preds - targets) ** 2\n",
    "        variance = np.var(targets, axis=0)\n",
    "        variance[variance == 0] = 1e-8  # avoid divide-by-zero\n",
    "        nrmse = np.sqrt(np.sum(squared_errors) / (horizon * np.sum(variance)))\n",
    "        horizon_nrmse[horizon] = nrmse\n",
    "    return horizon_nrmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-21T06:02:31.343115Z",
     "iopub.status.busy": "2025-06-21T06:02:31.342866Z",
     "iopub.status.idle": "2025-06-21T06:02:31.363724Z",
     "shell.execute_reply": "2025-06-21T06:02:31.362826Z",
     "shell.execute_reply.started": "2025-06-21T06:02:31.343097Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def compute_valid_prediction_time(y_true, y_pred, t_vals, threshold, lambda_max, dt):\n",
    "    \"\"\"\n",
    "    Compute the Valid Prediction Time (VPT) and compare it to Lyapunov time T_lambda = 1 / lambda_max.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true : ndarray of shape (N, dim)\n",
    "        True trajectory over time.\n",
    "    y_pred : ndarray of shape (N, dim)\n",
    "        Model's predicted trajectory over time (closed-loop).\n",
    "    t_vals : ndarray of shape (N,)\n",
    "        Time values corresponding to the trajectory steps.\n",
    "    threshold : float, optional\n",
    "        The error threshold, default is 0.4 as in your snippet.\n",
    "    lambda_max : float, optional\n",
    "        Largest Lyapunov exponent. Default=0.9 for Lorenz.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    T_VPT : float\n",
    "        Valid prediction time. The earliest time at which normalized error surpasses threshold\n",
    "        (or the last time if never surpassed).\n",
    "    T_lambda : float\n",
    "        Lyapunov time = 1 / lambda_max\n",
    "    ratio : float\n",
    "        How many Lyapunov times the model prediction remains valid, i.e. T_VPT / T_lambda.\n",
    "    \"\"\"\n",
    "    # 1) Average of y_true\n",
    "    y_mean = np.mean(y_true, axis=0)  # shape (dim,)\n",
    "    \n",
    "    # 2) Time-averaged norm^2 of (y_true - y_mean)\n",
    "    y_centered = y_true - y_mean\n",
    "    denom = np.mean(np.sum(y_centered**2, axis=1))  # scalar\n",
    "    \n",
    "    # 3) Compute the normalized error delta_gamma(t) = ||y_true - y_pred||^2 / denom\n",
    "    diff = y_true - y_pred\n",
    "    err_sq = np.sum(diff**2, axis=1)  # shape (N,)\n",
    "    delta_gamma = err_sq / denom      # shape (N,)\n",
    "    \n",
    "    # 4) Find the first time index where delta_gamma(t) exceeds threshold\n",
    "    idx_exceed = np.where(delta_gamma > threshold)[0]\n",
    "    if len(idx_exceed) == 0:\n",
    "        # never exceeds threshold => set T_VPT to the final time\n",
    "        T_VPT = t_vals[-1]\n",
    "    else:\n",
    "        T_VPT = t_vals[idx_exceed[0]]\n",
    "    \n",
    "    # 5) Compute T_lambda and ratio\n",
    "    T_lambda = 1.0 / lambda_max\n",
    "\n",
    "    # print(f\"\\n--- Valid Prediction Time (VPT) with threshold={threshold}, lambda_max={lambda_max} ---\")\n",
    "\n",
    "    T_VPT = (T_VPT - t_vals[0])  # Adjust T_VPT to be relative to the start time\n",
    "    ratio = T_VPT / T_lambda\n",
    "\n",
    "    return T_VPT, T_lambda, ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-21T06:02:31.471604Z",
     "iopub.status.busy": "2025-06-21T06:02:31.471314Z",
     "iopub.status.idle": "2025-06-21T06:02:31.480033Z",
     "shell.execute_reply": "2025-06-21T06:02:31.479212Z",
     "shell.execute_reply.started": "2025-06-21T06:02:31.471574Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# def compute_attractor_deviation(predictions, targets, cube_size=(0.1, 0.1, 0.1)):\n",
    "#     \"\"\"\n",
    "#     Compute the Attractor Deviation (ADev) metric.\n",
    "\n",
    "#     Parameters:\n",
    "#         predictions (numpy.ndarray): Predicted trajectories of shape (n, 3).\n",
    "#         targets (numpy.ndarray): True trajectories of shape (n, 3).\n",
    "#         cube_size (tuple): Dimensions of the cube (dx, dy, dz).\n",
    "\n",
    "#     Returns:\n",
    "#         float: The ADev metric.\n",
    "#     \"\"\"\n",
    "#     # Define the cube grid based on the range of the data and cube size\n",
    "#     min_coords = np.min(np.vstack((predictions, targets)), axis=0)\n",
    "#     max_coords = np.max(np.vstack((predictions, targets)), axis=0)\n",
    "\n",
    "#     # Create a grid of cubes\n",
    "#     grid_shape = ((max_coords - min_coords) / cube_size).astype(int) + 1\n",
    "\n",
    "#     # Initialize the cube occupancy arrays\n",
    "#     pred_cubes = np.zeros(grid_shape, dtype=int)\n",
    "#     target_cubes = np.zeros(grid_shape, dtype=int)\n",
    "\n",
    "#     # Map trajectories to cubes\n",
    "#     pred_indices = ((predictions - min_coords) / cube_size).astype(int)\n",
    "#     target_indices = ((targets - min_coords) / cube_size).astype(int)\n",
    "\n",
    "#     # Mark cubes visited by predictions and targets\n",
    "#     for idx in pred_indices:\n",
    "#         pred_cubes[tuple(idx)] = 1\n",
    "#     for idx in target_indices:\n",
    "#         target_cubes[tuple(idx)] = 1\n",
    "\n",
    "#     # Compute the ADev metric\n",
    "#     adev = np.sum(np.abs(pred_cubes - target_cubes))\n",
    "#     return adev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-21T06:02:31.481899Z",
     "iopub.status.busy": "2025-06-21T06:02:31.481582Z",
     "iopub.status.idle": "2025-06-21T06:02:31.510773Z",
     "shell.execute_reply": "2025-06-21T06:02:31.509821Z",
     "shell.execute_reply.started": "2025-06-21T06:02:31.481878Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(z: np.ndarray, /) -> np.ndarray:\n",
    "    \"\"\"Numerically-stable logistic σ : ℝ → (0, 1).\"\"\"\n",
    "    out = np.empty_like(z, dtype=np.float32)\n",
    "    np.subtract(0.0, z, out)            # out = −z   (no new allocation)\n",
    "    np.exp(out, out)                    # out = e^(−z)\n",
    "    out += 1.0                          # 1 + e^(−z)\n",
    "    np.reciprocal(out, out)             # 1 / (1 + e^(−z))\n",
    "    return out\n",
    "\n",
    "\n",
    "def _sample_frequencies(m: int, mode: str = \"log\") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Produce m distinct rotation angles θ_i ∈ (0, π).\n",
    "\n",
    "    * 'log'  : log-uniform in [10⁰·⁰, 10⁰·⁹] Hz then mapped to θ = 2πfΔt\n",
    "    * 'lin'  : uniform in (0, π)\n",
    "    * 'gold' : golden-ratio spacing (deterministic)\n",
    "    \"\"\"\n",
    "    if mode == \"log\":\n",
    "        # log-spread over ~1 decade, then map to (0, π)\n",
    "        f = 10 ** np.linspace(0.0, 0.9, m, dtype=np.float32)\n",
    "        f /= f.max()\n",
    "        return np.pi * f\n",
    "    if mode == \"lin\":\n",
    "        return np.random.default_rng().uniform(0.01, np.pi - 0.01, size=m)\n",
    "    if mode == \"gold\":\n",
    "        return (np.mod(np.arange(1, m + 1) * 0.61803398875, 1.0) * (np.pi - 0.02) + 0.01)\n",
    "    raise ValueError(\"mode must be {'log','lin','gold'}\")\n",
    "\n",
    "def augment_state_with_squares(x):\n",
    "    \"\"\"\n",
    "    Given state vector x in R^N, return [ x, x^2, 1 ] in R^(2N+1).\n",
    "    We'll use this for both training and prediction.\n",
    "    \"\"\"\n",
    "    x_sq = x**2\n",
    "    return np.concatenate([x, x_sq, [1.0]])  # shape: 2N+1\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Resonator reservoir class\n",
    "# ---------------------------------------------------------------------\n",
    "class FSR3D:\n",
    "    \"\"\"\n",
    "    Frequency-Selective Resonator Echo-State Network.\n",
    "\n",
    "    • N even ⇒ m = N/2 damped 2-D rotations (planar oscillators)\n",
    "    • Exact spectral control: eigenvalues r·e^{±iθ_i}\n",
    "    • Sparse symmetric nearest-neighbour coupling ε·C\n",
    "    • Optional static gain profile g_k  (sin→σ)  for heterogeneity\n",
    "    • Optional quadratic + quadrature feature map in the read-out\n",
    "    \"\"\"\n",
    "\n",
    "    # -----------------------------------------------------------------\n",
    "    def __init__(\n",
    "        self,\n",
    "        reservoir_size: int = 300,      # N (must be even)\n",
    "        frequency_mode: str = \"gold\",    # how to draw θ_i\n",
    "        r_damp: float = 0.95,           # attenuation per step\n",
    "        eps_couple: float = 0.05,       # ε   cross-pair mixing strength\n",
    "        input_scale: float = 0.5,\n",
    "        leak_rate: float = 1.0,         # α\n",
    "        ridge_alpha: float = 1e-6,\n",
    "        use_gain: bool = True,\n",
    "        gain_beta: float = 2.0,\n",
    "        gain_sigmoid: bool = True,\n",
    "        use_quadratic_feat: bool = True,\n",
    "        seed: int = 42,\n",
    "    ):\n",
    "        if reservoir_size % 2:\n",
    "            raise ValueError(\"reservoir_size must be even\")\n",
    "        self.N = reservoir_size\n",
    "        self.m = reservoir_size // 2\n",
    "        self.r = float(r_damp)\n",
    "        self.eps = float(eps_couple)\n",
    "        self.input_scale = input_scale\n",
    "        self.alpha = leak_rate\n",
    "        self.ridge_alpha = ridge_alpha\n",
    "        self.use_gain = use_gain\n",
    "        self.beta = gain_beta\n",
    "        self.sig_gain = gain_sigmoid\n",
    "        self.use_quad = use_quadratic_feat\n",
    "        self.seed = seed\n",
    "        self.freq_mode = frequency_mode\n",
    "\n",
    "        # matrices and state\n",
    "        self.W_res: np.ndarray | None = None\n",
    "        self.W_in: np.ndarray | None = None\n",
    "        self.W_out: np.ndarray | None = None\n",
    "        self.g: np.ndarray | None = None\n",
    "        self.x = np.zeros(self.N, dtype=np.float32)\n",
    "\n",
    "        # one-off construction\n",
    "        self._build_reservoir()\n",
    "        self._build_gain()\n",
    "\n",
    "    # -----------------------------------------------------------------\n",
    "    # internal builders\n",
    "    # -----------------------------------------------------------------\n",
    "    def _build_reservoir(self):\n",
    "        \"\"\"\n",
    "        Build   W_res = G · (R ⊕ ... ⊕ R  +  εC)   without the gain\n",
    "        (gain applied separately for cheaper runtime multiplication).\n",
    "        \"\"\"\n",
    "        m, r, eps = self.m, self.r, self.eps\n",
    "        θ = _sample_frequencies(m, mode=self.freq_mode)\n",
    "\n",
    "        # ----- block-diagonal damped rotations -----------------------\n",
    "        R_blocks = np.zeros((self.N, self.N), dtype=np.float32)\n",
    "        for i, theta in enumerate(θ):\n",
    "            c, s = np.cos(theta) * r, np.sin(theta) * r\n",
    "            i0 = 2 * i\n",
    "            R_blocks[i0, i0] = c\n",
    "            R_blocks[i0, i0 + 1] = -s\n",
    "            R_blocks[i0 + 1, i0] = s\n",
    "            R_blocks[i0 + 1, i0 + 1] = c\n",
    "\n",
    "        # ----- sparse symmetric coupling -----------------------------\n",
    "        rng = np.random.default_rng(self.seed)\n",
    "        C = np.zeros_like(R_blocks)\n",
    "        for i in range(m - 1):                        # nearest-neighbour chain\n",
    "            b = rng.standard_normal()\n",
    "            B = np.array([[b, 0.0], [0.0, b]], dtype=np.float32)\n",
    "            a0, a1 = 2 * i, 2 * (i + 1)\n",
    "            # upper block\n",
    "            C[a0 : a0 + 2, a1 : a1 + 2] = B\n",
    "            # symmetric lower block\n",
    "            C[a1 : a1 + 2, a0 : a0 + 2] = B.T\n",
    "\n",
    "        self.W_res = R_blocks + eps * C\n",
    "\n",
    "    def _build_gain(self):\n",
    "        \"\"\"Static per-neuron gain g_k.\"\"\"\n",
    "        if not self.use_gain:\n",
    "            self.g = np.ones(self.N, dtype=np.float32)\n",
    "            return\n",
    "        k_idx = np.arange(self.N, dtype=np.float32)\n",
    "        raw = self.beta * np.sin(2.0 * np.pi * k_idx / self.N)\n",
    "        self.g = sigmoid(raw) if self.sig_gain else raw.astype(np.float32)\n",
    "\n",
    "    # -----------------------------------------------------------------\n",
    "    # reservoir core\n",
    "    # -----------------------------------------------------------------\n",
    "    def _update(self, u_t: np.ndarray):\n",
    "        pre = self.W_res @ self.x + self.W_in @ u_t\n",
    "        if self.use_gain:\n",
    "            pre *= self.g\n",
    "        new_x = np.tanh(pre)\n",
    "        self.x = (1.0 - self.alpha) * self.x + self.alpha * new_x\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.x.fill(0.0)\n",
    "\n",
    "    # -----------------------------------------------------------------\n",
    "    # read-out training\n",
    "    # -----------------------------------------------------------------\n",
    "    def fit_readout(self, inputs: np.ndarray, targets: np.ndarray, discard: int = 100):\n",
    "        \"\"\"\n",
    "        Teacher-forcing pass to learn W_out via ridge regression.\n",
    "        * inputs  shape [T, d_in]\n",
    "        * targets shape [T, d_out]\n",
    "        \"\"\"\n",
    "        T, d_in = inputs.shape\n",
    "        if T <= discard + 1:\n",
    "            raise ValueError(\"Not enough data\")\n",
    "\n",
    "        # random input weights\n",
    "        rng = np.random.default_rng(self.seed)\n",
    "        self.W_in = (\n",
    "            rng.uniform(-1.0, 1.0, size=(self.N, d_in)) * self.input_scale\n",
    "        ).astype(np.float32)\n",
    "\n",
    "        # collect echoed states\n",
    "        self.reset_state()\n",
    "        states = []\n",
    "        for t in range(T):\n",
    "            self._update(inputs[t])\n",
    "            if t >= discard:\n",
    "                states.append(self.x.copy())\n",
    "\n",
    "        X = np.asarray(states, dtype=np.float32)            # [T−d, N]\n",
    "        Y = targets[discard:]                               # align\n",
    "\n",
    "        # feature map\n",
    "        if self.use_quad:\n",
    "            X_list = []\n",
    "            for s in X:\n",
    "                X_list.append(augment_state_with_squares(s))\n",
    "            feats = np.array(X_list, dtype=np.float32)\n",
    "\n",
    "        else:\n",
    "            feats = X\n",
    "\n",
    "        reg = Ridge(alpha=self.ridge_alpha, fit_intercept=False)\n",
    "        reg.fit(feats, Y)\n",
    "        self.W_out = reg.coef_.astype(np.float32)\n",
    "\n",
    "    # -----------------------------------------------------------------\n",
    "    # autoregressive forecast\n",
    "    # -----------------------------------------------------------------\n",
    "    def predict_autoregressive(self, init_u: np.ndarray, n_steps: int) -> np.ndarray:\n",
    "        if self.W_out is None:\n",
    "            raise RuntimeError(\"Call fit_readout() before prediction\")\n",
    "\n",
    "        d_in = init_u.shape[0]\n",
    "        preds = np.empty((n_steps, self.W_out.shape[0]), dtype=np.float32)\n",
    "\n",
    "        #self.reset_state()\n",
    "        u_t = init_u.astype(np.float32).copy()\n",
    "\n",
    "        for t in range(n_steps):\n",
    "            self._update(u_t)\n",
    "\n",
    "            if self.use_quad:\n",
    "                feat_vec = augment_state_with_squares(self.x)\n",
    "            else:\n",
    "                feat_vec = self.x\n",
    "\n",
    "            y_t = (self.W_out @ feat_vec).astype(np.float32)\n",
    "            preds[t] = y_t\n",
    "            u_t = y_t[:d_in]\n",
    "\n",
    "        return preds\n",
    "    \n",
    "    def predict_open_loop(self, inputs: np.ndarray):\n",
    "        preds = np.empty((inputs.shape[0], self.W_out.shape[0]), dtype=np.float32)\n",
    "        for true_input in inputs:\n",
    "            self._update(true_input)\n",
    "            if self.use_quad:\n",
    "                feat_vec = augment_state_with_squares(self.x)\n",
    "            else:\n",
    "                feat_vec = self.x\n",
    "            out = (self.W_out @ feat_vec).astype(np.float32)\n",
    "            preds.append(out)\n",
    "        return preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-21T06:26:41.755572Z",
     "iopub.status.busy": "2025-06-21T06:26:41.755262Z",
     "iopub.status.idle": "2025-06-21T06:26:41.759966Z",
     "shell.execute_reply": "2025-06-21T06:26:41.759106Z",
     "shell.execute_reply.started": "2025-06-21T06:26:41.755548Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# grid = {\n",
    "#     \"input_scale\": [0.7],\n",
    "#     \"ridge_alpha\": [1e-8],\n",
    "#     \"r_damp\": [0.5],\n",
    "#     \"eps_couple\": [0.1],\n",
    "#     \"leak_rate\": [0.7],\n",
    "#     \"gain_beta\": [0.6]\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-21T06:26:41.980482Z",
     "iopub.status.busy": "2025-06-21T06:26:41.979746Z",
     "iopub.status.idle": "2025-06-21T06:26:41.984046Z",
     "shell.execute_reply": "2025-06-21T06:26:41.983183Z",
     "shell.execute_reply.started": "2025-06-21T06:26:41.980456Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "grid = {\n",
    "    \"r_damp\": [0.7],\n",
    "    \"eps_couple\": [0.02],\n",
    "    \"input_scale\": [0.2, 0.4, 0.6, 0.8, 1.0],\n",
    "    \"leak_rate\": [0.1, 0.3, 0.5, 0.7, 0.9],\n",
    "    \"ridge_alpha\": [1e-8],\n",
    "    \"gain_beta\": [0.1, 0.3, 0.5, 0.7, 0.9],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-21T06:26:42.210820Z",
     "iopub.status.busy": "2025-06-21T06:26:42.210464Z",
     "iopub.status.idle": "2025-06-21T06:26:42.223876Z",
     "shell.execute_reply": "2025-06-21T06:26:42.222951Z",
     "shell.execute_reply.started": "2025-06-21T06:26:42.210774Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def run_grid_search(model_class, param_grid, model_name,\n",
    "                    output_path=\"grid_search_results.json\", f=generate_rossler_data, lambda_max=0.071):\n",
    "    combos = list(itertools.product(*param_grid.values()))\n",
    "    param_keys = list(param_grid.keys())\n",
    "    print(f\"\\n== Initial grid search for {model_name} with {len(combos)} combinations ==\")\n",
    "\n",
    "    results = []\n",
    "    # horizons = list(range(10, 1001, 10))\n",
    "    horizons = [200, 400, 600, 800, 1000]\n",
    "    \n",
    "\n",
    "    for comb in tqdm(combos, desc=\"Grid Search\"):\n",
    "        params = dict(zip(param_keys, comb))\n",
    "        seed_scores_vpt = []\n",
    "        horizon_nrmse_all = {h: [] for h in horizons}\n",
    "        horizon_nrmse_all_open_loop = {h: [] for h in horizons}\n",
    "        adev_scores = []\n",
    "        # ldev_scores = []\n",
    "\n",
    "        for initial_state in [[1.0, 1.0, 1.0], [1.0, 2.0, 3.0], [2.0, 1.5, 4.0]]:\n",
    "            tmax = 250\n",
    "            dt = 0.02\n",
    "            t_vals, lorenz_traj = f(\n",
    "                initial_state=initial_state,\n",
    "                tmax=tmax,\n",
    "                dt=dt\n",
    "            )\n",
    "\n",
    "            washout = 2000\n",
    "            t_vals = t_vals[washout:]\n",
    "            lorenz_traj = lorenz_traj[washout:]\n",
    "\n",
    "            scaler = MinMaxScaler()\n",
    "            scaler.fit(lorenz_traj)\n",
    "            lorenz_traj = scaler.transform(lorenz_traj)\n",
    "\n",
    "            T_data = len(lorenz_traj)\n",
    "            for train_frac in [0.3, 0.35, 0.4]:\n",
    "                train_end = int(train_frac * (T_data - 1))\n",
    "                train_input = lorenz_traj[:train_end]\n",
    "                train_target = lorenz_traj[1:train_end + 1]\n",
    "                test_input = lorenz_traj[train_end:-1]\n",
    "                test_target = lorenz_traj[train_end + 1:]\n",
    "                n_test_steps = len(test_input)\n",
    "                initial_in = test_input[0]\n",
    "\n",
    "                for seed in np.arange(1, 6):\n",
    "                    model = model_class(**params, seed=seed)\n",
    "                    model.fit_readout(train_input, train_target, discard=100)\n",
    "                    preds = model.predict_autoregressive(initial_in, n_test_steps)\n",
    "                    preds_open_loop = model.predict_open_loop(test_input)\n",
    "\n",
    "                    T_VPT_s, _, ratio = compute_valid_prediction_time(test_target, preds, t_vals, 0.4, lambda_max, dt)\n",
    "                    seed_scores_vpt.append(ratio)\n",
    "\n",
    "                    horizon_nrmse = evaluate_nrmse(preds, test_target, horizons)\n",
    "                    for h in horizons:\n",
    "                        horizon_nrmse_all[h].append(horizon_nrmse[h])\n",
    "\n",
    "                    horizon_nrmse_open_loop = evaluate_nrmse(preds_open_loop, test_target, horizons)\n",
    "                    for h in horizons:\n",
    "                        horizon_nrmse_all_open_loop[h].append(horizon_nrmse_open_loop[h])\n",
    "\n",
    "                    # adev = compute_attractor_deviation(preds, test_target)\n",
    "                    # adev_scores.append(adev)\n",
    "\n",
    "                    # ldev = compute_lyapunov_exponent(\"Lorenz\", preds, dt)\n",
    "                    # ldev_scores.append(ldev)\n",
    "\n",
    "        mean_vpt = float(np.mean(seed_scores_vpt))\n",
    "        std_vpt = float(np.std(seed_scores_vpt))\n",
    "        mean_nrmse_dict = {str(h): float(np.mean(horizon_nrmse_all[h])) for h in horizons}\n",
    "        std_nrmse_dict  = {str(h): float(np.std(horizon_nrmse_all[h]))  for h in horizons}\n",
    "        mean_nrmse_dict_open_loop = {str(h): float(np.mean(horizon_nrmse_all_open_loop[h])) for h in horizons}\n",
    "        std_nrmse_dict_open_loop = {str(h): float(np.std(horizon_nrmse_all_open_loop[h])) for h in horizons}\n",
    "        # mean_adev = float(np.mean(adev_scores))\n",
    "        # std_adev = float(np.std(adev_scores))\n",
    "        # mean_ldev = float(np.mean(ldev_scores))\n",
    "        # std_ldev = float(np.std(ldev_scores))\n",
    "\n",
    "        results.append({\n",
    "            \"params\": params,\n",
    "            \"seed_scores_T_VPT\": seed_scores_vpt,\n",
    "            \"mean_T_VPT\": mean_vpt,\n",
    "            \"std_T_VPT\": std_vpt,\n",
    "            \"mean_NRMSEs\": mean_nrmse_dict,\n",
    "            \"std_NRMSEs\": std_nrmse_dict,\n",
    "            \"mean_NRMSEs_open_loop\": mean_nrmse_dict_open_loop,\n",
    "            \"std_NRMSEs_open_loop\": std_nrmse_dict_open_loop,\n",
    "            # Uncomment if you want to include ADev and LDev metrics\n",
    "            # \"mean_ADev\": mean_adev,\n",
    "            # \"std_ADev\": std_adev,\n",
    "            # \"mean_LDev\": mean_ldev,\n",
    "            # \"std_LDev\": std_ldev\n",
    "        })\n",
    "\n",
    "    with open(output_path, \"w\") as f:\n",
    "        json.dump(results, f, indent=2)\n",
    "    print(f\"\\nAll results saved to `{output_path}`\")\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-21T06:26:42.422594Z",
     "iopub.status.busy": "2025-06-21T06:26:42.421703Z",
     "iopub.status.idle": "2025-06-21T06:28:18.737083Z",
     "shell.execute_reply": "2025-06-21T06:28:18.736430Z",
     "shell.execute_reply.started": "2025-06-21T06:26:42.422557Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "== Initial grid search for fsr with 1 combinations ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search: 100%|██████████| 1/1 [01:36<00:00, 96.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All results saved to `fsr_l.json`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'params': {'input_scale': 0.7,\n",
       "   'ridge_alpha': 1e-08,\n",
       "   'r_damp': 0.5,\n",
       "   'eps_couple': 0.1,\n",
       "   'leak_rate': 0.7,\n",
       "   'gain_beta': 0.6},\n",
       "  'seed_scores_T_VPT': [11.268000000000002,\n",
       "   4.752000000000001,\n",
       "   4.770000000000004,\n",
       "   4.770000000000004,\n",
       "   4.680000000000002,\n",
       "   11.411999999999999,\n",
       "   11.502,\n",
       "   10.133999999999999,\n",
       "   10.026,\n",
       "   10.170000000000003,\n",
       "   9.540000000000001,\n",
       "   8.244000000000003,\n",
       "   8.892000000000001,\n",
       "   8.244000000000003,\n",
       "   9.504000000000001,\n",
       "   10.404000000000002,\n",
       "   8.333999999999998,\n",
       "   8.297999999999998,\n",
       "   8.297999999999998,\n",
       "   10.494000000000003,\n",
       "   11.159999999999998,\n",
       "   7.344000000000003,\n",
       "   10.962,\n",
       "   11.033999999999997,\n",
       "   7.182000000000003,\n",
       "   8.388,\n",
       "   8.316,\n",
       "   8.442000000000002,\n",
       "   8.442000000000002,\n",
       "   10.962,\n",
       "   7.164000000000001,\n",
       "   7.182000000000003,\n",
       "   10.259999999999998,\n",
       "   7.182000000000003,\n",
       "   11.682000000000004,\n",
       "   7.002000000000001,\n",
       "   6.966000000000001,\n",
       "   6.911999999999999,\n",
       "   10.782000000000004,\n",
       "   10.709999999999999,\n",
       "   8.171999999999999,\n",
       "   9.756000000000002,\n",
       "   9.792000000000002,\n",
       "   9.558000000000003,\n",
       "   9.612],\n",
       "  'mean_T_VPT': 8.860000000000003,\n",
       "  'std_T_VPT': 1.9079278812366045,\n",
       "  'mean_NRMSEs': {'200': 0.002245218840853732,\n",
       "   '400': 0.06659954007628287,\n",
       "   '600': 0.35247370933027283,\n",
       "   '800': 0.7578440742410631,\n",
       "   '1000': 0.9346102185796332},\n",
       "  'std_NRMSEs': {'200': 0.0035145361080125034,\n",
       "   '400': 0.10898565773799569,\n",
       "   '600': 0.22670515083648327,\n",
       "   '800': 0.14608236685658213,\n",
       "   '1000': 0.1051459809147798},\n",
       "  'mean_ADev': 29.355555555555554,\n",
       "  'std_ADev': 13.21473177186995}]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_grid_search(FSR3D, grid, \"fsr\", output_path=\"fsr_r 41.json\", f=generate_rossler_data, lambda_max=0.071)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
