{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.integrate import odeint\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import Ridge\n",
    "import json\n",
    "import itertools\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lorenz_deriv(state, t, sigma=10.0, rho=28.0, beta=8.0/3.0):\n",
    "    x, y, z = state\n",
    "    dxdt = sigma * (y - x)\n",
    "    dydt = x*(rho - z) - y\n",
    "    dzdt = x*y - beta*z\n",
    "    return [dxdt, dydt, dzdt]\n",
    "\n",
    "def generate_lorenz_data(\n",
    "    initial_state=[1.0, 1.0, 1.0],\n",
    "    tmax=25.0,\n",
    "    dt=0.01,\n",
    "    sigma=10.0,\n",
    "    rho=28.0,\n",
    "    beta=8.0/3.0\n",
    "):\n",
    "    num_steps = int(tmax / dt) + 1 # +1 to include t=0\n",
    "    t_vals = np.linspace(0, tmax, num_steps)\n",
    "    sol = odeint(lorenz_deriv, initial_state, t_vals, args=(sigma, rho, beta))\n",
    "    return t_vals, sol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_nrmse(all_preds, test_target, horizons):\n",
    "    \"\"\"\n",
    "    Evaluate model performance over multiple prediction horizons\n",
    "    for teacher-forced single-step forecasting or autoregressive rollout.\n",
    "    \"\"\"\n",
    "    horizon_nrmse = {}\n",
    "    for horizon in horizons:\n",
    "        preds = all_preds[:horizon]\n",
    "        targets = test_target[:horizon]\n",
    "        squared_errors = (preds - targets) ** 2\n",
    "        variance = np.var(targets, axis=0)\n",
    "        variance[variance == 0] = 1e-8  # avoid divide-by-zero\n",
    "        nrmse = np.sqrt(np.sum(squared_errors) / (horizon * np.sum(variance)))\n",
    "        horizon_nrmse[horizon] = nrmse\n",
    "    return horizon_nrmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_valid_prediction_time(y_true, y_pred, t_vals, threshold, lambda_max, dt):\n",
    "    \"\"\"\n",
    "    Compute the Valid Prediction Time (VPT) and compare it to Lyapunov time T_lambda = 1 / lambda_max.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true : ndarray of shape (N, dim)\n",
    "        True trajectory over time.\n",
    "    y_pred : ndarray of shape (N, dim)\n",
    "        Model's predicted trajectory over time (closed-loop).\n",
    "    t_vals : ndarray of shape (N,)\n",
    "        Time values corresponding to the trajectory steps.\n",
    "    threshold : float, optional\n",
    "        The error threshold, default is 0.4 as in your snippet.\n",
    "    lambda_max : float, optional\n",
    "        Largest Lyapunov exponent. Default=0.9 for Lorenz.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    T_VPT : float\n",
    "        Valid prediction time. The earliest time at which normalized error surpasses threshold\n",
    "        (or the last time if never surpassed).\n",
    "    T_lambda : float\n",
    "        Lyapunov time = 1 / lambda_max\n",
    "    ratio : float\n",
    "        How many Lyapunov times the model prediction remains valid, i.e. T_VPT / T_lambda.\n",
    "    \"\"\"\n",
    "    # 1) Average of y_true\n",
    "    y_mean = np.mean(y_true, axis=0)  # shape (dim,)\n",
    "    \n",
    "    # 2) Time-averaged norm^2 of (y_true - y_mean)\n",
    "    y_centered = y_true - y_mean\n",
    "    denom = np.mean(np.sum(y_centered**2, axis=1))  # scalar\n",
    "    \n",
    "    # 3) Compute the normalized error delta_gamma(t) = ||y_true - y_pred||^2 / denom\n",
    "    diff = y_true - y_pred\n",
    "    err_sq = np.sum(diff**2, axis=1)  # shape (N,)\n",
    "    delta_gamma = err_sq / denom      # shape (N,)\n",
    "    \n",
    "    # 4) Find the first time index where delta_gamma(t) exceeds threshold\n",
    "    idx_exceed = np.where(delta_gamma > threshold)[0]\n",
    "    if len(idx_exceed) == 0:\n",
    "        # never exceeds threshold => set T_VPT to the final time\n",
    "        T_VPT = t_vals[-1]\n",
    "    else:\n",
    "        T_VPT = t_vals[idx_exceed[0]]\n",
    "    \n",
    "    # 5) Compute T_lambda and ratio\n",
    "    T_lambda = 1.0 / lambda_max\n",
    "\n",
    "    # print(f\"\\n--- Valid Prediction Time (VPT) with threshold={threshold}, lambda_max={lambda_max} ---\")\n",
    "\n",
    "    T_VPT = (T_VPT - t_vals[0])  # Adjust T_VPT to be relative to the start time\n",
    "    ratio = T_VPT / T_lambda\n",
    "\n",
    "    return T_VPT, T_lambda, ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_attractor_deviation(predictions, targets, cube_size=(0.1, 0.1, 0.1)):\n",
    "    \"\"\"\n",
    "    Compute the Attractor Deviation (ADev) metric.\n",
    "\n",
    "    Parameters:\n",
    "        predictions (numpy.ndarray): Predicted trajectories of shape (n, 3).\n",
    "        targets (numpy.ndarray): True trajectories of shape (n, 3).\n",
    "        cube_size (tuple): Dimensions of the cube (dx, dy, dz).\n",
    "\n",
    "    Returns:\n",
    "        float: The ADev metric.\n",
    "    \"\"\"\n",
    "    # Define the cube grid based on the range of the data and cube size\n",
    "    min_coords = np.min(np.vstack((predictions, targets)), axis=0)\n",
    "    max_coords = np.max(np.vstack((predictions, targets)), axis=0)\n",
    "\n",
    "    # Create a grid of cubes\n",
    "    grid_shape = ((max_coords - min_coords) / cube_size).astype(int) + 1\n",
    "\n",
    "    # Initialize the cube occupancy arrays\n",
    "    pred_cubes = np.zeros(grid_shape, dtype=int)\n",
    "    target_cubes = np.zeros(grid_shape, dtype=int)\n",
    "\n",
    "    # Map trajectories to cubes\n",
    "    pred_indices = ((predictions - min_coords) / cube_size).astype(int)\n",
    "    target_indices = ((targets - min_coords) / cube_size).astype(int)\n",
    "\n",
    "    # Mark cubes visited by predictions and targets\n",
    "    for idx in pred_indices:\n",
    "        pred_cubes[tuple(idx)] = 1\n",
    "    for idx in target_indices:\n",
    "        target_cubes[tuple(idx)] = 1\n",
    "\n",
    "    # Compute the ADev metric\n",
    "    adev = np.sum(np.abs(pred_cubes - target_cubes))\n",
    "    return adev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "\n",
    "class GliaNeuronTripartiteReservoirESN:\n",
    "    \"\"\"\n",
    "    Glia–Neuron Tripartite-Synapse Reservoir (GNT-SR)\n",
    "\n",
    "    ------------------------------------------------------------------\n",
    "    State variables\n",
    "        x  ∈ ℝᴺ   : neuronal membrane potentials (fast)\n",
    "        c  ∈ ℝᴹ   : astrocytic Ca²⁺ concentrations   (intermediate)\n",
    "        g  ∈ ℝᴹ   : gliotransmitter release fractions (slow)\n",
    "\n",
    "    Update order per time-step t → t+1\n",
    "        1)  c     ←   (1-μ)·c   + μ·η·σ(W_ng x − θ)   + μ·D·L_g c\n",
    "        2)  g     ←   γ·c / (1 + c)\n",
    "        3)  x     ←  (1-α)·x + α·tanh(W_nn x + W_in u + W_gn g)\n",
    "\n",
    "    Echo-state property is guaranteed by fixing ρ(W_nn) < 1 and because\n",
    "    astrocytic modulation acts only as an added bias.\n",
    "    \"\"\"\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    #                          constructor                              \n",
    "    # ------------------------------------------------------------------\n",
    "    def __init__(\n",
    "        self,\n",
    "        reservoir_size: int = 800,      # N  neurons\n",
    "        n_astrocytes: int | None = None,  # M  astrocytes; default N//10\n",
    "        input_dim: int = 3,\n",
    "        rho_star: float = 0.8,          # desired spectral radius of W_nn\n",
    "        alpha: float = 0.5,             # neuronal leak        (α)\n",
    "        tau_c: float = 200.0,           # Ca²⁺ relaxation time (steps)\n",
    "        eta: float = 1.0,               # Ca²⁺ activation gain (η)\n",
    "        D_diff: float = 0.005,          # astrocytic diffusion (D)\n",
    "        theta: float = 0.0,             # Ca²⁺ threshold       (θ)\n",
    "        gamma_glia: float = 0.4,        # max gliotransmitter  (γ)\n",
    "        input_scale: float = 0.5,\n",
    "        ridge_alpha: float = 1e-6,\n",
    "        use_quadratic_readout: bool = True,\n",
    "        seed: int = 42,\n",
    "    ):\n",
    "        # -------------- dimensions ------------------------------------\n",
    "        self.N = reservoir_size\n",
    "        self.M = n_astrocytes if n_astrocytes is not None else max(1, reservoir_size // 10)\n",
    "        self.d_in = input_dim\n",
    "\n",
    "        # -------------- hyper-parameters ------------------------------\n",
    "        self.rho_star = rho_star\n",
    "        self.alpha = alpha\n",
    "        self.mu = 1.0 / tau_c           # μ = Δt / τ_c  (Δt = 1)\n",
    "        self.eta = eta\n",
    "        self.D = D_diff\n",
    "        self.theta = theta\n",
    "        self.gamma = gamma_glia\n",
    "        self.input_scale = input_scale\n",
    "        self.ridge_alpha = ridge_alpha\n",
    "        self.use_quad = use_quadratic_readout\n",
    "        self.seed = seed\n",
    "\n",
    "        rng = np.random.default_rng(self.seed)\n",
    "\n",
    "        # --------------------------------------------------------------\n",
    "        # static weight matrices\n",
    "        # --------------------------------------------------------------\n",
    "        # 1) Neuron-neuron recurrent matrix   W_nn\n",
    "        W_raw = rng.standard_normal((self.N, self.N)).astype(np.float32)\n",
    "        eig_max = np.max(np.abs(np.linalg.eigvals(W_raw)))\n",
    "        self.W_nn = (self.rho_star / eig_max) * W_raw\n",
    "\n",
    "        # 2) Input weights  W_in\n",
    "        self.W_in = (\n",
    "            rng.uniform(-1.0, 1.0, size=(self.N, self.d_in)) * self.input_scale\n",
    "        ).astype(np.float32)\n",
    "\n",
    "        # 3) Neuron → astrocyte  W_ng   (rows sparse, non-neg)\n",
    "        self.W_ng = rng.uniform(0.0, 1.0, size=(self.M, self.N)).astype(np.float32)\n",
    "        # 4) Astrocyte → neuron  W_gn   (columns sparse, non-neg)\n",
    "        self.W_gn = rng.uniform(0.0, 1.0, size=(self.N, self.M)).astype(np.float32)\n",
    "\n",
    "        # 5) Laplacian L_g  for astrocyte diffusion (1-D chain for simplicity)\n",
    "        L = np.zeros((self.M, self.M), dtype=np.float32)\n",
    "        for i in range(self.M):\n",
    "            if i > 0:\n",
    "                L[i, i - 1] = -1.0\n",
    "            if i < self.M - 1:\n",
    "                L[i, i + 1] = -1.0\n",
    "            L[i, i] = (2.0 if 0 < i < self.M - 1 else 1.0)\n",
    "        self.L_g = L\n",
    "\n",
    "        # --------------------------------------------------------------\n",
    "        # dynamic state vectors\n",
    "        # --------------------------------------------------------------\n",
    "        self.x = np.zeros(self.N, dtype=np.float32)\n",
    "        self.c = np.zeros(self.M, dtype=np.float32)\n",
    "        self.g = np.zeros(self.M, dtype=np.float32)\n",
    "\n",
    "        self.W_out: np.ndarray | None = None\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    #                            helpers                                \n",
    "    # ------------------------------------------------------------------\n",
    "    def reset_state(self):\n",
    "        self.x.fill(0.0)\n",
    "        self.c.fill(0.0)\n",
    "        self.g.fill(0.0)\n",
    "\n",
    "    def _step(self, u_t: np.ndarray):\n",
    "        \"\"\"One full tripartite update.\"\"\"\n",
    "        # ---- astrocytic Ca²⁺ -----------------------------------------\n",
    "        pre_c = self.W_ng @ self.x - self.theta\n",
    "        sigma_term = 1.0 / (1.0 + np.exp(-pre_c))        # logistic σ\n",
    "        diff_term = self.D * (self.L_g @ self.c)\n",
    "        self.c = (1.0 - self.mu) * self.c + self.mu * (self.eta * sigma_term + diff_term)\n",
    "\n",
    "        # ---- gliotransmitter release --------------------------------\n",
    "        self.g = self.gamma * self.c / (1.0 + self.c)    # element-wise\n",
    "\n",
    "        # ---- neuronal update ----------------------------------------\n",
    "        bias = self.W_gn @ self.g                        # N-vector\n",
    "        pre = self.W_nn @ self.x + self.W_in @ u_t + bias\n",
    "        x_new = np.tanh(pre).astype(np.float32)\n",
    "        self.x = (1.0 - self.alpha) * self.x + self.alpha * x_new\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    #                       read-out training                           \n",
    "    # ------------------------------------------------------------------\n",
    "    def fit_readout(self, inputs: np.ndarray, targets: np.ndarray, discard: int = 100):\n",
    "        \"\"\"\n",
    "        Teacher forcing to train W_out.\n",
    "\n",
    "        inputs  : [T, d_in]\n",
    "        targets : [T, d_out]\n",
    "        \"\"\"\n",
    "        T, d_in = inputs.shape\n",
    "        if d_in != self.d_in:\n",
    "            raise ValueError(\"input_dim mismatch\")\n",
    "        if T <= discard + 1:\n",
    "            raise ValueError(\"sequence too short\")\n",
    "\n",
    "        self.reset_state()\n",
    "        feats_list = []\n",
    "        for t in range(T):\n",
    "            self._step(inputs[t])\n",
    "            if t >= discard:\n",
    "                if self.use_quad:\n",
    "                    feats = np.concatenate(\n",
    "                        [\n",
    "                            self.x,\n",
    "                            self.x * self.x,\n",
    "                            self.c,\n",
    "                            self.g,\n",
    "                            [1.0],\n",
    "                        ]\n",
    "                    )\n",
    "                else:\n",
    "                    feats = np.concatenate([self.x, self.c, self.g, [1.0]])\n",
    "                feats_list.append(feats)\n",
    "\n",
    "        X_feat = np.asarray(feats_list, dtype=np.float32)\n",
    "        Y = targets[discard:]\n",
    "\n",
    "        reg = Ridge(alpha=self.ridge_alpha, fit_intercept=False)\n",
    "        reg.fit(X_feat, Y)\n",
    "        self.W_out = reg.coef_.astype(np.float32)\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    #                     autoregressive rollout                        \n",
    "    # ------------------------------------------------------------------\n",
    "    def predict_autoregressive(self, init_input: np.ndarray, n_steps: int) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Free-run the reservoir for n_steps.\n",
    "\n",
    "        init_input : shape (d_in,)\n",
    "        returns    : shape (n_steps, d_out)\n",
    "        \"\"\"\n",
    "        if self.W_out is None:\n",
    "            raise RuntimeError(\"Call fit_readout() first\")\n",
    "\n",
    "        d_out = self.W_out.shape[0]\n",
    "        preds = np.empty((n_steps, d_out), dtype=np.float32)\n",
    "\n",
    "        #self.reset_state()\n",
    "        u_t = init_input.astype(np.float32).copy()\n",
    "\n",
    "        for t in range(n_steps):\n",
    "            self._step(u_t)\n",
    "\n",
    "            if self.use_quad:\n",
    "                feat_vec = np.concatenate([self.x, self.x * self.x, self.c, self.g, [1.0]])\n",
    "            else:\n",
    "                feat_vec = np.concatenate([self.x, self.c, self.g, [1.0]])\n",
    "\n",
    "            y_t = (self.W_out @ feat_vec).astype(np.float32)\n",
    "            preds[t] = y_t\n",
    "            u_t = y_t[: self.d_in]      # feedback first d_in components\n",
    "\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = {\n",
    "    \"reservoir_size\": [300],\n",
    "    \"n_astrocytes\": [20],\n",
    "    \"input_dim\": [3],\n",
    "    \"rho_star\": [0.98],\n",
    "    \"alpha\": [0.4],\n",
    "    \"tau_c\": [200.0],\n",
    "    \"eta\": [1.2],\n",
    "    \"D_diff\": [0.07],\n",
    "    \"theta\" : [0.02],\n",
    "    \"gamma_glia\": [0.01],\n",
    "    \"input_scale\" : [1.3],\n",
    "    \"ridge_alpha\" : [1e-8],\n",
    "    \"use_quadratic_readout\" : [True],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_grid_search(model_class, param_grid, model_name,\n",
    "                    output_path=\"grid_search_results.json\", f=generate_lorenz_data, lambda_max=0.9):\n",
    "    combos = list(itertools.product(*param_grid.values()))\n",
    "    param_keys = list(param_grid.keys())\n",
    "    print(f\"\\n== Initial grid search for {model_name} with {len(combos)} combinations ==\")\n",
    "\n",
    "    results = []\n",
    "    # horizons = list(range(10, 1001, 10))\n",
    "    # horizons = [200, 400, 600, 800, 1000]\n",
    "    \n",
    "\n",
    "    for comb in tqdm(combos, desc=\"Grid Search\"):\n",
    "        params = dict(zip(param_keys, comb))\n",
    "        seed_scores_vpt = []\n",
    "        # horizon_nrmse_all = {h: [] for h in horizons}\n",
    "        # horizon_nrmse_all_open_loop = {h: [] for h in horizons}\n",
    "        # adev_scores = []\n",
    "        # ldev_scores = []\n",
    "\n",
    "        for initial_state in [[1.0, 1.0, 1.0], [1.0, 2.0, 3.0], [2.0, 1.5, 4.0]]:\n",
    "            tmax = 250\n",
    "            dt = 0.02\n",
    "            t_vals, lorenz_traj = f(\n",
    "                initial_state=initial_state,\n",
    "                tmax=tmax,\n",
    "                dt=dt\n",
    "            )\n",
    "\n",
    "            washout = 2000\n",
    "            t_vals = t_vals[washout:]\n",
    "            lorenz_traj = lorenz_traj[washout:]\n",
    "\n",
    "            scaler = MinMaxScaler()\n",
    "            scaler.fit(lorenz_traj)\n",
    "            lorenz_traj = scaler.transform(lorenz_traj)\n",
    "\n",
    "            T_data = len(lorenz_traj)\n",
    "            for train_frac in [0.7, 0.75, 0.8]:\n",
    "                train_end = int(train_frac * (T_data - 1))\n",
    "                train_input = lorenz_traj[:train_end]\n",
    "                train_target = lorenz_traj[1:train_end + 1]\n",
    "                test_input = lorenz_traj[train_end:-1]\n",
    "                test_target = lorenz_traj[train_end + 1:]\n",
    "                n_test_steps = len(test_input)\n",
    "                initial_in = test_input[0]\n",
    "\n",
    "                for seed in np.arange(1, 6):\n",
    "                    model = model_class(**params, seed=seed)\n",
    "                    model.fit_readout(train_input, train_target, discard=100)\n",
    "                    preds = model.predict_autoregressive(initial_in, n_test_steps)\n",
    "                    \n",
    "                    T_VPT_s, _, ratio = compute_valid_prediction_time(test_target, preds, t_vals, 0.4, lambda_max, dt)\n",
    "                    seed_scores_vpt.append(ratio)\n",
    "\n",
    "                    # horizon_nrmse = evaluate_nrmse(preds, test_target, horizons)\n",
    "                    # for h in horizons:\n",
    "                    #     horizon_nrmse_all[h].append(horizon_nrmse[h])\n",
    "\n",
    "\n",
    "                    # adev = compute_attractor_deviation(preds, test_target)\n",
    "                    # adev_scores.append(adev)\n",
    "\n",
    "                    # ldev = compute_lyapunov_exponent(\"Lorenz\", preds, dt)\n",
    "                    # ldev_scores.append(ldev)\n",
    "\n",
    "        mean_vpt = float(np.mean(seed_scores_vpt))\n",
    "        std_vpt = float(np.std(seed_scores_vpt))\n",
    "        # mean_nrmse_dict = {str(h): float(np.mean(horizon_nrmse_all[h])) for h in horizons}\n",
    "        # std_nrmse_dict  = {str(h): float(np.std(horizon_nrmse_all[h]))  for h in horizons}\n",
    "        # mean_adev = float(np.mean(adev_scores))\n",
    "        # std_adev = float(np.std(adev_scores))\n",
    "        # mean_ldev = float(np.mean(ldev_scores))\n",
    "        # std_ldev = float(np.std(ldev_scores))\n",
    "\n",
    "        results.append({\n",
    "            \"params\": params,\n",
    "            \"seed_scores_T_VPT\": seed_scores_vpt,\n",
    "            \"mean_T_VPT\": mean_vpt,\n",
    "            \"std_T_VPT\": std_vpt,\n",
    "            # \"mean_NRMSEs\": mean_nrmse_dict,\n",
    "            # \"std_NRMSEs\": std_nrmse_dict,\n",
    "            # \"mean_ADev\": mean_adev,\n",
    "            # \"std_ADev\": std_adev,\n",
    "        })\n",
    "\n",
    "    with open(output_path, \"w\") as f:\n",
    "        json.dump(results, f, indent=2)\n",
    "    print(f\"\\nAll results saved to `{output_path}`\")\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "== Initial grid search for GliaNeuronTripartiteReservoir with 1 combinations ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search: 100%|██████████| 1/1 [00:48<00:00, 48.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All results saved to `GLIA.json`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'params': {'reservoir_size': 300,\n",
       "   'n_astrocytes': 20,\n",
       "   'input_dim': 3,\n",
       "   'rho_star': 0.98,\n",
       "   'alpha': 0.4,\n",
       "   'tau_c': 200.0,\n",
       "   'eta': 1.2,\n",
       "   'D_diff': 0.07,\n",
       "   'theta': 0.02,\n",
       "   'gamma_glia': 0.01,\n",
       "   'input_scale': 1.3,\n",
       "   'ridge_alpha': 1e-08,\n",
       "   'use_quadratic_readout': True},\n",
       "  'seed_scores_T_VPT': [np.float64(9.702),\n",
       "   np.float64(9.738),\n",
       "   np.float64(9.612),\n",
       "   np.float64(7.776),\n",
       "   np.float64(9.720000000000004),\n",
       "   np.float64(7.938),\n",
       "   np.float64(9.828000000000001),\n",
       "   np.float64(8.009999999999998),\n",
       "   np.float64(11.304000000000002),\n",
       "   np.float64(7.847999999999999),\n",
       "   np.float64(10.674),\n",
       "   np.float64(10.692000000000002),\n",
       "   np.float64(8.730000000000002),\n",
       "   np.float64(8.730000000000002),\n",
       "   np.float64(8.856000000000003),\n",
       "   np.float64(10.638),\n",
       "   np.float64(8.1),\n",
       "   np.float64(8.064),\n",
       "   np.float64(10.620000000000003),\n",
       "   np.float64(8.028),\n",
       "   np.float64(11.195999999999998),\n",
       "   np.float64(9.306000000000003),\n",
       "   np.float64(11.214),\n",
       "   np.float64(9.233999999999998),\n",
       "   np.float64(9.324),\n",
       "   np.float64(8.712),\n",
       "   np.float64(10.026),\n",
       "   np.float64(8.621999999999998),\n",
       "   np.float64(8.748),\n",
       "   np.float64(8.676),\n",
       "   np.float64(9.071999999999997),\n",
       "   np.float64(9.071999999999997),\n",
       "   np.float64(9.126),\n",
       "   np.float64(9.018000000000002),\n",
       "   np.float64(9.0),\n",
       "   np.float64(6.533999999999998),\n",
       "   np.float64(10.908000000000003),\n",
       "   np.float64(10.944000000000003),\n",
       "   np.float64(6.588),\n",
       "   np.float64(10.764000000000001),\n",
       "   np.float64(9.809999999999999),\n",
       "   np.float64(9.647999999999998),\n",
       "   np.float64(9.702),\n",
       "   np.float64(9.594000000000003),\n",
       "   np.float64(8.316)],\n",
       "  'mean_T_VPT': 9.2836,\n",
       "  'std_T_VPT': 1.1477431071454975}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_grid_search(GliaNeuronTripartiteReservoirESN, grid, \"GliaNeuronTripartiteReservoir\", output_path=\"GLIA.json\", f=generate_lorenz_data, lambda_max=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
