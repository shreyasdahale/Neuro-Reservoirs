{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2a722d1",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e605f985",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.integrate import odeint\n",
    "from sklearn.linear_model import Ridge\n",
    "from matplotlib.colors import Normalize\n",
    "import networkx as nx\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "from scipy.signal import welch\n",
    "import matplotlib.cm as cm\n",
    "import seaborn as sns\n",
    "from collections import defaultdict\n",
    "from sklearn.decomposition import PCA\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ac8933",
   "metadata": {},
   "source": [
    "# Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf80a9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_spectral_radius(W, target_radius=0.95):\n",
    "    \"\"\"\n",
    "    Scales a matrix W so that its largest eigenvalue magnitude = target_radius.\n",
    "    \"\"\"\n",
    "    eigvals = np.linalg.eigvals(W)\n",
    "    radius = np.max(np.abs(eigvals))\n",
    "    if radius == 0:\n",
    "        return W\n",
    "    return (W / radius) * target_radius\n",
    "\n",
    "def augment_state_with_squares(x):\n",
    "    \"\"\"\n",
    "    Given state vector x in R^N, return [ x, x^2, 1 ] in R^(2N+1).\n",
    "    We'll use this for both training and prediction.\n",
    "    \"\"\"\n",
    "    x_sq = x**2\n",
    "    return np.concatenate([x, x_sq, [1.0]])  # shape: 2N+1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4741c6",
   "metadata": {},
   "source": [
    "# HHLR [v1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "817c595b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import Ridge\n",
    "from numpy.linalg import eigvals\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Utility helpers\n",
    "# ---------------------------------------------------------------------\n",
    "def scale_spectral_radius(W, desired_radius=0.95):\n",
    "    \"\"\"Affine-scale square matrix W so that its spectral radius equals desired_radius.\"\"\"\n",
    "    eigs = eigvals(W)\n",
    "    current_radius = np.max(np.abs(eigs))\n",
    "    if current_radius == 0:\n",
    "        raise ValueError(\"Spectral radius of W is zero.\")\n",
    "    return W * (desired_radius / current_radius)\n",
    "\n",
    "def augment_state_with_squares(x):\n",
    "    \"\"\"[x, x^2, 1]   (same convention as in CycleReservoir3D).\"\"\"\n",
    "    return np.concatenate([x, x**2, [1.0]])\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# HH-LR class\n",
    "# ---------------------------------------------------------------------\n",
    "class HHLobeReservoir:\n",
    "    \"\"\"\n",
    "    Hemispherically-Hierarchical Lobe Reservoir (HH-LR).\n",
    "\n",
    "    Topology:\n",
    "      * 8 anatomical modules  —  L/R × {F, P, T, O}\n",
    "      * Intra-module: Watts–Strogatz small-world graphs (ring+rewire)\n",
    "      * Intra-hemisphere inter-lobe: distance-modulated shortcuts\n",
    "      * Inter-hemisphere (callosal): sparse homotopic bridges\n",
    "    \"\"\"\n",
    "\n",
    "    # --- anatomical bookkeeping -------------------------------------------------\n",
    "    _LOBES   = ['F', 'P', 'T', 'O']\n",
    "    _HEMIS   = ['L', 'R']\n",
    "    # rough 2-D centroids (arbitrary units) for distance computation\n",
    "    _CENTROIDS = {\n",
    "        ('L', 'F'): (-1.0,  1.0),\n",
    "        ('L', 'P'): (-1.0,  0.0),\n",
    "        ('L', 'T'): (-1.0, -1.0),\n",
    "        ('L', 'O'): (-1.0, -2.0),\n",
    "        ('R', 'F'): ( 1.0,  1.0),\n",
    "        ('R', 'P'): ( 1.0,  0.0),\n",
    "        ('R', 'T'): ( 1.0, -1.0),\n",
    "        ('R', 'O'): ( 1.0, -2.0),\n",
    "    }\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    def __init__(self,\n",
    "                 reservoir_size=800,\n",
    "                 input_dim=128,\n",
    "                 spectral_radius=0.9,\n",
    "                 input_scale=1.0,\n",
    "                 leaking_rate=1.0,\n",
    "                 ridge_alpha=1e-6,\n",
    "                 # small-world / shortcut hyper-parameters\n",
    "                 k_ring=8,\n",
    "                 p_rewire_frontal=0.30,\n",
    "                 p_rewire_other=0.10,\n",
    "                 P_lat=0.04,\n",
    "                 sigma=5.0,\n",
    "                 P_call=0.01,\n",
    "                 seed=42):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        reservoir_size   : total neuron count (split equally across the 8 modules if not divisible)\n",
    "        input_dim        : dimensionality of input vector u_t  (128 for EEG band-power features)\n",
    "        leaking_rate     : α in leaky-integrator update\n",
    "        \"\"\"\n",
    "        self.N     = reservoir_size\n",
    "        self.D_in  = input_dim\n",
    "        self.rho   = spectral_radius\n",
    "        self.in_scale   = input_scale\n",
    "        self.alpha = leaking_rate\n",
    "        self.ridge_alpha = ridge_alpha\n",
    "        self.seed  = seed\n",
    "\n",
    "        # ------------------------------------------------------------------\n",
    "        # 1) allocate neurons to the 8 modules as evenly as possible\n",
    "        # ------------------------------------------------------------------\n",
    "        base = self.N // 8\n",
    "        counts = [base] * 8\n",
    "        for i in range(self.N - base*8):\n",
    "            counts[i] += 1\n",
    "        self._module_slices = {}\n",
    "        idx0 = 0\n",
    "        for h in self._HEMIS:\n",
    "            for l in self._LOBES:\n",
    "                n = counts[len(self._module_slices)]\n",
    "                self._module_slices[(h, l)] = slice(idx0, idx0 + n)\n",
    "                idx0 += n\n",
    "\n",
    "        # ------------------------------------------------------------------\n",
    "        # 2) build adjacency matrix W according to HH-LR rules\n",
    "        # ------------------------------------------------------------------\n",
    "        rng = np.random.default_rng(self.seed)\n",
    "        W = np.zeros((self.N, self.N), dtype=float)\n",
    "\n",
    "        # 2.1 intra-module small-world wiring\n",
    "        for (h, l), sl in self._module_slices.items():\n",
    "            n_mod = sl.stop - sl.start\n",
    "            k = min(k_ring, n_mod-1)  # guard tiny modules\n",
    "            p_rewire = p_rewire_frontal if l == 'F' else p_rewire_other\n",
    "            # ring lattice\n",
    "            for i_local in range(n_mod):\n",
    "                for m in range(1, k+1):\n",
    "                    j_local = (i_local + m) % n_mod\n",
    "                    i_glob = sl.start + i_local\n",
    "                    j_glob = sl.start + j_local\n",
    "                    W[i_glob, j_glob] = rng.standard_normal()\n",
    "                    W[j_glob, i_glob] = rng.standard_normal()\n",
    "            # rewire each existing edge with prob p_rewire\n",
    "            for i_local in range(n_mod):\n",
    "                for m in range(1, k+1):\n",
    "                    if rng.random() < p_rewire:\n",
    "                        # pick a random new target in same module (avoid self-loop)\n",
    "                        j_local_new = rng.integers(0, n_mod-1)\n",
    "                        if j_local_new >= i_local:\n",
    "                            j_local_new += 1\n",
    "                        i_glob = sl.start + i_local\n",
    "                        j_glob_new = sl.start + j_local_new\n",
    "                        # overwrite previous weight (both directions)\n",
    "                        w_new = rng.standard_normal()\n",
    "                        W[i_glob, j_glob_new] = w_new\n",
    "                        W[j_glob_new, i_glob] = rng.standard_normal()\n",
    "\n",
    "        # 2.2 intra-hemisphere inter-lobe shortcuts (distance-weighted)\n",
    "        for h in self._HEMIS:\n",
    "            for l1 in self._LOBES:\n",
    "                for l2 in self._LOBES:\n",
    "                    if l1 == l2:\n",
    "                        continue\n",
    "                    sl1 = self._module_slices[(h, l1)]\n",
    "                    sl2 = self._module_slices[(h, l2)]\n",
    "                    c1 = np.array(self._CENTROIDS[(h, l1)])\n",
    "                    c2 = np.array(self._CENTROIDS[(h, l2)])\n",
    "                    dist = np.linalg.norm(c1 - c2)\n",
    "                    p_edge = P_lat * np.exp(-dist / sigma)\n",
    "                    for i in range(sl1.start, sl1.stop):\n",
    "                        mask = rng.random(sl2.stop - sl2.start) < p_edge\n",
    "                        js = np.nonzero(mask)[0] + sl2.start\n",
    "                        if js.size:\n",
    "                            W[i, js] = rng.standard_normal(size=js.size)\n",
    "                            W[js, i] = rng.standard_normal(size=js.size)\n",
    "\n",
    "        # 2.3 inter-hemisphere callosal bridges (homotopic)\n",
    "        for l in self._LOBES:\n",
    "            sl_L = self._module_slices[('L', l)]\n",
    "            sl_R = self._module_slices[('R', l)]\n",
    "            for i in range(sl_L.start, sl_L.stop):\n",
    "                mask = rng.random(sl_R.stop - sl_R.start) < P_call\n",
    "                js = np.nonzero(mask)[0] + sl_R.start\n",
    "                if js.size:\n",
    "                    W[i, js] = rng.standard_normal(size=js.size)\n",
    "                    W[js, i] = rng.standard_normal(size=js.size)\n",
    "\n",
    "        # 2.4 spectral scaling\n",
    "        W = scale_spectral_radius(W, self.rho)\n",
    "        self.W = W\n",
    "\n",
    "        # ------------------------------------------------------------------\n",
    "        # 3) random input weights\n",
    "        # ------------------------------------------------------------------\n",
    "        rng = np.random.default_rng(self.seed + 1)\n",
    "        self.W_in = (rng.random((self.N, self.D_in)) - 0.5) * 2.0 * self.in_scale\n",
    "\n",
    "        # readout and state\n",
    "        self.W_out = None\n",
    "        self.x = np.zeros(self.N)\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # ESN core methods (same signatures as CycleReservoir3D)\n",
    "    # ------------------------------------------------------------------\n",
    "    def reset_state(self):\n",
    "        self.x = np.zeros(self.N)\n",
    "\n",
    "    def _update(self, u):\n",
    "        pre_activation = self.W @ self.x + self.W_in @ u\n",
    "        x_new = np.tanh(pre_activation)\n",
    "        self.x = (1.0 - self.alpha) * self.x + self.alpha * x_new\n",
    "\n",
    "    def collect_states(self, inputs, discard=100):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        inputs  : iterable / array of shape (T, input_dim)\n",
    "        discard : number of initial time-steps to omit from training\n",
    "        \"\"\"\n",
    "        self.reset_state()\n",
    "        states = []\n",
    "        for u in inputs:\n",
    "            self._update(u)\n",
    "            states.append(self.x.copy())\n",
    "        return np.array(states[discard:]), np.array(states[:discard])\n",
    "\n",
    "    def fit_readout(self, train_input, train_target, discard=100):\n",
    "        \"\"\"\n",
    "        Ridge regression read-out; identical augmentation as baseline.\n",
    "        \"\"\"\n",
    "        states_use, _ = self.collect_states(train_input, discard=discard)\n",
    "        targets_use = train_target[discard:]\n",
    "        X_aug = np.vstack([augment_state_with_squares(s) for s in states_use])\n",
    "\n",
    "        reg = Ridge(alpha=self.ridge_alpha, fit_intercept=False)\n",
    "        reg.fit(X_aug, targets_use)\n",
    "        self.W_out = reg.coef_\n",
    "\n",
    "    def predict_sequence(self, inputs):\n",
    "        \"\"\"\n",
    "        Feed-forward prediction (no teacher forcing).  Suitable for classification:\n",
    "        returns raw linear outputs; apply threshold/sigmoid externally.\n",
    "        \"\"\"\n",
    "        preds = []\n",
    "        self.reset_state()\n",
    "        for u in inputs:\n",
    "            self._update(u)\n",
    "            preds.append(self.W_out @ augment_state_with_squares(self.x)) # quadratic lift-off\n",
    "            #preds.append(self.W_out @ self.x)\n",
    "        return np.array(preds)\n",
    "    \n",
    "    def predict_autoregressive(self, initial_input, n_steps):\n",
    "        preds = []\n",
    "        current_in = np.array(initial_input)\n",
    "        for _ in range(n_steps):\n",
    "            self._update(current_in)\n",
    "            out = self.W_out @ augment_state_with_squares(self.x)\n",
    "            preds.append(out)\n",
    "            current_in = out\n",
    "        return np.array(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587f6038",
   "metadata": {},
   "source": [
    "### NRMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b55e0383",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_nrmse(all_preds, test_target, horizons):\n",
    "    \"\"\"\n",
    "    Evaluate model performance over multiple prediction horizons\n",
    "    for teacher-forced single-step forecasting or autoregressive rollout.\n",
    "    \"\"\"\n",
    "    horizon_nrmse = {}\n",
    "    for horizon in horizons:\n",
    "        preds = all_preds[:horizon]\n",
    "        targets = test_target[:horizon]\n",
    "        squared_errors = (preds - targets) ** 2\n",
    "        variance = np.var(targets, axis=0)\n",
    "        variance[variance == 0] = 1e-8  # avoid divide-by-zero\n",
    "        nrmse = np.sqrt(np.sum(squared_errors) / (horizon * np.sum(variance)))\n",
    "        horizon_nrmse[horizon] = nrmse\n",
    "    return horizon_nrmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb9a21c",
   "metadata": {},
   "source": [
    "### VPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "193a03f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_valid_prediction_time(y_true, y_pred, test_time, lyapunov_time, threshold=0.4):\n",
    "    y_mean = np.mean(y_true, axis=0)\n",
    "    y_centered = y_true - y_mean\n",
    "    denom = np.mean(np.sum(y_centered**2, axis=1))\n",
    "\n",
    "    error = y_true - y_pred\n",
    "    squared_error = np.sum(error**2, axis=1)\n",
    "    delta = squared_error / denom\n",
    "\n",
    "    idx_exceed = np.where(delta > threshold)[0]\n",
    "    if len(idx_exceed) == 0:\n",
    "        # never exceeds threshold => set T_VPT to the final time\n",
    "        T_VPT = test_time[-1]\n",
    "    else:\n",
    "        T_VPT = test_time[idx_exceed[0]]\n",
    "\n",
    "    ratio = T_VPT / lyapunov_time\n",
    "\n",
    "    return T_VPT, ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4e8e78",
   "metadata": {},
   "source": [
    "### ADev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38f84534",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_attractor_deviation(predictions, targets, cube_size=(0.1, 0.1, 0.1)):\n",
    "    \"\"\"\n",
    "    Compute the Attractor Deviation (ADev) metric.\n",
    "\n",
    "    Parameters:\n",
    "        predictions (numpy.ndarray): Predicted trajectories of shape (n, 3).\n",
    "        targets (numpy.ndarray): True trajectories of shape (n, 3).\n",
    "        cube_size (tuple): Dimensions of the cube (dx, dy, dz).\n",
    "\n",
    "    Returns:\n",
    "        float: The ADev metric.\n",
    "    \"\"\"\n",
    "    # Define the cube grid based on the range of the data and cube size\n",
    "    min_coords = np.min(np.vstack((predictions, targets)), axis=0)\n",
    "    max_coords = np.max(np.vstack((predictions, targets)), axis=0)\n",
    "\n",
    "    # Create a grid of cubes\n",
    "    grid_shape = ((max_coords - min_coords) / cube_size).astype(int) + 1\n",
    "\n",
    "    # Initialize the cube occupancy arrays\n",
    "    pred_cubes = np.zeros(grid_shape, dtype=int)\n",
    "    target_cubes = np.zeros(grid_shape, dtype=int)\n",
    "\n",
    "    # Map trajectories to cubes\n",
    "    pred_indices = ((predictions - min_coords) / cube_size).astype(int)\n",
    "    target_indices = ((targets - min_coords) / cube_size).astype(int)\n",
    "\n",
    "    # Mark cubes visited by predictions and targets\n",
    "    for idx in pred_indices:\n",
    "        pred_cubes[tuple(idx)] = 1\n",
    "    for idx in target_indices:\n",
    "        target_cubes[tuple(idx)] = 1\n",
    "\n",
    "    # Compute the ADev metric\n",
    "    adev = np.sum(np.abs(pred_cubes - target_cubes))\n",
    "    return adev"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825c2de7",
   "metadata": {},
   "source": [
    "### PSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "402a5c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_psd(y, dt=0.01):\n",
    "    z = y[:, 2]  # Extract Z-component\n",
    "    \n",
    "    # Compute PSD using Welch’s method\n",
    "    freqs, psd = welch(z, fs=1/dt, window='hamming', nperseg=len(z))  # Using Hamming window\n",
    "    \n",
    "    return freqs, psd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8719c3c",
   "metadata": {},
   "source": [
    "# MIT-BIH Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "49bbfe54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_delay_embedding(signal, embed_dim):\n",
    "    L = len(signal) - embed_dim + 1\n",
    "    emb = np.zeros((L, embed_dim))\n",
    "    for i in range(L):\n",
    "        emb[i, :] = signal[i:i+embed_dim]\n",
    "    return emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "54b46a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wfdb\n",
    "\n",
    "# Download and load record and annotations for patient #100\n",
    "record = wfdb.rdrecord('100', sampfrom=0, sampto=25002, pn_dir='mitdb')  # first 20,000 samples\n",
    "annotation = wfdb.rdann('100', 'atr', sampfrom=0, sampto=25002, pn_dir='mitdb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "7a0e8cf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.145, -0.145, -0.145, ..., -0.41 , -0.415, -0.425],\n",
       "      shape=(25002,))"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get input signal u(t) from the first channel\n",
    "u = record.p_signal[:, 0] \n",
    "u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "93538ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize input\n",
    "u_min = np.min(u)\n",
    "u_max = np.max(u)\n",
    "u_norm = (u - u_min) / (u_max - u_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "6dfcd0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = record.fs  # sampling frequency (should be 360 Hz)\n",
    "t_vals = np.arange(len(u_norm)) / fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "ef734865",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_dim = 3\n",
    "# inputs = u_norm\n",
    "inputs = create_delay_embedding(u_norm, emb_dim)\n",
    "\n",
    "# Create target array (heartbeat locations)\n",
    "targets = np.zeros(len(u_norm))\n",
    "targets[annotation.sample] = 1  # mark annotations as 1 (heartbeat)\n",
    "targets = create_delay_embedding(targets, emb_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "938389fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 25000, train size: 15000, test size: 9999\n"
     ]
    }
   ],
   "source": [
    "data_size = len(inputs)\n",
    "train_size = 15000\n",
    "train_input = inputs[:train_size]\n",
    "train_target = targets[:train_size]\n",
    "test_input = inputs[train_size+1:]\n",
    "test_target = targets[train_size+1:]\n",
    "test_size = len(test_input)\n",
    "print(f\"Total samples: {data_size}, train size: {train_size}, test size: {test_size}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "8231544e",
   "metadata": {},
   "outputs": [],
   "source": [
    "horizons = [300, 600, 1000]\n",
    "\n",
    "nrmse_dict = defaultdict(list)\n",
    "seeds = range(995, 1025)\n",
    "\n",
    "for seed in seeds:\n",
    "    hhlr = HHLobeReservoir(\n",
    "        reservoir_size=500,\n",
    "        input_dim=emb_dim,\n",
    "        spectral_radius=0.0001,\n",
    "        input_scale=1.5,\n",
    "        leaking_rate=0.9,\n",
    "        ridge_alpha=1e-08,\n",
    "        k_ring=6,\n",
    "        p_rewire_frontal=0.30,\n",
    "        p_rewire_other=0.10,\n",
    "        P_lat=0.04,\n",
    "        sigma=5.0,\n",
    "        P_call=0.01,\n",
    "        seed=seed\n",
    "    )\n",
    "    hhlr.fit_readout(train_input, train_target, discard=5000)\n",
    "    hhlr_preds = hhlr.predict_sequence(test_input)\n",
    "    hhlr_nrmse = evaluate_nrmse(hhlr_preds, test_target, horizons)\n",
    "    nrmse_dict['HHLR'].append(hhlr_nrmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "337c012a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NRMSE for Different Prediction Horizons:\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "HHLR             \n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "300        0.2677566717347884 ± 0.006063637930798729\n",
      "600        0.3155822163726197 ± 0.004610418356072609\n",
      "1000       0.4394767105225158 ± 0.004610194160673745\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nNRMSE for Different Prediction Horizons:\")\n",
    "print(\"-\" * 140)\n",
    "print(f\"{'HHLR':<17}\")\n",
    "print(\"-\" * 140)\n",
    "\n",
    "for horizon in horizons:\n",
    "    hhlr_vals = [np.mean(hhlr_nrmse[horizon]) for hhlr_nrmse in nrmse_dict['HHLR']]\n",
    "\n",
    "    print(f\"{horizon:<10}\", end=\" \")\n",
    "    for vals in [hhlr_vals]:\n",
    "        mean = np.mean(vals)\n",
    "        std = np.std(vals)\n",
    "        print(f\"{mean} ± {std}\".ljust(18), end=\"\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39c1e20",
   "metadata": {},
   "source": [
    "# Sunspot Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3232502c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1749</td>\n",
       "      <td>1</td>\n",
       "      <td>1749.042</td>\n",
       "      <td>96.7</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1749</td>\n",
       "      <td>2</td>\n",
       "      <td>1749.123</td>\n",
       "      <td>104.3</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1749</td>\n",
       "      <td>3</td>\n",
       "      <td>1749.204</td>\n",
       "      <td>116.7</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1749</td>\n",
       "      <td>4</td>\n",
       "      <td>1749.288</td>\n",
       "      <td>92.8</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1749</td>\n",
       "      <td>5</td>\n",
       "      <td>1749.371</td>\n",
       "      <td>141.7</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3310</th>\n",
       "      <td>2024</td>\n",
       "      <td>11</td>\n",
       "      <td>2024.873</td>\n",
       "      <td>152.5</td>\n",
       "      <td>20.9</td>\n",
       "      <td>681</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3311</th>\n",
       "      <td>2024</td>\n",
       "      <td>12</td>\n",
       "      <td>2024.958</td>\n",
       "      <td>154.5</td>\n",
       "      <td>25.6</td>\n",
       "      <td>572</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3312</th>\n",
       "      <td>2025</td>\n",
       "      <td>1</td>\n",
       "      <td>2025.042</td>\n",
       "      <td>137.0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>670</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3313</th>\n",
       "      <td>2025</td>\n",
       "      <td>2</td>\n",
       "      <td>2025.122</td>\n",
       "      <td>154.6</td>\n",
       "      <td>23.3</td>\n",
       "      <td>655</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3314</th>\n",
       "      <td>2025</td>\n",
       "      <td>3</td>\n",
       "      <td>2025.204</td>\n",
       "      <td>134.2</td>\n",
       "      <td>20.4</td>\n",
       "      <td>1011</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3315 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0   1         2      3     4     5  6\n",
       "0     1749   1  1749.042   96.7  -1.0    -1  1\n",
       "1     1749   2  1749.123  104.3  -1.0    -1  1\n",
       "2     1749   3  1749.204  116.7  -1.0    -1  1\n",
       "3     1749   4  1749.288   92.8  -1.0    -1  1\n",
       "4     1749   5  1749.371  141.7  -1.0    -1  1\n",
       "...    ...  ..       ...    ...   ...   ... ..\n",
       "3310  2024  11  2024.873  152.5  20.9   681  0\n",
       "3311  2024  12  2024.958  154.5  25.6   572  0\n",
       "3312  2025   1  2025.042  137.0  23.3   670  0\n",
       "3313  2025   2  2025.122  154.6  23.3   655  0\n",
       "3314  2025   3  2025.204  134.2  20.4  1011  0\n",
       "\n",
       "[3315 rows x 7 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "file_path = 'RealWorld/datasets/SN_m_tot_V2.0.csv'\n",
    "\n",
    "df = pd.read_csv(file_path, sep=';', header = None)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "98f8602b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 3315\n",
      "Train size: 2000\n",
      "Test size: 1312\n"
     ]
    }
   ],
   "source": [
    "data = df.iloc[:, 3].values\n",
    "dt = 1\n",
    "dataset_size = len(data)\n",
    "data = create_delay_embedding(data, 3)\n",
    "print(f\"Dataset size: {dataset_size}\")\n",
    "\n",
    "# Train/Test Split\n",
    "train_end = 2000\n",
    "train_input  = data[:train_end]\n",
    "train_target = data[1:train_end+1]\n",
    "test_input   = data[train_end:-1]\n",
    "test_target  = data[train_end+1:]\n",
    "y_test = test_target\n",
    "n_test_steps = len(test_target)\n",
    "time_test = np.arange(n_test_steps) * dt\n",
    "\n",
    "print(f\"Train size: {len(train_input)}\\nTest size: {len(test_input)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c7684b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "horizons = [300, 600, 1000]\n",
    "\n",
    "nrmse_dict = defaultdict(list)\n",
    "seeds = range(995, 1025)\n",
    "\n",
    "for seed in seeds:\n",
    "    hhlr = HHLobeReservoir(\n",
    "        reservoir_size=500,\n",
    "        input_dim=emb_dim,\n",
    "        spectral_radius=0.1,\n",
    "        input_scale=0.000001,\n",
    "        leaking_rate=0.9,\n",
    "        ridge_alpha=1e-08,\n",
    "        k_ring=6,\n",
    "        p_rewire_frontal=0.30,\n",
    "        p_rewire_other=0.10,\n",
    "        P_lat=0.04,\n",
    "        sigma=5.0,\n",
    "        P_call=0.01,\n",
    "        seed=seed\n",
    "    )\n",
    "    hhlr.fit_readout(train_input, train_target, discard=100)\n",
    "    hhlr_preds = hhlr.predict_sequence(test_input)\n",
    "    hhlr_nrmse = evaluate_nrmse(hhlr_preds, test_target, horizons)\n",
    "    nrmse_dict['HHLR'].append(hhlr_nrmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "daaef00f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NRMSE for Different Prediction Horizons:\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "HHLR             \n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "300        0.2518938299029971 ± 5.0188758236031255e-05\n",
      "600        0.20408723950118077 ± 3.8554511582339564e-05\n",
      "1000       0.2025080720350752 ± 2.9866115555249395e-05\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nNRMSE for Different Prediction Horizons:\")\n",
    "print(\"-\" * 140)\n",
    "print(f\"{'HHLR':<17}\")\n",
    "print(\"-\" * 140)\n",
    "\n",
    "for horizon in horizons:\n",
    "    hhlr_vals = [np.mean(hhlr_nrmse[horizon]) for hhlr_nrmse in nrmse_dict['HHLR']]\n",
    "\n",
    "    print(f\"{horizon:<10}\", end=\" \")\n",
    "    for vals in [hhlr_vals]:\n",
    "        mean = np.mean(vals)\n",
    "        std = np.std(vals)\n",
    "        print(f\"{mean} ± {std}\".ljust(18), end=\"\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e6ee32",
   "metadata": {},
   "source": [
    "# Sante Fe Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "2407cfd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>76.53</td>\n",
       "      <td>8320</td>\n",
       "      <td>7771</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>76.53</td>\n",
       "      <td>8117</td>\n",
       "      <td>7774</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>76.15</td>\n",
       "      <td>7620</td>\n",
       "      <td>7788</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>75.39</td>\n",
       "      <td>6413</td>\n",
       "      <td>7787</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75.51</td>\n",
       "      <td>7518</td>\n",
       "      <td>7767</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16995</th>\n",
       "      <td>73.57</td>\n",
       "      <td>16021</td>\n",
       "      <td>6498</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16996</th>\n",
       "      <td>73.79</td>\n",
       "      <td>-6957</td>\n",
       "      <td>6547</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16997</th>\n",
       "      <td>74.54</td>\n",
       "      <td>11476</td>\n",
       "      <td>6576</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16998</th>\n",
       "      <td>74.36</td>\n",
       "      <td>15058</td>\n",
       "      <td>6573</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16999</th>\n",
       "      <td>72.91</td>\n",
       "      <td>13510</td>\n",
       "      <td>6676</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0      1     2   3\n",
       "0      76.53   8320  7771 NaN\n",
       "1      76.53   8117  7774 NaN\n",
       "2      76.15   7620  7788 NaN\n",
       "3      75.39   6413  7787 NaN\n",
       "4      75.51   7518  7767 NaN\n",
       "...      ...    ...   ...  ..\n",
       "16995  73.57  16021  6498 NaN\n",
       "16996  73.79  -6957  6547 NaN\n",
       "16997  74.54  11476  6576 NaN\n",
       "16998  74.36  15058  6573 NaN\n",
       "16999  72.91  13510  6676 NaN\n",
       "\n",
       "[17000 rows x 4 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = 'RealWorld/datasets/santa-fe-time-series-competition-data-set-b-1.0.0/b1.txt'\n",
    "\n",
    "df = pd.read_csv(file_path, header=None, sep=' ')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b5624624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the first column (column 0) of the DataFrame\n",
    "df[0] = (df[0] - df[0].min()) / (df[0].max() - df[0].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ae5bf803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data length: 17000.\n",
      "Train size: 7000  \n",
      "Test size: 9997\n"
     ]
    }
   ],
   "source": [
    "data = df.iloc[:, 0].values\n",
    "chosen_system = \"SantaFe\"\n",
    "dt = 1\n",
    "T_data = len(data)\n",
    "data = create_delay_embedding(data, 3)\n",
    "print(f\"Data length: {T_data}.\")\n",
    "\n",
    "# Train/Test Split\n",
    "train_end = 7000\n",
    "train_input  = data[:train_end]\n",
    "train_target = data[1:train_end+1]\n",
    "test_input   = data[train_end:-1]\n",
    "test_target  = data[train_end+1:]\n",
    "y_test = test_target\n",
    "n_test_steps = len(test_target)\n",
    "time_test = np.arange(n_test_steps) * dt\n",
    "\n",
    "print(f\"Train size: {len(train_input)}  \\nTest size: {len(test_input)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "5900d956",
   "metadata": {},
   "outputs": [],
   "source": [
    "horizons = [300, 600, 1000]\n",
    "\n",
    "nrmse_dict = defaultdict(list)\n",
    "seeds = range(995, 1025)\n",
    "\n",
    "for seed in seeds:\n",
    "    hhlr = HHLobeReservoir(\n",
    "        reservoir_size=500,\n",
    "        input_dim=emb_dim,\n",
    "        spectral_radius=0.1,\n",
    "        input_scale=0.001,\n",
    "        leaking_rate=0.9,\n",
    "        ridge_alpha=1e-08,\n",
    "        k_ring=6,\n",
    "        p_rewire_frontal=0.30,\n",
    "        p_rewire_other=0.10,\n",
    "        P_lat=0.04,\n",
    "        sigma=5.0,\n",
    "        P_call=0.01,\n",
    "        seed=seed\n",
    "    )\n",
    "    hhlr.fit_readout(train_input, train_target, discard=100)\n",
    "    hhlr_preds = hhlr.predict_sequence(test_input)\n",
    "    hhlr_nrmse = evaluate_nrmse(hhlr_preds, test_target, horizons)\n",
    "    nrmse_dict['HHLR'].append(hhlr_nrmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "afd4e124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NRMSE for Different Prediction Horizons:\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "HHLR             \n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "300        0.1625942273766201 ± 0.0015864192947001516\n",
      "600        0.13326051267076544 ± 0.000407011178925061\n",
      "1000       0.14440468459939237 ± 0.00031377393089875933\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nNRMSE for Different Prediction Horizons:\")\n",
    "print(\"-\" * 140)\n",
    "print(f\"{'HHLR':<17}\")\n",
    "print(\"-\" * 140)\n",
    "\n",
    "for horizon in horizons:\n",
    "    hhlr_vals = [np.mean(hhlr_nrmse[horizon]) for hhlr_nrmse in nrmse_dict['HHLR']]\n",
    "\n",
    "    print(f\"{horizon:<10}\", end=\" \")\n",
    "    for vals in [hhlr_vals]:\n",
    "        mean = np.mean(vals)\n",
    "        std = np.std(vals)\n",
    "        print(f\"{mean} ± {std}\".ljust(18), end=\"\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b69b157",
   "metadata": {},
   "source": [
    "# BCI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe19f3ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading: datasets/BCI_Competion4_dataset4\\sub1_comp.mat\n",
      "Available keys in .mat file: dict_keys(['__header__', '__version__', '__globals__', 'train_data', 'test_data', 'train_dg'])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data_dir = 'datasets/BCI_Competion4_dataset4'\n",
    "\n",
    "mat_files = [f for f in os.listdir(data_dir) if f.lower().endswith('.mat')]\n",
    "if not mat_files:\n",
    "    raise FileNotFoundError(f'No .mat files found in {data_dir}')\n",
    "mat_path = os.path.join(data_dir, mat_files[0])\n",
    "print(\"Loading:\", mat_path)\n",
    "\n",
    "# ─── Load the data ────────────────────────────────────────────────────────\n",
    "data = sio.loadmat(mat_path)\n",
    "print(\"Available keys in .mat file:\", data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77d93b32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (15000, 62)    (timepoints × channels)\n",
      "Y_train shape:  (15000, 5)    (timepoints × fingers)\n",
      "X_test shape:   (5000, 62)     (timepoints × channels)\n",
      "Y_test shape:   (5000, 5)     (timepoints × fingers)\n"
     ]
    }
   ],
   "source": [
    "N_train = 15000\n",
    "N_test  = 5000\n",
    "\n",
    "# ─── Load both the “comp” and “testlabels” .mat files ─────────────────────────\n",
    "comp_path       = os.path.join(data_dir, 'sub1_comp.mat')\n",
    "testlabels_path = os.path.join(data_dir, 'sub1_testlabels.mat')\n",
    "\n",
    "comp_data     = sio.loadmat(comp_path)\n",
    "testlabels    = sio.loadmat(testlabels_path)\n",
    "\n",
    "# ─── Extract arrays ───────────────────────────────────────────────────────────\n",
    "# From sub1_comp.mat:\n",
    "X_train = comp_data['train_data']   # ECoG: (timepoints × channels)\n",
    "Y_train = comp_data['train_dg']     # Finger flexions: (timepoints × 5)\n",
    "\n",
    "X_test  = comp_data['test_data']    # ECoG test inputs: (timepoints × channels)\n",
    "\n",
    "# From sub1_testlabels.mat:\n",
    "Y_test  = testlabels['test_dg']     # True flexions for X_test: (timepoints × 5)\n",
    "\n",
    "\n",
    "X_train = X_train[:N_train]\n",
    "Y_train = Y_train[:N_train]\n",
    "X_test  = X_test[:N_test]\n",
    "Y_test  = Y_test[:N_test]\n",
    "\n",
    "# ─── Print dimensions ───────────────────────────────────────────────────────\n",
    "print(f\"X_train shape:  {X_train.shape}    (timepoints × channels)\")\n",
    "print(f\"Y_train shape:  {Y_train.shape}    (timepoints × fingers)\")\n",
    "print(f\"X_test shape:   {X_test.shape}     (timepoints × channels)\")\n",
    "print(f\"Y_test shape:   {Y_test.shape}     (timepoints × fingers)\")\n",
    "\n",
    "# ─── Time vector ─────────────────────────────────────────────────────────────\n",
    "fs = 1000.0\n",
    "t_train = np.arange(X_train.shape[0]) / fs\n",
    "t_test  = np.arange(X_test.shape[0])  / fs\n",
    "\n",
    "# # ─── Plot first 5 channels of TRAINING ECoG (first 2 s) ────────────────────\n",
    "# plt.figure(figsize=(12,6))\n",
    "# for ch in range(min(5, X_train.shape[1])):\n",
    "#     plt.plot(t_train[:2000], X_train[:2000, ch] + ch*200, label=f'Ch {ch+1}')\n",
    "# plt.xlabel('Time (s)')\n",
    "# plt.ylabel('Amplitude + offset')\n",
    "# plt.title('Train: First 5 ECoG Channels (first 2 s)')\n",
    "# plt.legend(loc='upper right')\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "# # ─── Plot TRAINING finger flexions (first 2 s) ─────────────────────────────\n",
    "# plt.figure(figsize=(12,4))\n",
    "# for f in range(Y_train.shape[1]):\n",
    "#     plt.plot(t_train[:2000], Y_train[:2000, f], label=f'Finger {f+1}')\n",
    "# plt.xlabel('Time (s)')\n",
    "# plt.ylabel('Flexion signal')\n",
    "# plt.title('Train: Finger Flexion Trajectories (first 2 s)')\n",
    "# plt.legend(loc='upper right')\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "all_horizons = list(range(10, 1001, 10))\n",
    "horizons = [300, 600, 1000]\n",
    "\n",
    "\n",
    "nrmse_dict = defaultdict(list)\n",
    "seeds = range(995, 1025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "35f479a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "horizons = [300, 600, 1000]\n",
    "\n",
    "nrmse_dict = defaultdict(list)\n",
    "seeds = range(995, 1025)\n",
    "\n",
    "for seed in seeds:\n",
    "    hhlr = HHLobeReservoir(\n",
    "        reservoir_size=500,\n",
    "        input_dim=62,\n",
    "        spectral_radius=0.1,\n",
    "        input_scale=0.001,\n",
    "        leaking_rate=0.9,\n",
    "        ridge_alpha=1e-08,\n",
    "        k_ring=6,\n",
    "        p_rewire_frontal=0.30,\n",
    "        p_rewire_other=0.10,\n",
    "        P_lat=0.04,\n",
    "        sigma=5.0,\n",
    "        P_call=0.01,\n",
    "        seed=seed\n",
    "    )\n",
    "    hhlr.fit_readout(X_train, Y_train, discard=100)\n",
    "    hhlr_preds = hhlr.predict_sequence(X_test)\n",
    "    hhlr_nrmse = evaluate_nrmse(hhlr_preds, Y_test, horizons)\n",
    "    nrmse_dict['HHLR[v1]'].append(hhlr_nrmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ed1a357d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NRMSE for Different Prediction Horizons:\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "HHLR             \n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "300        2.3318243328816948 ± 0.20856790431182595\n",
      "600        1.5775198521492597 ± 0.10146909837309058\n",
      "1000       1.726268533453933 ± 0.08755785187646534\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nNRMSE for Different Prediction Horizons:\")\n",
    "print(\"-\" * 140)\n",
    "print(f\"{'HHLR':<17}\")\n",
    "print(\"-\" * 140)\n",
    "\n",
    "for horizon in horizons:\n",
    "    hhlr_vals = [np.mean(hhlr_nrmse[horizon]) for hhlr_nrmse in nrmse_dict['HHLR[v1]']]\n",
    "\n",
    "    print(f\"{horizon:<10}\", end=\" \")\n",
    "    for vals in [hhlr_vals]:\n",
    "        mean = np.mean(vals)\n",
    "        std = np.std(vals)\n",
    "        print(f\"{mean} ± {std}\".ljust(18), end=\"\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11af2f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
