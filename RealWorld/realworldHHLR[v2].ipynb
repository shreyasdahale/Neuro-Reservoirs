{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2a722d1",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e605f985",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.integrate import odeint\n",
    "from sklearn.linear_model import Ridge\n",
    "from matplotlib.colors import Normalize\n",
    "import networkx as nx\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "from scipy.signal import welch\n",
    "import matplotlib.cm as cm\n",
    "import seaborn as sns\n",
    "from collections import defaultdict\n",
    "from sklearn.decomposition import PCA\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ac8933",
   "metadata": {},
   "source": [
    "# Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf80a9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_spectral_radius(W, target_radius=0.95):\n",
    "    \"\"\"\n",
    "    Scales a matrix W so that its largest eigenvalue magnitude = target_radius.\n",
    "    \"\"\"\n",
    "    eigvals = np.linalg.eigvals(W)\n",
    "    radius = np.max(np.abs(eigvals))\n",
    "    if radius == 0:\n",
    "        return W\n",
    "    return (W / radius) * target_radius\n",
    "\n",
    "def augment_state_with_squares(x):\n",
    "    \"\"\"\n",
    "    Given state vector x in R^N, return [ x, x^2, 1 ] in R^(2N+1).\n",
    "    We'll use this for both training and prediction.\n",
    "    \"\"\"\n",
    "    x_sq = x**2\n",
    "    return np.concatenate([x, x_sq, [1.0]])  # shape: 2N+1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4741c6",
   "metadata": {},
   "source": [
    "# HHLR [v2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "817c595b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import Ridge\n",
    "from numpy.linalg import eigvals\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Utility helpers\n",
    "# ---------------------------------------------------------------------\n",
    "def scale_spectral_radius(W, desired_radius=0.95):\n",
    "    \"\"\"Affine-scale W so that its spectral radius equals desired_radius.\"\"\"\n",
    "    eigs = eigvals(W)\n",
    "    radius = np.max(np.abs(eigs))\n",
    "    if radius == 0:\n",
    "        raise ValueError(\"Spectral radius of W is zero.\")\n",
    "    return W * (desired_radius / radius)\n",
    "\n",
    "\n",
    "def augment_state_with_squares(x):\n",
    "    \"\"\"Return [x, x², 1] (same convention as in CycleReservoir3D).\"\"\"\n",
    "    return np.concatenate([x, x**2, [1.0]])\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Hemispherically–Hierarchical Lobe Reservoir\n",
    "# ---------------------------------------------------------------------\n",
    "class HHLobeReservoir:\n",
    "    \"\"\"\n",
    "    Hemispherically-Hierarchical Lobe Reservoir (HH-LR)\n",
    "\n",
    "    • 8 anatomical modules  —  L/R × {F, P, T, O}\n",
    "    • Intra-module: Watts–Strogatz small-world graphs (ring + rewire)\n",
    "    • Intra-hemisphere shortcuts: distance-modulated (exp decay)\n",
    "    • Inter-hemisphere bridges: sparse homotopic callosal links\n",
    "    • Lobe cardinalities follow MRI volume ratio 4 : 3 : 2 : 1\n",
    "    \"\"\"\n",
    "\n",
    "    # bookkeeping ------------------------------------------------------\n",
    "    _LOBES  = ['F', 'P', 'T', 'O']\n",
    "    _HEMIS  = ['L', 'R']\n",
    "    _CENTROIDS = {                             # rough 2-D montage coords\n",
    "        ('L', 'F'): (-1.0,  1.0), ('L', 'P'): (-1.0,  0.0),\n",
    "        ('L', 'T'): (-1.0, -1.0), ('L', 'O'): (-1.0, -2.0),\n",
    "        ('R', 'F'): ( 1.0,  1.0), ('R', 'P'): ( 1.0,  0.0),\n",
    "        ('R', 'T'): ( 1.0, -1.0), ('R', 'O'): ( 1.0, -2.0),\n",
    "    }\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    def __init__(self,\n",
    "                 reservoir_size=800,\n",
    "                 input_dim=32,\n",
    "                 spectral_radius=0.9,\n",
    "                 input_scale=1.0,\n",
    "                 leaking_rate=1.0,\n",
    "                 ridge_alpha=1e-6,\n",
    "                 # small-world / shortcut hyper-parameters\n",
    "                 k_ring=8,\n",
    "                 p_rewire_frontal=0.30,\n",
    "                 p_rewire_other=0.10,\n",
    "                 P_lat=0.04,\n",
    "                 sigma=5.0,\n",
    "                 P_call=0.01,\n",
    "                 seed=42):\n",
    "        \"\"\"\n",
    "        reservoir_size : total number of neurons (N)\n",
    "        input_dim      : dimension of u_t  (128 for EEG band-power features)\n",
    "        leaking_rate   : α in leaky-integrator update\n",
    "        \"\"\"\n",
    "        self.N          = reservoir_size\n",
    "        self.D_in       = input_dim\n",
    "        self.rho        = spectral_radius\n",
    "        self.in_scale   = input_scale\n",
    "        self.alpha      = leaking_rate\n",
    "        self.ridge_alpha= ridge_alpha\n",
    "        self.seed       = seed\n",
    "\n",
    "        # --------------------------------------------------------------\n",
    "        # 1) allocate neurons:  per-hemisphere 4 : 3 : 2 : 1 (F:P:T:O)\n",
    "        # --------------------------------------------------------------\n",
    "        ratio = {'F': 4, 'P': 3, 'T': 2, 'O': 1}\n",
    "        total_w = sum(ratio.values())          # = 10\n",
    "        half_N  = self.N // 2                  # neurons per hemisphere\n",
    "\n",
    "        counts_per_hemi = {\n",
    "            l: int(half_N * ratio[l] / total_w) for l in self._LOBES\n",
    "        }\n",
    "\n",
    "        # distribute rounding residuals (largest fractional remainder first)\n",
    "        residual = half_N - sum(counts_per_hemi.values())\n",
    "        if residual > 0:\n",
    "            remainders = sorted(\n",
    "                self._LOBES,\n",
    "                key=lambda l: (half_N * ratio[l] / total_w) - counts_per_hemi[l],\n",
    "                reverse=True\n",
    "            )\n",
    "            for l in remainders[:residual]:\n",
    "                counts_per_hemi[l] += 1\n",
    "\n",
    "        # build slice table\n",
    "        self._module_slices = {}\n",
    "        idx0 = 0\n",
    "        for h in self._HEMIS:          # L then R\n",
    "            for l in self._LOBES:      # F, P, T, O\n",
    "                n = counts_per_hemi[l]\n",
    "                self._module_slices[(h, l)] = slice(idx0, idx0 + n)\n",
    "                idx0 += n\n",
    "        assert idx0 == self.N, \"Slice allocation error\"\n",
    "\n",
    "        # --------------------------------------------------------------\n",
    "        # 2) construct adjacency matrix W according to HH-LR rules\n",
    "        # --------------------------------------------------------------\n",
    "        rng = np.random.default_rng(self.seed)\n",
    "        W = np.zeros((self.N, self.N), dtype=float)\n",
    "\n",
    "        # 2.1 intra-module small-world wiring\n",
    "        for (h, l), sl in self._module_slices.items():\n",
    "            n_mod = sl.stop - sl.start\n",
    "            k = min(k_ring, n_mod - 1)\n",
    "            p_rewire = p_rewire_frontal if l == 'F' else p_rewire_other\n",
    "\n",
    "            # ring lattice\n",
    "            for i_local in range(n_mod):\n",
    "                for m in range(1, k + 1):\n",
    "                    j_local = (i_local + m) % n_mod\n",
    "                    i_glob  = sl.start + i_local\n",
    "                    j_glob  = sl.start + j_local\n",
    "                    W[i_glob, j_glob] = rng.standard_normal()\n",
    "                    W[j_glob, i_glob] = rng.standard_normal()\n",
    "\n",
    "            # random rewiring\n",
    "            for i_local in range(n_mod):\n",
    "                for m in range(1, k + 1):\n",
    "                    if rng.random() < p_rewire:\n",
    "                        j_local_new = rng.integers(0, n_mod - 1)\n",
    "                        if j_local_new >= i_local:\n",
    "                            j_local_new += 1\n",
    "                        i_glob = sl.start + i_local\n",
    "                        j_glob_new = sl.start + j_local_new\n",
    "                        w_new = rng.standard_normal()\n",
    "                        W[i_glob, j_glob_new] = w_new\n",
    "                        W[j_glob_new, i_glob] = rng.standard_normal()\n",
    "\n",
    "        # 2.2 intra-hemisphere distance-weighted shortcuts\n",
    "        for h in self._HEMIS:\n",
    "            for l1 in self._LOBES:\n",
    "                for l2 in self._LOBES:\n",
    "                    if l1 == l2:\n",
    "                        continue\n",
    "                    sl1 = self._module_slices[(h, l1)]\n",
    "                    sl2 = self._module_slices[(h, l2)]\n",
    "                    d = np.linalg.norm(\n",
    "                        np.array(self._CENTROIDS[(h, l1)]) -\n",
    "                        np.array(self._CENTROIDS[(h, l2)])\n",
    "                    )\n",
    "                    p_edge = P_lat * np.exp(-d / sigma)\n",
    "                    for i in range(sl1.start, sl1.stop):\n",
    "                        mask = rng.random(sl2.stop - sl2.start) < p_edge\n",
    "                        js = np.nonzero(mask)[0] + sl2.start\n",
    "                        if js.size:\n",
    "                            W[i, js] = rng.standard_normal(size=js.size)\n",
    "                            W[js, i] = rng.standard_normal(size=js.size)\n",
    "\n",
    "        # 2.3 inter-hemisphere homotopic callosal links\n",
    "        for l in self._LOBES:\n",
    "            sl_L = self._module_slices[('L', l)]\n",
    "            sl_R = self._module_slices[('R', l)]\n",
    "            for i in range(sl_L.start, sl_L.stop):\n",
    "                mask = rng.random(sl_R.stop - sl_R.start) < P_call\n",
    "                js = np.nonzero(mask)[0] + sl_R.start\n",
    "                if js.size:\n",
    "                    W[i, js] = rng.standard_normal(size=js.size)\n",
    "                    W[js, i] = rng.standard_normal(size=js.size)\n",
    "\n",
    "        # 2.4 spectral scaling to enforce ESP\n",
    "        self.W = scale_spectral_radius(W, self.rho)\n",
    "\n",
    "        # --------------------------------------------------------------\n",
    "        # 3) random input weights\n",
    "        # --------------------------------------------------------------\n",
    "        rng = np.random.default_rng(self.seed + 1)\n",
    "        self.W_in = (rng.random((self.N, self.D_in)) - 0.5) * 2.0 * self.in_scale\n",
    "\n",
    "        # initialize state & read-out\n",
    "        self.x = np.zeros(self.N)\n",
    "        self.W_out = None\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # ESN core methods --------------------------------------------------\n",
    "    # ------------------------------------------------------------------\n",
    "    def reset_state(self):\n",
    "        self.x.fill(0.0)\n",
    "\n",
    "    def _update(self, u):\n",
    "        pre = self.W @ self.x + self.W_in @ u\n",
    "        x_new = np.tanh(pre)\n",
    "        self.x = (1.0 - self.alpha) * self.x + self.alpha * x_new\n",
    "\n",
    "    def collect_states(self, inputs, discard=100):\n",
    "        self.reset_state()\n",
    "        states = []\n",
    "        for u in inputs:\n",
    "            self._update(u)\n",
    "            states.append(self.x.copy())\n",
    "        return np.array(states[discard:]), np.array(states[:discard])\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # read-out ----------------------------------------------------------\n",
    "    # ------------------------------------------------------------------\n",
    "    def fit_readout(self, train_input, train_target, discard=100):\n",
    "        states_use, _ = self.collect_states(train_input, discard)\n",
    "        targets_use = train_target[discard:]\n",
    "        X_aug = np.vstack([augment_state_with_squares(s) for s in states_use])\n",
    "\n",
    "        reg = Ridge(alpha=self.ridge_alpha, fit_intercept=False)\n",
    "        reg.fit(X_aug, targets_use)\n",
    "        self.W_out = reg.coef_\n",
    "\n",
    "    def predict_sequence(self, inputs):\n",
    "        preds = []\n",
    "        self.reset_state()\n",
    "        for u in inputs:\n",
    "            self._update(u)\n",
    "            preds.append(self.W_out @ augment_state_with_squares(self.x))\n",
    "        return np.array(preds)\n",
    "    \n",
    "    def predict_autoregressive(self, initial_input, n_steps):\n",
    "        preds = []\n",
    "        current_in = np.array(initial_input)\n",
    "        for _ in range(n_steps):\n",
    "            self._update(current_in)\n",
    "            out = self.W_out @ augment_state_with_squares(self.x)\n",
    "            preds.append(out)\n",
    "            current_in = out\n",
    "        return np.array(preds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587f6038",
   "metadata": {},
   "source": [
    "### NRMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b55e0383",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_nrmse(all_preds, test_target, horizons):\n",
    "    \"\"\"\n",
    "    Evaluate model performance over multiple prediction horizons\n",
    "    for teacher-forced single-step forecasting or autoregressive rollout.\n",
    "    \"\"\"\n",
    "    horizon_nrmse = {}\n",
    "    for horizon in horizons:\n",
    "        preds = all_preds[:horizon]\n",
    "        targets = test_target[:horizon]\n",
    "        squared_errors = (preds - targets) ** 2\n",
    "        variance = np.var(targets, axis=0)\n",
    "        variance[variance == 0] = 1e-8  # avoid divide-by-zero\n",
    "        nrmse = np.sqrt(np.sum(squared_errors) / (horizon * np.sum(variance)))\n",
    "        horizon_nrmse[horizon] = nrmse\n",
    "    return horizon_nrmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb9a21c",
   "metadata": {},
   "source": [
    "### VPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "193a03f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_valid_prediction_time(y_true, y_pred, test_time, lyapunov_time, threshold=0.4):\n",
    "    y_mean = np.mean(y_true, axis=0)\n",
    "    y_centered = y_true - y_mean\n",
    "    denom = np.mean(np.sum(y_centered**2, axis=1))\n",
    "\n",
    "    error = y_true - y_pred\n",
    "    squared_error = np.sum(error**2, axis=1)\n",
    "    delta = squared_error / denom\n",
    "\n",
    "    idx_exceed = np.where(delta > threshold)[0]\n",
    "    if len(idx_exceed) == 0:\n",
    "        # never exceeds threshold => set T_VPT to the final time\n",
    "        T_VPT = test_time[-1]\n",
    "    else:\n",
    "        T_VPT = test_time[idx_exceed[0]]\n",
    "\n",
    "    ratio = T_VPT / lyapunov_time\n",
    "\n",
    "    return T_VPT, ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4e8e78",
   "metadata": {},
   "source": [
    "### ADev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38f84534",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_attractor_deviation(predictions, targets, cube_size=(0.1, 0.1, 0.1)):\n",
    "    \"\"\"\n",
    "    Compute the Attractor Deviation (ADev) metric.\n",
    "\n",
    "    Parameters:\n",
    "        predictions (numpy.ndarray): Predicted trajectories of shape (n, 3).\n",
    "        targets (numpy.ndarray): True trajectories of shape (n, 3).\n",
    "        cube_size (tuple): Dimensions of the cube (dx, dy, dz).\n",
    "\n",
    "    Returns:\n",
    "        float: The ADev metric.\n",
    "    \"\"\"\n",
    "    # Define the cube grid based on the range of the data and cube size\n",
    "    min_coords = np.min(np.vstack((predictions, targets)), axis=0)\n",
    "    max_coords = np.max(np.vstack((predictions, targets)), axis=0)\n",
    "\n",
    "    # Create a grid of cubes\n",
    "    grid_shape = ((max_coords - min_coords) / cube_size).astype(int) + 1\n",
    "\n",
    "    # Initialize the cube occupancy arrays\n",
    "    pred_cubes = np.zeros(grid_shape, dtype=int)\n",
    "    target_cubes = np.zeros(grid_shape, dtype=int)\n",
    "\n",
    "    # Map trajectories to cubes\n",
    "    pred_indices = ((predictions - min_coords) / cube_size).astype(int)\n",
    "    target_indices = ((targets - min_coords) / cube_size).astype(int)\n",
    "\n",
    "    # Mark cubes visited by predictions and targets\n",
    "    for idx in pred_indices:\n",
    "        pred_cubes[tuple(idx)] = 1\n",
    "    for idx in target_indices:\n",
    "        target_cubes[tuple(idx)] = 1\n",
    "\n",
    "    # Compute the ADev metric\n",
    "    adev = np.sum(np.abs(pred_cubes - target_cubes))\n",
    "    return adev"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825c2de7",
   "metadata": {},
   "source": [
    "### PSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "402a5c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_psd(y, dt=0.01):\n",
    "    z = y[:, 2]  # Extract Z-component\n",
    "    \n",
    "    # Compute PSD using Welch’s method\n",
    "    freqs, psd = welch(z, fs=1/dt, window='hamming', nperseg=len(z))  # Using Hamming window\n",
    "    \n",
    "    return freqs, psd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8719c3c",
   "metadata": {},
   "source": [
    "# MIT-BIH Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "49bbfe54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_delay_embedding(signal, embed_dim):\n",
    "    L = len(signal) - embed_dim + 1\n",
    "    emb = np.zeros((L, embed_dim))\n",
    "    for i in range(L):\n",
    "        emb[i, :] = signal[i:i+embed_dim]\n",
    "    return emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "54b46a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wfdb\n",
    "\n",
    "# Download and load record and annotations for patient #100\n",
    "record = wfdb.rdrecord('100', sampfrom=0, sampto=25002, pn_dir='mitdb')  # first 20,000 samples\n",
    "annotation = wfdb.rdann('100', 'atr', sampfrom=0, sampto=25002, pn_dir='mitdb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7a0e8cf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.145, -0.145, -0.145, ..., -0.41 , -0.415, -0.425],\n",
       "      shape=(25002,))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get input signal u(t) from the first channel\n",
    "u = record.p_signal[:, 0] \n",
    "u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "93538ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize input\n",
    "u_min = np.min(u)\n",
    "u_max = np.max(u)\n",
    "u_norm = (u - u_min) / (u_max - u_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6dfcd0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = record.fs  # sampling frequency (should be 360 Hz)\n",
    "t_vals = np.arange(len(u_norm)) / fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ef734865",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_dim = 3\n",
    "# inputs = u_norm\n",
    "inputs = create_delay_embedding(u_norm, emb_dim)\n",
    "\n",
    "# Create target array (heartbeat locations)\n",
    "targets = np.zeros(len(u_norm))\n",
    "targets[annotation.sample] = 1  # mark annotations as 1 (heartbeat)\n",
    "targets = create_delay_embedding(targets, emb_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "938389fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 25000, train size: 15000, test size: 9999\n"
     ]
    }
   ],
   "source": [
    "data_size = len(inputs)\n",
    "train_size = 15000\n",
    "train_input = inputs[:train_size]\n",
    "train_target = targets[:train_size]\n",
    "test_input = inputs[train_size+1:]\n",
    "test_target = targets[train_size+1:]\n",
    "test_size = len(test_input)\n",
    "print(f\"Total samples: {data_size}, train size: {train_size}, test size: {test_size}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8231544e",
   "metadata": {},
   "outputs": [],
   "source": [
    "horizons = [300, 600, 1000]\n",
    "\n",
    "nrmse_dict = defaultdict(list)\n",
    "seeds = range(995, 1025)\n",
    "\n",
    "for seed in seeds:\n",
    "    hhlr = HHLobeReservoir(\n",
    "        reservoir_size=500,\n",
    "        input_dim=emb_dim,\n",
    "        spectral_radius=0.0001,\n",
    "        input_scale=1.5,\n",
    "        leaking_rate=0.9,\n",
    "        ridge_alpha=1e-08,\n",
    "        k_ring=6,\n",
    "        p_rewire_frontal=0.30,\n",
    "        p_rewire_other=0.10,\n",
    "        P_lat=0.04,\n",
    "        sigma=5.0,\n",
    "        P_call=0.01,\n",
    "        seed=seed\n",
    "    )\n",
    "    hhlr.fit_readout(train_input, train_target, discard=5000)\n",
    "    hhlr_preds = hhlr.predict_sequence(test_input)\n",
    "    hhlr_nrmse = evaluate_nrmse(hhlr_preds, test_target, horizons)\n",
    "    nrmse_dict['HHLR'].append(hhlr_nrmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "337c012a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NRMSE for Different Prediction Horizons:\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "HHLR             \n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "300        0.2687796567437806 ± 0.006795129206464729\n",
      "600        0.3160501569107667 ± 0.004922184974029872\n",
      "1000       0.4395676574101214 ± 0.004726515133190974\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nNRMSE for Different Prediction Horizons:\")\n",
    "print(\"-\" * 140)\n",
    "print(f\"{'HHLR':<17}\")\n",
    "print(\"-\" * 140)\n",
    "\n",
    "for horizon in horizons:\n",
    "    hhlr_vals = [np.mean(hhlr_nrmse[horizon]) for hhlr_nrmse in nrmse_dict['HHLR']]\n",
    "\n",
    "    print(f\"{horizon:<10}\", end=\" \")\n",
    "    for vals in [hhlr_vals]:\n",
    "        mean = np.mean(vals)\n",
    "        std = np.std(vals)\n",
    "        print(f\"{mean} ± {std}\".ljust(18), end=\"\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39c1e20",
   "metadata": {},
   "source": [
    "# Sunspot Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3232502c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1749</td>\n",
       "      <td>1</td>\n",
       "      <td>1749.042</td>\n",
       "      <td>96.7</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1749</td>\n",
       "      <td>2</td>\n",
       "      <td>1749.123</td>\n",
       "      <td>104.3</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1749</td>\n",
       "      <td>3</td>\n",
       "      <td>1749.204</td>\n",
       "      <td>116.7</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1749</td>\n",
       "      <td>4</td>\n",
       "      <td>1749.288</td>\n",
       "      <td>92.8</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1749</td>\n",
       "      <td>5</td>\n",
       "      <td>1749.371</td>\n",
       "      <td>141.7</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3310</th>\n",
       "      <td>2024</td>\n",
       "      <td>11</td>\n",
       "      <td>2024.873</td>\n",
       "      <td>152.5</td>\n",
       "      <td>20.9</td>\n",
       "      <td>681</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3311</th>\n",
       "      <td>2024</td>\n",
       "      <td>12</td>\n",
       "      <td>2024.958</td>\n",
       "      <td>154.5</td>\n",
       "      <td>25.6</td>\n",
       "      <td>572</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3312</th>\n",
       "      <td>2025</td>\n",
       "      <td>1</td>\n",
       "      <td>2025.042</td>\n",
       "      <td>137.0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>670</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3313</th>\n",
       "      <td>2025</td>\n",
       "      <td>2</td>\n",
       "      <td>2025.122</td>\n",
       "      <td>154.6</td>\n",
       "      <td>23.3</td>\n",
       "      <td>655</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3314</th>\n",
       "      <td>2025</td>\n",
       "      <td>3</td>\n",
       "      <td>2025.204</td>\n",
       "      <td>134.2</td>\n",
       "      <td>20.4</td>\n",
       "      <td>1011</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3315 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0   1         2      3     4     5  6\n",
       "0     1749   1  1749.042   96.7  -1.0    -1  1\n",
       "1     1749   2  1749.123  104.3  -1.0    -1  1\n",
       "2     1749   3  1749.204  116.7  -1.0    -1  1\n",
       "3     1749   4  1749.288   92.8  -1.0    -1  1\n",
       "4     1749   5  1749.371  141.7  -1.0    -1  1\n",
       "...    ...  ..       ...    ...   ...   ... ..\n",
       "3310  2024  11  2024.873  152.5  20.9   681  0\n",
       "3311  2024  12  2024.958  154.5  25.6   572  0\n",
       "3312  2025   1  2025.042  137.0  23.3   670  0\n",
       "3313  2025   2  2025.122  154.6  23.3   655  0\n",
       "3314  2025   3  2025.204  134.2  20.4  1011  0\n",
       "\n",
       "[3315 rows x 7 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "file_path = 'RealWorld/datasets/SN_m_tot_V2.0.csv'\n",
    "\n",
    "df = pd.read_csv(file_path, sep=';', header = None)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "98f8602b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 3315\n",
      "Train size: 2000\n",
      "Test size: 1312\n"
     ]
    }
   ],
   "source": [
    "data = df.iloc[:, 3].values\n",
    "dt = 1\n",
    "dataset_size = len(data)\n",
    "data = create_delay_embedding(data, 3)\n",
    "print(f\"Dataset size: {dataset_size}\")\n",
    "\n",
    "# Train/Test Split\n",
    "train_end = 2000\n",
    "train_input  = data[:train_end]\n",
    "train_target = data[1:train_end+1]\n",
    "test_input   = data[train_end:-1]\n",
    "test_target  = data[train_end+1:]\n",
    "y_test = test_target\n",
    "n_test_steps = len(test_target)\n",
    "time_test = np.arange(n_test_steps) * dt\n",
    "\n",
    "print(f\"Train size: {len(train_input)}\\nTest size: {len(test_input)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c7684b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "horizons = [300, 600, 1000]\n",
    "\n",
    "nrmse_dict = defaultdict(list)\n",
    "seeds = range(995, 1025)\n",
    "\n",
    "for seed in seeds:\n",
    "    hhlr = HHLobeReservoir(\n",
    "        reservoir_size=500,\n",
    "        input_dim=emb_dim,\n",
    "        spectral_radius=0.1,\n",
    "        input_scale=0.000001,\n",
    "        leaking_rate=0.9,\n",
    "        ridge_alpha=1e-08,\n",
    "        k_ring=6,\n",
    "        p_rewire_frontal=0.30,\n",
    "        p_rewire_other=0.10,\n",
    "        P_lat=0.04,\n",
    "        sigma=5.0,\n",
    "        P_call=0.01,\n",
    "        seed=seed\n",
    "    )\n",
    "    hhlr.fit_readout(train_input, train_target, discard=100)\n",
    "    hhlr_preds = hhlr.predict_sequence(test_input)\n",
    "    hhlr_nrmse = evaluate_nrmse(hhlr_preds, test_target, horizons)\n",
    "    nrmse_dict['HHLR'].append(hhlr_nrmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "daaef00f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NRMSE for Different Prediction Horizons:\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "HHLR             \n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "300        0.25191434057725326 ± 5.815903786693317e-05\n",
      "600        0.2040988478870382 ± 4.080769684213441e-05\n",
      "1000       0.2025164375199728 ± 3.0433333910963375e-05\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nNRMSE for Different Prediction Horizons:\")\n",
    "print(\"-\" * 140)\n",
    "print(f\"{'HHLR':<17}\")\n",
    "print(\"-\" * 140)\n",
    "\n",
    "for horizon in horizons:\n",
    "    hhlr_vals = [np.mean(hhlr_nrmse[horizon]) for hhlr_nrmse in nrmse_dict['HHLR']]\n",
    "\n",
    "    print(f\"{horizon:<10}\", end=\" \")\n",
    "    for vals in [hhlr_vals]:\n",
    "        mean = np.mean(vals)\n",
    "        std = np.std(vals)\n",
    "        print(f\"{mean} ± {std}\".ljust(18), end=\"\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e6ee32",
   "metadata": {},
   "source": [
    "# Sante Fe Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2407cfd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>76.53</td>\n",
       "      <td>8320</td>\n",
       "      <td>7771</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>76.53</td>\n",
       "      <td>8117</td>\n",
       "      <td>7774</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>76.15</td>\n",
       "      <td>7620</td>\n",
       "      <td>7788</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>75.39</td>\n",
       "      <td>6413</td>\n",
       "      <td>7787</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75.51</td>\n",
       "      <td>7518</td>\n",
       "      <td>7767</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16995</th>\n",
       "      <td>73.57</td>\n",
       "      <td>16021</td>\n",
       "      <td>6498</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16996</th>\n",
       "      <td>73.79</td>\n",
       "      <td>-6957</td>\n",
       "      <td>6547</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16997</th>\n",
       "      <td>74.54</td>\n",
       "      <td>11476</td>\n",
       "      <td>6576</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16998</th>\n",
       "      <td>74.36</td>\n",
       "      <td>15058</td>\n",
       "      <td>6573</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16999</th>\n",
       "      <td>72.91</td>\n",
       "      <td>13510</td>\n",
       "      <td>6676</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0      1     2   3\n",
       "0      76.53   8320  7771 NaN\n",
       "1      76.53   8117  7774 NaN\n",
       "2      76.15   7620  7788 NaN\n",
       "3      75.39   6413  7787 NaN\n",
       "4      75.51   7518  7767 NaN\n",
       "...      ...    ...   ...  ..\n",
       "16995  73.57  16021  6498 NaN\n",
       "16996  73.79  -6957  6547 NaN\n",
       "16997  74.54  11476  6576 NaN\n",
       "16998  74.36  15058  6573 NaN\n",
       "16999  72.91  13510  6676 NaN\n",
       "\n",
       "[17000 rows x 4 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = 'RealWorld/datasets/santa-fe-time-series-competition-data-set-b-1.0.0/b1.txt'\n",
    "\n",
    "df = pd.read_csv(file_path, header=None, sep=' ')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b5624624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the first column (column 0) of the DataFrame\n",
    "df[0] = (df[0] - df[0].min()) / (df[0].max() - df[0].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ae5bf803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data length: 17000.\n",
      "Train size: 7000  \n",
      "Test size: 9997\n"
     ]
    }
   ],
   "source": [
    "data = df.iloc[:, 0].values\n",
    "chosen_system = \"SantaFe\"\n",
    "dt = 1\n",
    "T_data = len(data)\n",
    "data = create_delay_embedding(data, 3)\n",
    "print(f\"Data length: {T_data}.\")\n",
    "\n",
    "# Train/Test Split\n",
    "train_end = 7000\n",
    "train_input  = data[:train_end]\n",
    "train_target = data[1:train_end+1]\n",
    "test_input   = data[train_end:-1]\n",
    "test_target  = data[train_end+1:]\n",
    "y_test = test_target\n",
    "n_test_steps = len(test_target)\n",
    "time_test = np.arange(n_test_steps) * dt\n",
    "\n",
    "print(f\"Train size: {len(train_input)}  \\nTest size: {len(test_input)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5900d956",
   "metadata": {},
   "outputs": [],
   "source": [
    "horizons = [300, 600, 1000]\n",
    "\n",
    "nrmse_dict = defaultdict(list)\n",
    "seeds = range(995, 1025)\n",
    "\n",
    "for seed in seeds:\n",
    "    hhlr = HHLobeReservoir(\n",
    "        reservoir_size=500,\n",
    "        input_dim=emb_dim,\n",
    "        spectral_radius=0.1,\n",
    "        input_scale=0.001,\n",
    "        leaking_rate=0.9,\n",
    "        ridge_alpha=1e-08,\n",
    "        k_ring=6,\n",
    "        p_rewire_frontal=0.30,\n",
    "        p_rewire_other=0.10,\n",
    "        P_lat=0.04,\n",
    "        sigma=5.0,\n",
    "        P_call=0.01,\n",
    "        seed=seed\n",
    "    )\n",
    "    hhlr.fit_readout(train_input, train_target, discard=100)\n",
    "    hhlr_preds = hhlr.predict_sequence(test_input)\n",
    "    hhlr_nrmse = evaluate_nrmse(hhlr_preds, test_target, horizons)\n",
    "    nrmse_dict['HHLR'].append(hhlr_nrmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "afd4e124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NRMSE for Different Prediction Horizons:\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "HHLR             \n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "300        0.1632833665795095 ± 0.0017642838709850679\n",
      "600        0.13344369480080598 ± 0.0004615956534575276\n",
      "1000       0.1445385562805409 ± 0.0003472245405112505\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nNRMSE for Different Prediction Horizons:\")\n",
    "print(\"-\" * 140)\n",
    "print(f\"{'HHLR':<17}\")\n",
    "print(\"-\" * 140)\n",
    "\n",
    "for horizon in horizons:\n",
    "    hhlr_vals = [np.mean(hhlr_nrmse[horizon]) for hhlr_nrmse in nrmse_dict['HHLR']]\n",
    "\n",
    "    print(f\"{horizon:<10}\", end=\" \")\n",
    "    for vals in [hhlr_vals]:\n",
    "        mean = np.mean(vals)\n",
    "        std = np.std(vals)\n",
    "        print(f\"{mean} ± {std}\".ljust(18), end=\"\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27efeeba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for seed in seeds:\n",
    "#     crj = CRJRes3D(\n",
    "#         reservoir_size=500,\n",
    "#         edge_weight=0.8,\n",
    "#         jump=15,\n",
    "#         spectral_radius=0.99,\n",
    "#         input_scale=0.2,\n",
    "#         leaking_rate=0.8,\n",
    "#         ridge_alpha=1e-6,\n",
    "#         seed=seed\n",
    "#     )\n",
    "#     crj.fit_readout(train_input, train_target, discard=5000)\n",
    "#     crj_preds = crj.predict(test_input)\n",
    "#     crj_nrmse = evaluate_nrmse(crj_preds, test_target, all_horizons)\n",
    "#     nrmse_dict['CRJ'].append(crj_nrmse)\n",
    "\n",
    "# for seed in seeds:\n",
    "#     mci_esn = MCIESN3D(\n",
    "#         reservoir_size=500,\n",
    "#         cycle_weight=0.8,\n",
    "#         connect_weight=0.8,\n",
    "#         combine_factor=0.1,\n",
    "#         v1=0.03,\n",
    "#         v2=0.03,\n",
    "#         spectral_radius=0.99,\n",
    "#         leaking_rate=0.8,\n",
    "#         ridge_alpha=1e-6,\n",
    "#         seed=seed\n",
    "#     )\n",
    "#     mci_esn.fit_readout(train_input, train_target, discard=5000)\n",
    "#     mci_esn_preds = mci_esn.predict(test_input)\n",
    "#     mci_esn_nrmse = evaluate_nrmse(mci_esn_preds, test_target, horizons)\n",
    "#     nrmse_dict['MCI-ESN'].append(mci_esn_nrmse)\n",
    "\n",
    "\n",
    "# for seed in seeds:\n",
    "#     deepesn = DeepESN3D(\n",
    "#         num_layers=5,\n",
    "#         reservoir_size=100,\n",
    "#         spectral_radius=0.99,\n",
    "#         input_scale=0.2,\n",
    "#         leaking_rate=0.8,\n",
    "#         ridge_alpha=1e-6,\n",
    "#         seed=seed\n",
    "#     )\n",
    "#     deepesn.fit_readout(train_input, train_target, discard=5000)\n",
    "#     deepesn_preds = deepesn.predict(test_input)\n",
    "#     deepesn_nrmse = evaluate_nrmse(deepesn_preds, test_target, horizons)\n",
    "#     nrmse_dict['DeepESN'].append(deepesn_nrmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3e5f0f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "for horizon in [1000]:\n",
    "    crj_vals = [np.mean(crj_nrmse[horizon]) for crj_nrmse in nrmse_dict['CRJ']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "20bd0846",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[np.float64(0.29000843893248435),\n",
       " np.float64(0.309148323024945),\n",
       " np.float64(0.32659144846892424),\n",
       " np.float64(0.3039714851291318),\n",
       " np.float64(0.29258113930886226),\n",
       " np.float64(0.31024836734397154),\n",
       " np.float64(0.2951963586421195),\n",
       " np.float64(0.2853331750098682),\n",
       " np.float64(0.31924539710353983),\n",
       " np.float64(0.30016568182513714),\n",
       " np.float64(0.3191322226103948),\n",
       " np.float64(0.33379069862031424),\n",
       " np.float64(0.3143257694771222),\n",
       " np.float64(0.31721888143145544),\n",
       " np.float64(0.30552764770563207),\n",
       " np.float64(0.3011093344323173),\n",
       " np.float64(0.3555299804718019),\n",
       " np.float64(0.31279757786746004),\n",
       " np.float64(0.3062745634197625),\n",
       " np.float64(0.31540614075135104),\n",
       " np.float64(0.3073646034931301),\n",
       " np.float64(0.32850520523876053),\n",
       " np.float64(0.2868286264541298),\n",
       " np.float64(0.30146383711230884),\n",
       " np.float64(0.31231718734721303),\n",
       " np.float64(0.3251354111071609),\n",
       " np.float64(0.3295762473780636),\n",
       " np.float64(0.30554270928538646),\n",
       " np.float64(0.3057524375888075),\n",
       " np.float64(0.3169192555569122),\n",
       " np.float64(0.29000843893248435),\n",
       " np.float64(0.309148323024945),\n",
       " np.float64(0.32659144846892424),\n",
       " np.float64(0.3039714851291318),\n",
       " np.float64(0.29258113930886226),\n",
       " np.float64(0.31024836734397154),\n",
       " np.float64(0.2951963586421195),\n",
       " np.float64(0.2853331750098682),\n",
       " np.float64(0.31924539710353983),\n",
       " np.float64(0.30016568182513714),\n",
       " np.float64(0.3191322226103948),\n",
       " np.float64(0.33379069862031424),\n",
       " np.float64(0.3143257694771222),\n",
       " np.float64(0.31721888143145544),\n",
       " np.float64(0.30552764770563207),\n",
       " np.float64(0.3011093344323173),\n",
       " np.float64(0.3555299804718019),\n",
       " np.float64(0.31279757786746004),\n",
       " np.float64(0.3062745634197625),\n",
       " np.float64(0.31540614075135104),\n",
       " np.float64(0.3073646034931301),\n",
       " np.float64(0.32850520523876053),\n",
       " np.float64(0.2868286264541298),\n",
       " np.float64(0.30146383711230884),\n",
       " np.float64(0.31231718734721303),\n",
       " np.float64(0.3251354111071609),\n",
       " np.float64(0.3295762473780636),\n",
       " np.float64(0.30554270928538646),\n",
       " np.float64(0.3057524375888075),\n",
       " np.float64(0.3169192555569122)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crj_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0614d25e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nrmse_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mnrmse_dict\u001b[49m[\u001b[33m'\u001b[39m\u001b[33mCRJ\u001b[39m\u001b[33m'\u001b[39m][\u001b[32m1000\u001b[39m]\n",
      "\u001b[31mNameError\u001b[39m: name 'nrmse_dict' is not defined"
     ]
    }
   ],
   "source": [
    "nrmse_dict['CRJ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4a243d60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NRMSE for Different Prediction Horizons:\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "HFR              \n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "300        nan ± nan         \n",
      "600        nan ± nan         \n",
      "1000       nan ± nan         \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shrey\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\numpy\\_core\\fromnumeric.py:3860: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\shrey\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\numpy\\_core\\_methods.py:145: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "c:\\Users\\shrey\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\numpy\\_core\\_methods.py:223: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "c:\\Users\\shrey\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\numpy\\_core\\_methods.py:181: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean,\n",
      "c:\\Users\\shrey\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\numpy\\_core\\_methods.py:215: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nNRMSE for Different Prediction Horizons:\")\n",
    "print(\"-\" * 140)\n",
    "print(f\"{'HFR':<17}\")\n",
    "print(\"-\" * 140)\n",
    "\n",
    "\n",
    "for horizon in horizons:\n",
    "    hfr_vals = [np.mean(hfr_nrmse[horizon]) for hfr_nrmse in nrmse_dict['HFR']]\n",
    "\n",
    "    print(f\"{horizon:<10}\", end=\" \")\n",
    "    for vals in [hfr_vals]:\n",
    "        mean = np.mean(vals)\n",
    "        std = np.std(vals)\n",
    "        print(f\"{mean} ± {std}\".ljust(18), end=\"\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe19f3ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
