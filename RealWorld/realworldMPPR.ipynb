{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2a722d1",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e605f985",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.integrate import odeint\n",
    "from sklearn.linear_model import Ridge\n",
    "from matplotlib.colors import Normalize\n",
    "import networkx as nx\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "from scipy.signal import welch\n",
    "import matplotlib.cm as cm\n",
    "import seaborn as sns\n",
    "from collections import defaultdict\n",
    "from sklearn.decomposition import PCA\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ac8933",
   "metadata": {},
   "source": [
    "# Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf80a9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_spectral_radius(W, target_radius=0.95):\n",
    "    \"\"\"\n",
    "    Scales a matrix W so that its largest eigenvalue magnitude = target_radius.\n",
    "    \"\"\"\n",
    "    eigvals = np.linalg.eigvals(W)\n",
    "    radius = np.max(np.abs(eigvals))\n",
    "    if radius == 0:\n",
    "        return W\n",
    "    return (W / radius) * target_radius\n",
    "\n",
    "def augment_state_with_squares(x):\n",
    "    \"\"\"\n",
    "    Given state vector x in R^N, return [ x, x^2, 1 ] in R^(2N+1).\n",
    "    We'll use this for both training and prediction.\n",
    "    \"\"\"\n",
    "    x_sq = x**2\n",
    "    return np.concatenate([x, x_sq, [1.0]])  # shape: 2N+1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4741c6",
   "metadata": {},
   "source": [
    "# MPPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "817c595b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Numerically stable logistic function.\"\"\"\n",
    "    return 1.0 / (1.0 + np.exp(-x))\n",
    "\n",
    "\n",
    "class MPPRN:\n",
    "    \"\"\"\n",
    "    Swirl-Gated k-Cycle Echo-State Network (SG-kC-ESN).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    reservoir_size : int\n",
    "        Total number of neurons N (must be divisible by n_cycles).\n",
    "    n_cycles       : int, ≥ 2\n",
    "        How many simple cycles to create.\n",
    "    cycle_weight   : float\n",
    "        Weight r on each ring edge.\n",
    "    bridge_weight  : float\n",
    "        Weight s on the k sparse bridges (one per cycle).\n",
    "    input_scale    : float\n",
    "        Scaling of random input matrix W_in.\n",
    "    leak_rate      : float in (0,1]\n",
    "        leaky-integrator update; 1 recovers standard ESN.\n",
    "    ridge_alpha    : float\n",
    "        ℓ₂ penalty used in the ridge read-out.\n",
    "    swirl_beta, swirl_frequency, swirl_sigmoid\n",
    "        Parameters of the static per-neuron swirl gate\n",
    "            g_k = σ[β sin(ω·q + φ_c)]      if swirl_sigmoid\n",
    "                  β sin(ω·q + φ_c)         otherwise\n",
    "        with φ_c = 2πc / k   (c = ring id).\n",
    "    \"\"\"\n",
    "\n",
    "    # ------------------------------- init ------------------------------ #\n",
    "    def __init__(\n",
    "        self,\n",
    "        reservoir_size: int = 600,\n",
    "        n_cycles: int = 4,\n",
    "        cycle_weight: float = 0.9,\n",
    "        bridge_weight: float = 0.25,\n",
    "        input_scale: float = 0.5,\n",
    "        leak_rate: float = 1.0,\n",
    "        ridge_alpha: float = 1e-6,\n",
    "        swirl_beta: float = 2.0,\n",
    "        swirl_frequency: float | None = None,\n",
    "        swirl_sigmoid: bool = True,\n",
    "        seed: int = 42,\n",
    "        use_polynomial_readout: bool = True,\n",
    "    ):\n",
    "        if n_cycles < 2:\n",
    "            raise ValueError(\"n_cycles must be at least 2\")\n",
    "        if reservoir_size % n_cycles:\n",
    "            raise ValueError(\"reservoir_size must be divisible by n_cycles\")\n",
    "\n",
    "        # -------------- basic bookkeeping --------------------------------\n",
    "        self.N = reservoir_size\n",
    "        self.k = n_cycles\n",
    "        self.m = reservoir_size // n_cycles          # neurons per ring\n",
    "\n",
    "        # -------------- hyper-parameters ---------------------------------\n",
    "        self.r = cycle_weight\n",
    "        self.s = bridge_weight\n",
    "        self.input_scale = input_scale\n",
    "        self.alpha = leak_rate\n",
    "        self.ridge_alpha = ridge_alpha\n",
    "        self.beta = swirl_beta\n",
    "        self.omega = (\n",
    "            swirl_frequency if swirl_frequency is not None else 2.0 * np.pi / self.m\n",
    "        )\n",
    "        self.swirl_sigmoid = swirl_sigmoid\n",
    "        self.seed = seed\n",
    "        self.use_poly = use_polynomial_readout\n",
    "\n",
    "        # -------------- placeholders to be filled ------------------------\n",
    "        self.W_res: np.ndarray | None = None\n",
    "        self.W_in: np.ndarray | None = None\n",
    "        self.W_out: np.ndarray | None = None\n",
    "        self.gate: np.ndarray | None = None\n",
    "        self.x = np.zeros(self.N, dtype=np.float32)\n",
    "\n",
    "        # -------------- one-off construction -----------------------------\n",
    "        self._build_reservoir()\n",
    "        self._build_swirl_gate()\n",
    "\n",
    "    # =========================== builders =============================== #\n",
    "    def _build_reservoir(self):\n",
    "        \"\"\"Construct the k-cycle recurrent matrix W_res (shape N × N).\"\"\"\n",
    "        m, r, s, k = self.m, self.r, self.s, self.k\n",
    "\n",
    "        # 1) ring block C_r : unidirectional permutation matrix scaled by r\n",
    "        C_r = np.zeros((m, m), dtype=np.float32)\n",
    "        for i in range(m):\n",
    "            C_r[(i + 1) % m, i] = r\n",
    "\n",
    "        # 2) bridge block S : rank-1 matrix with single non-zero entry (0,0)\n",
    "        S = np.zeros((m, m), dtype=np.float32)\n",
    "        S[0, 0] = s\n",
    "\n",
    "        # 3) assemble full block matrix\n",
    "        W = np.zeros((self.N, self.N), dtype=np.float32)\n",
    "\n",
    "        def put_block(row_ring: int, col_ring: int, block: np.ndarray):\n",
    "            i0, j0 = row_ring * m, col_ring * m\n",
    "            W[i0 : i0 + m, j0 : j0 + m] = block\n",
    "\n",
    "        for c in range(k):\n",
    "            put_block(c, c, C_r)                   # diagonal ring\n",
    "            put_block(c, (c - 1) % k, S)           # bridge to predecessor\n",
    "\n",
    "        self.W_res = W\n",
    "\n",
    "    def _build_swirl_gate(self):\n",
    "        \"\"\"Pre-compute static gain vector g (length N).\"\"\"\n",
    "        g = np.empty(self.N, dtype=np.float32)\n",
    "        for k_idx in range(self.N):\n",
    "            ring_id = k_idx // self.m\n",
    "            local_q = k_idx % self.m\n",
    "            phi_c = 2.0 * np.pi * ring_id / self.k\n",
    "            raw = self.beta * np.sin(self.omega * local_q + phi_c)\n",
    "            g[k_idx] = sigmoid(raw) if self.swirl_sigmoid else raw\n",
    "        self.gate = g\n",
    "\n",
    "    # ====================== low-level reservoir ops ===================== #\n",
    "    def _apply_gate(self, vec: np.ndarray) -> np.ndarray:\n",
    "        return self.gate * vec\n",
    "\n",
    "    def _update_state(self, u_t: np.ndarray):\n",
    "        \"\"\"Single ESN step with optional leakage.\"\"\"\n",
    "        pre = self.W_res @ self.x + self.W_in @ u_t\n",
    "        gated = self._apply_gate(pre)\n",
    "        new_x = np.tanh(gated)\n",
    "        self.x = (1.0 - self.alpha) * self.x + self.alpha * new_x\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.x.fill(0.0)\n",
    "\n",
    "    # ====================== read-out training (ridge) =================== #\n",
    "    def fit_readout(self, inputs: np.ndarray, targets: np.ndarray, discard: int = 100):\n",
    "        \"\"\"\n",
    "        Teacher forcing pass • inputs [T, d_in] → states, then fit ridge.\n",
    "        \"\"\"\n",
    "        T, d_in = inputs.shape\n",
    "        if T <= discard + 1:\n",
    "            raise ValueError(\"Not enough data for training\")\n",
    "\n",
    "        rng = np.random.default_rng(self.seed)\n",
    "        self.W_in = (\n",
    "            rng.uniform(-1.0, 1.0, size=(self.N, d_in)) * self.input_scale\n",
    "        ).astype(np.float32)\n",
    "\n",
    "        self.reset_state()\n",
    "        states = []\n",
    "        for t in range(T):\n",
    "            self._update_state(inputs[t])\n",
    "            if t >= discard:\n",
    "                states.append(self.x.copy())\n",
    "\n",
    "        states = np.asarray(states, dtype=np.float32)          # [T-discard, N]\n",
    "        Y = targets[discard:]                                  # same length\n",
    "\n",
    "        if self.use_poly:\n",
    "            feats = np.concatenate(\n",
    "                [states, states * states, np.ones((states.shape[0], 1), dtype=np.float32)],\n",
    "                axis=1,\n",
    "            )\n",
    "        else:\n",
    "            feats = states\n",
    "\n",
    "        reg = Ridge(alpha=self.ridge_alpha, fit_intercept=False)\n",
    "        reg.fit(feats, Y)\n",
    "        self.W_out = reg.coef_.astype(np.float32)             # d_out × feat_dim\n",
    "\n",
    "    # ======================== autoregressive roll-out =================== #\n",
    "    def predict_autoregressive(\n",
    "        self, initial_input: np.ndarray, n_steps: int\n",
    "    ) -> np.ndarray:\n",
    "        if self.W_out is None:\n",
    "            raise RuntimeError(\"Call fit_readout() before prediction.\")\n",
    "\n",
    "        d_in = initial_input.shape[0]\n",
    "        preds = np.empty((n_steps, self.W_out.shape[0]), dtype=np.float32)\n",
    "\n",
    "        #self.reset_state()\n",
    "        current_in = initial_input.astype(np.float32).copy()\n",
    "\n",
    "        for t in range(n_steps):\n",
    "            self._update_state(current_in)\n",
    "\n",
    "            if self.use_poly:\n",
    "                big_x = np.concatenate(\n",
    "                    [self.x, self.x * self.x, np.ones(1, dtype=np.float32)]\n",
    "                )\n",
    "            else:\n",
    "                big_x = self.x\n",
    "\n",
    "            y_t = (self.W_out @ big_x).astype(np.float32)\n",
    "            preds[t] = y_t\n",
    "            current_in = y_t[:d_in]  # feedback: assume d_in ≤ d_out\n",
    "\n",
    "        return preds\n",
    "    \n",
    "    def predict_open_loop(self, test_input):\n",
    "        preds = []\n",
    "        for true_input in test_input:\n",
    "            self._update_state(true_input)\n",
    "            x_aug = augment_state_with_squares(self.x)\n",
    "            out = self.W_out @ x_aug\n",
    "            preds.append(out)\n",
    "        return np.array(preds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587f6038",
   "metadata": {},
   "source": [
    "### NRMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b55e0383",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_nrmse(all_preds, test_target, horizons):\n",
    "    \"\"\"\n",
    "    Evaluate model performance over multiple prediction horizons for Teacher-forced Single-step Forecasting\n",
    "    \"\"\"\n",
    "    horizon_nrmse = {}\n",
    "    \n",
    "    for horizon in horizons:\n",
    "        preds = all_preds[:horizon]\n",
    "        targets = test_target[:horizon]\n",
    "        squared_errors = (preds - targets)**2\n",
    "        variance = np.var(targets, axis=0)\n",
    "        nrmse = np.sqrt(np.sum(squared_errors) / (horizon * variance))\n",
    "        horizon_nrmse[horizon] = nrmse\n",
    "\n",
    "    return horizon_nrmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb9a21c",
   "metadata": {},
   "source": [
    "### VPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "193a03f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_valid_prediction_time(y_true, y_pred, test_time, lyapunov_time, threshold=0.4):\n",
    "    y_mean = np.mean(y_true, axis=0)\n",
    "    y_centered = y_true - y_mean\n",
    "    denom = np.mean(np.sum(y_centered**2, axis=1))\n",
    "\n",
    "    error = y_true - y_pred\n",
    "    squared_error = np.sum(error**2, axis=1)\n",
    "    delta = squared_error / denom\n",
    "\n",
    "    idx_exceed = np.where(delta > threshold)[0]\n",
    "    if len(idx_exceed) == 0:\n",
    "        # never exceeds threshold => set T_VPT to the final time\n",
    "        T_VPT = test_time[-1]\n",
    "    else:\n",
    "        T_VPT = test_time[idx_exceed[0]]\n",
    "\n",
    "    ratio = T_VPT / lyapunov_time\n",
    "\n",
    "    return T_VPT, ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4e8e78",
   "metadata": {},
   "source": [
    "### ADev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38f84534",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_attractor_deviation(predictions, targets, cube_size=(0.1, 0.1, 0.1)):\n",
    "    \"\"\"\n",
    "    Compute the Attractor Deviation (ADev) metric.\n",
    "\n",
    "    Parameters:\n",
    "        predictions (numpy.ndarray): Predicted trajectories of shape (n, 3).\n",
    "        targets (numpy.ndarray): True trajectories of shape (n, 3).\n",
    "        cube_size (tuple): Dimensions of the cube (dx, dy, dz).\n",
    "\n",
    "    Returns:\n",
    "        float: The ADev metric.\n",
    "    \"\"\"\n",
    "    # Define the cube grid based on the range of the data and cube size\n",
    "    min_coords = np.min(np.vstack((predictions, targets)), axis=0)\n",
    "    max_coords = np.max(np.vstack((predictions, targets)), axis=0)\n",
    "\n",
    "    # Create a grid of cubes\n",
    "    grid_shape = ((max_coords - min_coords) / cube_size).astype(int) + 1\n",
    "\n",
    "    # Initialize the cube occupancy arrays\n",
    "    pred_cubes = np.zeros(grid_shape, dtype=int)\n",
    "    target_cubes = np.zeros(grid_shape, dtype=int)\n",
    "\n",
    "    # Map trajectories to cubes\n",
    "    pred_indices = ((predictions - min_coords) / cube_size).astype(int)\n",
    "    target_indices = ((targets - min_coords) / cube_size).astype(int)\n",
    "\n",
    "    # Mark cubes visited by predictions and targets\n",
    "    for idx in pred_indices:\n",
    "        pred_cubes[tuple(idx)] = 1\n",
    "    for idx in target_indices:\n",
    "        target_cubes[tuple(idx)] = 1\n",
    "\n",
    "    # Compute the ADev metric\n",
    "    adev = np.sum(np.abs(pred_cubes - target_cubes))\n",
    "    return adev"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825c2de7",
   "metadata": {},
   "source": [
    "### PSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "402a5c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_psd(y, dt=0.01):\n",
    "    z = y[:, 2]  # Extract Z-component\n",
    "    \n",
    "    # Compute PSD using Welch’s method\n",
    "    freqs, psd = welch(z, fs=1/dt, window='hamming', nperseg=len(z))  # Using Hamming window\n",
    "    \n",
    "    return freqs, psd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8719c3c",
   "metadata": {},
   "source": [
    "# MIT-BIH Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49bbfe54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_delay_embedding(signal, embed_dim):\n",
    "    L = len(signal) - embed_dim + 1\n",
    "    emb = np.zeros((L, embed_dim))\n",
    "    for i in range(L):\n",
    "        emb[i, :] = signal[i:i+embed_dim]\n",
    "    return emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54b46a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wfdb\n",
    "\n",
    "# Download and load record and annotations for patient #100\n",
    "record = wfdb.rdrecord('100', sampfrom=0, sampto=25002, pn_dir='mitdb')  # first 20,000 samples\n",
    "annotation = wfdb.rdann('100', 'atr', sampfrom=0, sampto=25002, pn_dir='mitdb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a0e8cf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.145, -0.145, -0.145, ..., -0.41 , -0.415, -0.425],\n",
       "      shape=(25002,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get input signal u(t) from the first channel\n",
    "u = record.p_signal[:, 0] \n",
    "u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "93538ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize input\n",
    "u_min = np.min(u)\n",
    "u_max = np.max(u)\n",
    "u_norm = (u - u_min) / (u_max - u_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6dfcd0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = record.fs  # sampling frequency (should be 360 Hz)\n",
    "t_vals = np.arange(len(u_norm)) / fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef734865",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_dim = 3\n",
    "# inputs = u_norm\n",
    "inputs = create_delay_embedding(u_norm, emb_dim)\n",
    "\n",
    "# Create target array (heartbeat locations)\n",
    "targets = np.zeros(len(u_norm))\n",
    "targets[annotation.sample] = 1  # mark annotations as 1 (heartbeat)\n",
    "targets = create_delay_embedding(targets, emb_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "938389fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 25000, train size: 15000, test size: 9999\n"
     ]
    }
   ],
   "source": [
    "data_size = len(inputs)\n",
    "train_size = 15000\n",
    "train_input = inputs[:train_size]\n",
    "train_target = targets[:train_size]\n",
    "test_input = inputs[train_size+1:]\n",
    "test_target = targets[train_size+1:]\n",
    "test_size = len(test_input)\n",
    "print(f\"Total samples: {data_size}, train size: {train_size}, test size: {test_size}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "218cb6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = []\n",
    "# step = 5\n",
    "# for a in range(5, 101, step):\n",
    "#     for b in range(a + step, 111, step):\n",
    "#         for c in range(b + step, 121, step):\n",
    "#             for d in range(c + step, 131, step):\n",
    "#                 for e in range(d + step, 141, step):\n",
    "#                     for f in range(e + step, 151, step):\n",
    "#                         for g in range(f + step, 161, step):\n",
    "#                             for h in range(g + step, 171, step):\n",
    "#                                 i = 300 - a - b - c - d - e - f - g - h\n",
    "#                                 if i > h and i % step == 0 and i <= 300:\n",
    "#                                     result.append([a, b, c, d, e, f, g, h, i])\n",
    "\n",
    "# print(result)\n",
    "# print(f\"Total unique combinations: {len(result)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df4b7772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid = {\n",
    "#     \"cells_per_level\": [[5, 10, 20, 25, 30, 35, 40, 60, 75, 90, 110]],\n",
    "#     \"spectral_radius\": [0.92],\n",
    "#     \"input_scale\": [0.1],\n",
    "#     \"leaking_rate\": [0.1],\n",
    "#     \"ridge_alpha\": [1e-8],\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f2f85de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "horizons = [300, 600, 1000]\n",
    "\n",
    "nrmse_dict = defaultdict(list)\n",
    "seeds = range(995, 1025)\n",
    "\n",
    "for seed in seeds:\n",
    "    sph_res = MPPRN(\n",
    "        reservoir_size        = 300,      # total neurons  (must be multiple of 3)\n",
    "        cycle_weight          = 0.001,      # r  weight on each edge of the three base cycles\n",
    "        bridge_weight         = 0.02,     # s  weight on the three inter-cycle “bridge” edges\n",
    "        input_scale           = 1.4,      # |W_in| multiplier   (was 0.5 by default)\n",
    "        leak_rate             = 0.8,      # α  leaky-integrator coefficient (1.0 ⇒ no leak)\n",
    "        ridge_alpha           = 1e-6,     #  penalty for the read-out ridge regression\n",
    "        swirl_beta            = 12.5,      # β  controls the steepness of the swirl gate\n",
    "        swirl_frequency       = None,     # ω  spatial frequency (defaults to 2π / (N/3))\n",
    "        swirl_sigmoid         = True,     # if False, uses raw sin; if True, uses σ(β sin(…))\n",
    "        seed                  = seed,       # seed \n",
    "        use_polynomial_readout= True      # augment read-out with square andd bias\n",
    "    )\n",
    "    sph_res.fit_readout(train_input, train_target, discard=5000)\n",
    "    hfr_preds = sph_res.predict_open_loop(test_input)\n",
    "    hfr_nrmse = evaluate_nrmse(hfr_preds, test_target, horizons)\n",
    "    nrmse_dict['HFR'].append(hfr_nrmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "337c012a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NRMSE for Different Prediction Horizons:\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "MPPRN            \n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "300        0.7022629698063398 ± 0.014567439239971258\n",
      "600        0.7459315376743182 ± 0.013617995792092273\n",
      "1000       0.8978069973191508 ± 0.011526372960124492\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nNRMSE for Different Prediction Horizons:\")\n",
    "print(\"-\" * 140)\n",
    "print(f\"{'MPPRN':<17}\")\n",
    "print(\"-\" * 140)\n",
    "\n",
    "for horizon in horizons:\n",
    "    hfr_vals = [np.mean(hfr_nrmse[horizon]) for hfr_nrmse in nrmse_dict['HFR']]\n",
    "\n",
    "    print(f\"{horizon:<10}\", end=\" \")\n",
    "    for vals in [hfr_vals]:\n",
    "        mean = np.mean(vals)\n",
    "        std = np.std(vals)\n",
    "        print(f\"{mean} ± {std}\".ljust(18), end=\"\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "60917d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def run_grid_search(model_class, param_grid, model_name,\n",
    "#                     output_path=\"grid_search_results.json\"):\n",
    "#     # Precompute param combinations\n",
    "#     combos = list(itertools.product(*param_grid.values()))\n",
    "#     param_keys = list(param_grid.keys())\n",
    "#     print(f\"\\n== Initial grid search for {model_name} with {len(combos)} combinations ==\")\n",
    "\n",
    "#     results = []\n",
    "#     horizons = [300, 600, 1000]\n",
    "#     seeds = range(995, 1025)\n",
    "#     # tqdm adds a progress bar for better visualization\n",
    "#     for comb in tqdm(combos, desc=\"Grid Search\"):\n",
    "#         params = dict(zip(param_keys, comb))\n",
    "#         seed_scores = []\n",
    "#         for seed in seeds:\n",
    "#             model = model_class(seed=seed, **params)\n",
    "#             model.fit_readout(train_input, train_target, discard=5000)\n",
    "#             preds = model.predict_open_loop(test_input)\n",
    "#             nrmse = evaluate_nrmse(preds, test_target, horizons)\n",
    "#             seed_scores.append(nrmse)\n",
    "\n",
    "#         results.append({\n",
    "#             \"params\": params,\n",
    "#             \"scores\": seed_scores\n",
    "#         })\n",
    "\n",
    "#     return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7df19d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = run_grid_search(\n",
    "#     HFRRes3D,\n",
    "#     grid,\n",
    "#     model_name=\"HFRRes3D\",\n",
    "#     output_path=\"hfr_grid_search_results.json\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b3ab10bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d21c45b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "87f6a7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# rows = []\n",
    "# for entry in results:\n",
    "#     params = entry[\"params\"]\n",
    "#     scores = entry[\"scores\"]\n",
    "\n",
    "#     # Convert list of dicts to dict of lists per horizon\n",
    "#     all_scores = {300: [], 600: [], 1000: []}\n",
    "#     for score_dict in scores:\n",
    "#         for h in all_scores:\n",
    "#             all_scores[h].append(score_dict[h])\n",
    "\n",
    "#     # Compute mean and std for each horizon\n",
    "#     row = params.copy()\n",
    "#     for h in all_scores:\n",
    "#         values = np.array(all_scores[h])\n",
    "#         row[f\"nrmse_{h}_mean\"] = values.mean()\n",
    "#         row[f\"nrmse_{h}_std\"] = values.std()\n",
    "\n",
    "#     rows.append(row)\n",
    "\n",
    "# # Convert to DataFrame\n",
    "# df = pd.DataFrame(rows)\n",
    "\n",
    "# # Optional: Convert list-type params to string if needed\n",
    "# if 'cells_per_level' in df.columns:\n",
    "#     df['cells_per_level'] = df['cells_per_level'].apply(str)\n",
    "\n",
    "# # Save to CSV\n",
    "# df.to_csv(\"results.csv\", index=False)\n",
    "# print(\"Saved to grid_search_results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39c1e20",
   "metadata": {},
   "source": [
    "# Sunspot Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3232502c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1749</td>\n",
       "      <td>1</td>\n",
       "      <td>1749.042</td>\n",
       "      <td>96.7</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1749</td>\n",
       "      <td>2</td>\n",
       "      <td>1749.123</td>\n",
       "      <td>104.3</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1749</td>\n",
       "      <td>3</td>\n",
       "      <td>1749.204</td>\n",
       "      <td>116.7</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1749</td>\n",
       "      <td>4</td>\n",
       "      <td>1749.288</td>\n",
       "      <td>92.8</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1749</td>\n",
       "      <td>5</td>\n",
       "      <td>1749.371</td>\n",
       "      <td>141.7</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3310</th>\n",
       "      <td>2024</td>\n",
       "      <td>11</td>\n",
       "      <td>2024.873</td>\n",
       "      <td>152.5</td>\n",
       "      <td>20.9</td>\n",
       "      <td>681</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3311</th>\n",
       "      <td>2024</td>\n",
       "      <td>12</td>\n",
       "      <td>2024.958</td>\n",
       "      <td>154.5</td>\n",
       "      <td>25.6</td>\n",
       "      <td>572</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3312</th>\n",
       "      <td>2025</td>\n",
       "      <td>1</td>\n",
       "      <td>2025.042</td>\n",
       "      <td>137.0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>670</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3313</th>\n",
       "      <td>2025</td>\n",
       "      <td>2</td>\n",
       "      <td>2025.122</td>\n",
       "      <td>154.6</td>\n",
       "      <td>23.3</td>\n",
       "      <td>655</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3314</th>\n",
       "      <td>2025</td>\n",
       "      <td>3</td>\n",
       "      <td>2025.204</td>\n",
       "      <td>134.2</td>\n",
       "      <td>20.4</td>\n",
       "      <td>1011</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3315 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0   1         2      3     4     5  6\n",
       "0     1749   1  1749.042   96.7  -1.0    -1  1\n",
       "1     1749   2  1749.123  104.3  -1.0    -1  1\n",
       "2     1749   3  1749.204  116.7  -1.0    -1  1\n",
       "3     1749   4  1749.288   92.8  -1.0    -1  1\n",
       "4     1749   5  1749.371  141.7  -1.0    -1  1\n",
       "...    ...  ..       ...    ...   ...   ... ..\n",
       "3310  2024  11  2024.873  152.5  20.9   681  0\n",
       "3311  2024  12  2024.958  154.5  25.6   572  0\n",
       "3312  2025   1  2025.042  137.0  23.3   670  0\n",
       "3313  2025   2  2025.122  154.6  23.3   655  0\n",
       "3314  2025   3  2025.204  134.2  20.4  1011  0\n",
       "\n",
       "[3315 rows x 7 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "file_path = 'datasets/SN_m_tot_V2.0.csv'\n",
    "\n",
    "df = pd.read_csv(file_path, sep=';', header = None)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "98f8602b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 3315\n",
      "Train size: 2000\n",
      "Test size: 1312\n"
     ]
    }
   ],
   "source": [
    "data = df.iloc[:, 3].values\n",
    "dt = 1\n",
    "dataset_size = len(data)\n",
    "data = create_delay_embedding(data, 3)\n",
    "print(f\"Dataset size: {dataset_size}\")\n",
    "\n",
    "# Train/Test Split\n",
    "train_end = 2000\n",
    "train_input  = data[:train_end]\n",
    "train_target = data[1:train_end+1]\n",
    "test_input   = data[train_end:-1]\n",
    "test_target  = data[train_end+1:]\n",
    "y_test = test_target\n",
    "n_test_steps = len(test_target)\n",
    "time_test = np.arange(n_test_steps) * dt\n",
    "\n",
    "print(f\"Train size: {len(train_input)}\\nTest size: {len(test_input)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7684b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_horizons = list(range(10, 1001, 10))\n",
    "# horizons = [300, 600, 1000]\n",
    "\n",
    "\n",
    "# nrmse_dict = defaultdict(list)\n",
    "# seeds = range(995, 1025)\n",
    "\n",
    "# for seed in seeds:\n",
    "#     sph_res = MPPRN(\n",
    "#         reservoir_size        = 500,      # total neurons  (must be multiple of 3)\n",
    "#         n_cycles              = 5,\n",
    "#         cycle_weight          = 0.00001,      # r  weight on each edge of the three base cycles\n",
    "#         bridge_weight         = 0.02,     # s  weight on the three inter-cycle “bridge” edges\n",
    "#         input_scale           = 1.1,     # |W_in| multiplier   (was 0.5 by default)\n",
    "#         leak_rate             = 0.5,      # α  leaky-integrator coefficient (1.0 ⇒ no leak)\n",
    "#         ridge_alpha           = 1e-8,     #  penalty for the read-out ridge regression\n",
    "#         swirl_beta            = 150,    # β  controls the steepness of the swirl gate\n",
    "#         swirl_frequency       = None,     # ω  spatial frequency (defaults to 2π / (N/3))\n",
    "#         swirl_sigmoid         = True,     # if False, uses raw sin; if True, uses σ(β sin(…))\n",
    "#         seed                  = seed,       # seed \n",
    "#         use_polynomial_readout= True      # augment read-out with square andd bias\n",
    "#     )\n",
    "#     sph_res.fit_readout(train_input, train_target, discard=100)\n",
    "#     hfr_preds = sph_res.predict_open_loop(test_input)\n",
    "#     hfr_nrmse = evaluate_nrmse(hfr_preds, test_target, horizons)\n",
    "#     nrmse_dict['HFR'].append(hfr_nrmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0286627c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_horizons = list(range(10, 1001, 10))\n",
    "horizons = [300, 600, 1000]\n",
    "\n",
    "\n",
    "nrmse_dict = defaultdict(list)\n",
    "seeds = range(995, 1025)\n",
    "\n",
    "for seed in seeds:\n",
    "    sph_res = MPPRN(\n",
    "        reservoir_size        = 300,      # total neurons  (must be multiple of 3)\n",
    "        n_cycles              = 5,\n",
    "        cycle_weight          = 0.001,      # r  weight on each edge of the three base cycles\n",
    "        bridge_weight         = 0.02,     # s  weight on the three inter-cycle “bridge” edges\n",
    "        input_scale           = 1.1,     # |W_in| multiplier   (was 0.5 by default)\n",
    "        leak_rate             = 0.5,      # α  leaky-integrator coefficient (1.0 ⇒ no leak)\n",
    "        ridge_alpha           = 1e-8,     #  penalty for the read-out ridge regression\n",
    "        swirl_beta            = 30,    # β  controls the steepness of the swirl gate\n",
    "        swirl_frequency       = None,     # ω  spatial frequency (defaults to 2π / (N/3))\n",
    "        swirl_sigmoid         = True,     # if False, uses raw sin; if True, uses σ(β sin(…))\n",
    "        seed                  = seed,       # seed \n",
    "        use_polynomial_readout= True      # augment read-out with square andd bias\n",
    "    )\n",
    "    sph_res.fit_readout(train_input, train_target, discard=100)\n",
    "    hfr_preds = sph_res.predict_open_loop(test_input)\n",
    "    hfr_nrmse = evaluate_nrmse(hfr_preds, test_target, horizons)\n",
    "    nrmse_dict['HFR'].append(hfr_nrmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "daaef00f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NRMSE for Different Prediction Horizons:\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "MPPRN            \n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "300        0.4655008525792734 ± 0.008749936126559478\n",
      "600        0.4143967930574644 ± 0.01350331943196619\n",
      "1000       0.39965414442413544 ± 0.009597118893105184\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nNRMSE for Different Prediction Horizons:\")\n",
    "print(\"-\" * 140)\n",
    "print(f\"{'MPPRN':<17}\")\n",
    "print(\"-\" * 140)\n",
    "\n",
    "for horizon in horizons:\n",
    "    hfr_vals = [np.mean(hfr_nrmse[horizon]) for hfr_nrmse in nrmse_dict['HFR']]\n",
    "\n",
    "    print(f\"{horizon:<10}\", end=\" \")\n",
    "    for vals in [hfr_vals]:\n",
    "        mean = np.mean(vals)\n",
    "        std = np.std(vals)\n",
    "        print(f\"{mean} ± {std}\".ljust(18), end=\"\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e6ee32",
   "metadata": {},
   "source": [
    "# Sante Fe Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2407cfd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>76.53</td>\n",
       "      <td>8320</td>\n",
       "      <td>7771</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>76.53</td>\n",
       "      <td>8117</td>\n",
       "      <td>7774</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>76.15</td>\n",
       "      <td>7620</td>\n",
       "      <td>7788</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>75.39</td>\n",
       "      <td>6413</td>\n",
       "      <td>7787</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75.51</td>\n",
       "      <td>7518</td>\n",
       "      <td>7767</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16995</th>\n",
       "      <td>73.57</td>\n",
       "      <td>16021</td>\n",
       "      <td>6498</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16996</th>\n",
       "      <td>73.79</td>\n",
       "      <td>-6957</td>\n",
       "      <td>6547</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16997</th>\n",
       "      <td>74.54</td>\n",
       "      <td>11476</td>\n",
       "      <td>6576</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16998</th>\n",
       "      <td>74.36</td>\n",
       "      <td>15058</td>\n",
       "      <td>6573</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16999</th>\n",
       "      <td>72.91</td>\n",
       "      <td>13510</td>\n",
       "      <td>6676</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0      1     2   3\n",
       "0      76.53   8320  7771 NaN\n",
       "1      76.53   8117  7774 NaN\n",
       "2      76.15   7620  7788 NaN\n",
       "3      75.39   6413  7787 NaN\n",
       "4      75.51   7518  7767 NaN\n",
       "...      ...    ...   ...  ..\n",
       "16995  73.57  16021  6498 NaN\n",
       "16996  73.79  -6957  6547 NaN\n",
       "16997  74.54  11476  6576 NaN\n",
       "16998  74.36  15058  6573 NaN\n",
       "16999  72.91  13510  6676 NaN\n",
       "\n",
       "[17000 rows x 4 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = 'datasets/santa-fe-time-series-competition-data-set-b-1.0.0/b1.txt'\n",
    "\n",
    "df = pd.read_csv(file_path, header=None, sep=' ')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b5624624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the first column (column 0) of the DataFrame\n",
    "df[0] = (df[0] - df[0].min()) / (df[0].max() - df[0].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ae5bf803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data length: 17000.\n",
      "Train size: 7000  \n",
      "Test size: 9997\n"
     ]
    }
   ],
   "source": [
    "data = df.iloc[:, 0].values\n",
    "chosen_system = \"SantaFe\"\n",
    "dt = 1\n",
    "T_data = len(data)\n",
    "data = create_delay_embedding(data, 3)\n",
    "print(f\"Data length: {T_data}.\")\n",
    "\n",
    "# Train/Test Split\n",
    "train_end = 7000\n",
    "train_input  = data[:train_end]\n",
    "train_target = data[1:train_end+1]\n",
    "test_input   = data[train_end:-1]\n",
    "test_target  = data[train_end+1:]\n",
    "y_test = test_target\n",
    "n_test_steps = len(test_target)\n",
    "time_test = np.arange(n_test_steps) * dt\n",
    "\n",
    "print(f\"Train size: {len(train_input)}  \\nTest size: {len(test_input)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5900d956",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_horizons = list(range(10, 1001, 10))\n",
    "horizons = [300, 600, 1000]\n",
    "\n",
    "\n",
    "nrmse_dict = defaultdict(list)\n",
    "seeds = range(995, 1025)\n",
    "\n",
    "for seed in seeds:\n",
    "    sph_res = MPPRN(\n",
    "        reservoir_size        = 300,      # total neurons  (must be multiple of 3)\n",
    "        n_cycles              = 5,\n",
    "        cycle_weight          = 0.001,      # r  weight on each edge of the three base cycles\n",
    "        bridge_weight         = 0.02,     # s  weight on the three inter-cycle “bridge” edges\n",
    "        input_scale           = 1.1,     # |W_in| multiplier   (was 0.5 by default)\n",
    "        leak_rate             = 0.5,      # α  leaky-integrator coefficient (1.0 ⇒ no leak)\n",
    "        ridge_alpha           = 1e-8,     #  penalty for the read-out ridge regression\n",
    "        swirl_beta            = 50,    # β  controls the steepness of the swirl gate\n",
    "        swirl_frequency       = None,     # ω  spatial frequency (defaults to 2π / (N/3))\n",
    "        swirl_sigmoid         = True,     # if False, uses raw sin; if True, uses σ(β sin(…))\n",
    "        seed                  = seed,       # seed \n",
    "        use_polynomial_readout= True      # augment read-out with square andd bias\n",
    "    )\n",
    "    sph_res.fit_readout(train_input, train_target, discard=100)\n",
    "    hfr_preds = sph_res.predict_open_loop(test_input)\n",
    "    hfr_nrmse = evaluate_nrmse(hfr_preds, test_target, horizons)\n",
    "    nrmse_dict['HFR'].append(hfr_nrmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4a243d60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NRMSE for Different Prediction Horizons:\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "MPPR-N           \n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "300        0.2493345548207022 ± 0.0007499412002111277\n",
      "600        0.2193263750740337 ± 0.0004027635001078921\n",
      "1000       0.23542138838365562 ± 0.0003896402061993685\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nNRMSE for Different Prediction Horizons:\")\n",
    "print(\"-\" * 140)\n",
    "print(f\"{'MPPR-N':<17}\")\n",
    "print(\"-\" * 140)\n",
    "\n",
    "\n",
    "for horizon in horizons:\n",
    "    hfr_vals = [np.mean(hfr_nrmse[horizon]) for hfr_nrmse in nrmse_dict['HFR']]\n",
    "\n",
    "    print(f\"{horizon:<10}\", end=\" \")\n",
    "    for vals in [hfr_vals]:\n",
    "        mean = np.mean(vals)\n",
    "        std = np.std(vals)\n",
    "        print(f\"{mean} ± {std}\".ljust(18), end=\"\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe19f3ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
