{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import Ridge\nimport itertools\nfrom scipy.integrate import odeint\nfrom sklearn.preprocessing import StandardScaler","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T04:56:50.989849Z","iopub.execute_input":"2025-04-17T04:56:50.990153Z","iopub.status.idle":"2025-04-17T04:56:51.811986Z","shell.execute_reply.started":"2025-04-17T04:56:50.990126Z","shell.execute_reply":"2025-04-17T04:56:51.811054Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def compute_valid_prediction_time(y_true, y_pred, t_vals, threshold, lambda_max, dt):\n    \"\"\"\n    Compute the Valid Prediction Time (VPT) and compare it to Lyapunov time T_lambda = 1 / lambda_max.\n    \n    Parameters\n    ----------\n    y_true : ndarray of shape (N, dim)\n        True trajectory over time.\n    y_pred : ndarray of shape (N, dim)\n        Model's predicted trajectory over time (closed-loop).\n    t_vals : ndarray of shape (N,)\n        Time values corresponding to the trajectory steps.\n    threshold : float, optional\n        The error threshold, default is 0.4 as in your snippet.\n    lambda_max : float, optional\n        Largest Lyapunov exponent. Default=0.9 for Lorenz.\n        \n    Returns\n    -------\n    T_VPT : float\n        Valid prediction time. The earliest time at which normalized error surpasses threshold\n        (or the last time if never surpassed).\n    T_lambda : float\n        Lyapunov time = 1 / lambda_max\n    ratio : float\n        How many Lyapunov times the model prediction remains valid, i.e. T_VPT / T_lambda.\n    \"\"\"\n    # 1) Average of y_true\n    y_mean = np.mean(y_true, axis=0)  # shape (dim,)\n    \n    # 2) Time-averaged norm^2 of (y_true - y_mean)\n    y_centered = y_true - y_mean\n    denom = np.mean(np.sum(y_centered**2, axis=1))  # scalar\n    \n    # 3) Compute the normalized error delta_gamma(t) = ||y_true - y_pred||^2 / denom\n    diff = y_true - y_pred\n    err_sq = np.sum(diff**2, axis=1)  # shape (N,)\n    delta_gamma = err_sq / denom      # shape (N,)\n    \n    # 4) Find the first time index where delta_gamma(t) exceeds threshold\n    idx_exceed = np.where(delta_gamma > threshold)[0]\n    if len(idx_exceed) == 0:\n        # never exceeds threshold => set T_VPT to the final time\n        T_VPT = t_vals[-1]\n    else:\n        T_VPT = t_vals[idx_exceed[0]]\n    \n    # 5) Compute T_lambda and ratio\n    T_lambda = 1.0 / lambda_max\n\n    # print(f\"\\n--- Valid Prediction Time (VPT) with threshold={threshold}, lambda_max={lambda_max} ---\")\n\n    T_VPT = (T_VPT - t_vals[0])  # Adjust T_VPT to be relative to the start time\n    ratio = T_VPT / T_lambda\n\n    return T_VPT, T_lambda, ratio","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T04:56:58.922621Z","iopub.execute_input":"2025-04-17T04:56:58.923108Z","iopub.status.idle":"2025-04-17T04:56:58.930947Z","shell.execute_reply.started":"2025-04-17T04:56:58.923075Z","shell.execute_reply":"2025-04-17T04:56:58.929923Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def scale_spectral_radius(W, target_radius=0.95):\n    \"\"\"\n    Scales a matrix W so that its largest eigenvalue magnitude = target_radius.\n    \"\"\"\n    eigvals = np.linalg.eigvals(W)\n    radius = np.max(np.abs(eigvals))\n    if radius == 0:\n        return W\n    return (W / radius) * target_radius","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T04:57:02.886484Z","iopub.execute_input":"2025-04-17T04:57:02.886762Z","iopub.status.idle":"2025-04-17T04:57:02.891412Z","shell.execute_reply.started":"2025-04-17T04:57:02.886743Z","shell.execute_reply":"2025-04-17T04:57:02.890682Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def augment_state_with_squares(x):\n    \"\"\"\n    Given state vector x in R^N, return [ x, x^2, 1 ] in R^(2N+1).\n    We'll use this for both training and prediction.\n    \"\"\"\n    x_sq = x**2\n    return np.concatenate([x, x_sq, [1.0]])  # shape: 2N+1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T04:57:04.072416Z","iopub.execute_input":"2025-04-17T04:57:04.072756Z","iopub.status.idle":"2025-04-17T04:57:04.077318Z","shell.execute_reply.started":"2025-04-17T04:57:04.072732Z","shell.execute_reply":"2025-04-17T04:57:04.076551Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class ESN3D:\n    \"\"\"\n    Dense random ESN for 3D->3D single-step.\n    Teacher forcing for training, autoregressive for testing.\n    \"\"\"\n    def __init__(self,\n                 reservoir_size=300,\n                 spectral_radius=0.95,\n                 input_scale=1.0,\n                 leaking_rate=1.0,\n                 ridge_alpha=1e-6,\n                 seed=42):\n        self.reservoir_size = reservoir_size\n        self.spectral_radius = spectral_radius\n        self.input_scale = input_scale\n        self.leaking_rate = leaking_rate\n        self.ridge_alpha = ridge_alpha\n        self.seed = seed\n\n        np.random.seed(self.seed)\n        W = np.random.randn(reservoir_size, reservoir_size)*0.1\n        W = scale_spectral_radius(W, self.spectral_radius)\n        self.W = W\n\n        np.random.seed(self.seed+1)\n        self.W_in = (np.random.rand(reservoir_size,3) - 0.5)*2.0*self.input_scale\n        # self.W_in = np.random.uniform(-self.input_scale, self.input_scale, (reservoir_size, 3))\n\n        self.W_out = None\n        self.x = np.zeros(reservoir_size)\n\n    def reset_state(self):\n        self.x = np.zeros(self.reservoir_size)\n\n    def _update(self, u):\n        pre_activation = self.W @ self.x + self.W_in @ u\n        x_new = np.tanh(pre_activation)\n        alpha = self.leaking_rate\n        self.x = (1.0 - alpha)*self.x + alpha*x_new\n\n    def collect_states(self, inputs, discard=100):\n        self.reset_state()\n        states = []\n        for val in inputs:\n            self._update(val)\n            states.append(self.x.copy())\n        states = np.array(states)\n        return states[discard:], states[:discard]\n\n    def fit_readout(self, train_input, train_target, discard=100):\n        states_use, _ = self.collect_states(train_input, discard=discard)\n        targets_use = train_target[discard:]\n        # X_aug = np.hstack([states_use, np.ones((states_use.shape[0],1))])\n\n        # polynomial readout\n        X_list = []\n        for s in states_use:\n            X_list.append(augment_state_with_squares(s))\n        X_aug = np.array(X_list)  # shape => [T-discard, 2N+1]\n\n        reg = Ridge(alpha=self.ridge_alpha, fit_intercept=False)\n        reg.fit(X_aug, targets_use)\n        self.W_out = reg.coef_\n\n    def predict_autoregressive(self, initial_input, n_steps):\n        preds = []\n        current_in = np.array(initial_input)\n        for _ in range(n_steps):\n            self._update(current_in)\n            # x_aug = np.concatenate([self.x, [1.0]])\n            x_aug = augment_state_with_squares(self.x)\n            out = self.W_out @ x_aug\n            preds.append(out)\n            current_in = out\n        return np.array(preds)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T04:57:05.98827Z","iopub.execute_input":"2025-04-17T04:57:05.988604Z","iopub.status.idle":"2025-04-17T04:57:06.001005Z","shell.execute_reply.started":"2025-04-17T04:57:05.988576Z","shell.execute_reply":"2025-04-17T04:57:06.000201Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class SparseESN3D:\n    \"\"\"\n    Sparse random ESN for 3D->3D single-step,\n    teacher forcing for training, autoregressive for testing.\n    \"\"\"\n    def __init__(self,\n                 reservoir_size=300,\n                 spectral_radius=0.95,\n                 connectivity=0.05,\n                 input_scale=1.0,\n                 leaking_rate=1.0,\n                 ridge_alpha=1e-6,\n                 seed=42):\n        self.reservoir_size = reservoir_size\n        self.spectral_radius = spectral_radius\n        self.connectivity = connectivity\n        self.input_scale = input_scale\n        self.leaking_rate = leaking_rate\n        self.ridge_alpha = ridge_alpha\n        self.seed = seed\n\n        np.random.seed(self.seed)\n        W_full = np.random.randn(reservoir_size, reservoir_size)*0.1\n        mask = (np.random.rand(reservoir_size, reservoir_size) < self.connectivity)\n        W = W_full * mask\n        W = scale_spectral_radius(W, self.spectral_radius)\n        self.W = W\n\n        np.random.seed(self.seed+1)\n        self.W_in = (np.random.rand(reservoir_size,3) - 0.5)*2.0*self.input_scale\n\n        self.W_out = None\n        self.x = np.zeros(reservoir_size)\n\n    def reset_state(self):\n        self.x = np.zeros(self.reservoir_size)\n\n    def _update(self, u):\n        pre_activation = self.W @ self.x + self.W_in @ u\n        x_new = np.tanh(pre_activation)\n        alpha = self.leaking_rate\n        self.x = (1.0 - alpha)*self.x + alpha*x_new\n\n    def collect_states(self, inputs, discard=100):\n        self.reset_state()\n        states = []\n        for val in inputs:\n            self._update(val)\n            states.append(self.x.copy())\n        states = np.array(states)\n        return states[discard:], states[:discard]\n\n    def fit_readout(self, train_input, train_target, discard=100):\n        states_use, _ = self.collect_states(train_input, discard=discard)\n        targets_use = train_target[discard:]\n        # X_aug = np.hstack([states_use, np.ones((states_use.shape[0],1))])\n\n        # polynomial readout\n        X_list = []\n        for s in states_use:\n            X_list.append(augment_state_with_squares(s))\n        X_aug = np.array(X_list)  # shape => [T-discard, 2N+1]\n\n        reg = Ridge(alpha=self.ridge_alpha, fit_intercept=False)\n        reg.fit(X_aug, targets_use)\n        self.W_out = reg.coef_\n\n    def predict_autoregressive(self, initial_input, n_steps):\n        preds = []\n        current_in = np.array(initial_input)\n        for _ in range(n_steps):\n            self._update(current_in)\n            # x_aug = np.concatenate([self.x, [1.0]])\n            x_aug = augment_state_with_squares(self.x)\n            out = self.W_out @ x_aug\n            preds.append(out)\n            current_in = out\n        return np.array(preds)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T04:57:09.189061Z","iopub.execute_input":"2025-04-17T04:57:09.189628Z","iopub.status.idle":"2025-04-17T04:57:09.201106Z","shell.execute_reply.started":"2025-04-17T04:57:09.1896Z","shell.execute_reply":"2025-04-17T04:57:09.200256Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class CR3D:\n    \"\"\"\n    Cycle (ring) reservoir for 3D->3D single-step,\n    teacher forcing for training, autoregressive for testing.\n    \"\"\"\n    def __init__(self,\n                 reservoir_size=300,\n                 spectral_radius=0.95,\n                 input_scale=1.0,\n                 leaking_rate=1.0,\n                 ridge_alpha=1e-6,\n                 seed=42):\n        self.reservoir_size = reservoir_size\n        self.spectral_radius = spectral_radius\n        self.input_scale = input_scale\n        self.leaking_rate = leaking_rate\n        self.ridge_alpha = ridge_alpha\n        self.seed = seed\n\n        np.random.seed(self.seed)\n        W = np.zeros((reservoir_size, reservoir_size))\n        for i in range(reservoir_size):\n            j = (i+1) % reservoir_size\n            W[i, j] = 1.0\n        W = scale_spectral_radius(W, self.spectral_radius)\n        self.W = W\n        \n        np.random.seed(self.seed+1)\n        self.W_in = (np.random.rand(reservoir_size,3) - 0.5)*2.0*self.input_scale\n\n        self.W_out = None\n        self.x = np.zeros(reservoir_size)\n\n    def reset_state(self):\n        self.x = np.zeros(self.reservoir_size)\n\n    def _update(self, u):\n        pre_activation = self.W @ self.x + self.W_in @ u\n        x_new = np.tanh(pre_activation)\n        alpha = self.leaking_rate\n        self.x = (1.0 - alpha)*self.x + alpha*x_new\n\n    def collect_states(self, inputs, discard=100):\n        self.reset_state()\n        states = []\n        for val in inputs:\n            self._update(val)\n            states.append(self.x.copy())\n        states = np.array(states)\n        return states[discard:], states[:discard]\n\n    def fit_readout(self, train_input, train_target, discard=100):\n        states_use, _ = self.collect_states(train_input, discard=discard)\n        targets_use = train_target[discard:]\n        # X_aug = np.hstack([states_use, np.ones((states_use.shape[0],1))])\n\n        # polynomial readout\n        X_list = []\n        for s in states_use:\n            X_list.append(augment_state_with_squares(s))\n        X_aug = np.array(X_list)  # shape => [T-discard, 2N+1]\n\n        reg = Ridge(alpha=self.ridge_alpha, fit_intercept=False)\n        reg.fit(X_aug, targets_use)\n        self.W_out = reg.coef_\n\n    def predict_autoregressive(self, initial_input, n_steps):\n        preds = []\n        current_in = np.array(initial_input)\n        for _ in range(n_steps):\n            self._update(current_in)\n            # x_aug = np.concatenate([self.x, [1.0]])\n            x_aug = augment_state_with_squares(self.x)\n            out = self.W_out @ x_aug\n            preds.append(out)\n            current_in = out\n        return np.array(preds)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T04:57:12.748726Z","iopub.execute_input":"2025-04-17T04:57:12.749492Z","iopub.status.idle":"2025-04-17T04:57:12.760229Z","shell.execute_reply.started":"2025-04-17T04:57:12.749455Z","shell.execute_reply":"2025-04-17T04:57:12.75939Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def lorenz_deriv(state, t, sigma=10.0, rho=28.0, beta=8.0/3.0):\n    x, y, z = state\n    dxdt = sigma * (y - x)\n    dydt = x*(rho - z) - y\n    dzdt = x*y - beta*z\n    return [dxdt, dydt, dzdt]\n\ndef generate_lorenz_data(\n    initial_state=[1.0, 1.0, 1.0],\n    tmax=25.0,\n    dt=0.01,\n    sigma=10.0,\n    rho=28.0,\n    beta=8.0/3.0\n):\n    num_steps = int(tmax / dt) + 1 # +1 to include t=0\n    t_vals = np.linspace(0, tmax, num_steps)\n    sol = odeint(lorenz_deriv, initial_state, t_vals, args=(sigma, rho, beta))\n    return t_vals, sol\n\ndef report_vpt(name, preds, test_target, time_test, dt):\n    T_VPT, T_lambda, ratio = compute_valid_prediction_time(\n        test_target, preds, time_test, threshold=0.4, lambda_max=0.9, dt=dt\n    )\n    # print(f\"{name:20s} => T_VPT={T_VPT:.3f},  T_lambda={T_lambda:.3f}, ratio={ratio:.3f}\")\n    return T_VPT, T_lambda, ratio\n\ntmax = 250\ndt   = 0.02\nt_vals, lorenz_traj = generate_lorenz_data(\n    initial_state=[1.0,1.0,1.0],\n    tmax=tmax,\n    dt=dt\n)\n\nwashout = 2000\nt_vals = t_vals[washout:]\nlorenz_traj = lorenz_traj[washout:]\n\n# normalize\nscaler = StandardScaler()\nscaler.fit(lorenz_traj)\nlorenz_traj = scaler.transform(lorenz_traj)\n\nT_data = len(lorenz_traj)\nprint(f\"Data length: {T_data}, from t=0..{tmax} with dt={dt}.\")\n\nn_test_steps = 2100\n\n# train/test split\ntrain_frac = 0.8\ntrain_end = int(train_frac*(T_data-1))\ntrain_input  = lorenz_traj[:train_end]\ntrain_target = lorenz_traj[1:train_end+1]\ntest_input   = lorenz_traj[train_end:train_end+n_test_steps]\ntest_target  = lorenz_traj[train_end+1:train_end+n_test_steps+1]\nprint(f\"Train size: {len(train_input)}  Test size: {len(test_input)}\")\n\ninitial_in = test_input[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T04:57:19.942391Z","iopub.execute_input":"2025-04-17T04:57:19.943035Z","iopub.status.idle":"2025-04-17T04:57:20.063401Z","shell.execute_reply.started":"2025-04-17T04:57:19.943008Z","shell.execute_reply":"2025-04-17T04:57:20.06259Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# (a) Baseline ESN\nesn = ESN3D(\n    reservoir_size=300,\n    spectral_radius=0.1,\n    input_scale=0.1,\n    leaking_rate=0.9,\n    ridge_alpha=1e-09,\n    seed=42\n)\nesn.fit_readout(train_input, train_target, discard=100)\n\n# (b) Cycle Reservoir\ncycle_res = CR3D(\n    reservoir_size=300,\n    spectral_radius=0.8,\n    input_scale=0.4,\n    leaking_rate=0.5,\n    ridge_alpha=1e-05,\n    seed=43\n)\ncycle_res.fit_readout(train_input, train_target, discard=100)\n\n# (c) Sparse ESN\nsparse_res = SparseESN3D(\n    reservoir_size=300,\n    spectral_radius=0.95,\n    connectivity=0.04,\n    input_scale=1.0,\n    leaking_rate=0.8,\n    ridge_alpha=1e-9,\n    seed=44\n)\nsparse_res.fit_readout(train_input, train_target, discard=100)\n\nesn_preds    = esn.predict_autoregressive(initial_in, n_test_steps)\ncycle_preds  = cycle_res.predict_autoregressive(initial_in, n_test_steps)\nsparse_preds = sparse_res.predict_autoregressive(initial_in, n_test_steps)\n\na, _, _ = report_vpt(\"Dense ESN\",    esn_preds, test_target, t_vals[train_end:train_end+n_test_steps], dt)\nb, _, _ = report_vpt(\"Cycle Res\",  cycle_preds, test_target, t_vals[train_end:train_end+n_test_steps], dt)\nc, _, _ = report_vpt(\"Sparse ESN\",   sparse_preds, test_target, t_vals[train_end:train_end+n_test_steps], dt)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T04:57:22.448792Z","iopub.execute_input":"2025-04-17T04:57:22.449404Z","iopub.status.idle":"2025-04-17T04:57:24.267132Z","shell.execute_reply.started":"2025-04-17T04:57:22.449377Z","shell.execute_reply":"2025-04-17T04:57:24.266238Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define your parameter grids\nparam_grid_common = {\n    \"spectral_radius\": [0.8, 0.9, 0.95],\n    \"input_scale\": [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n    \"leaking_rate\": [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],\n    \"ridge_alpha\": [1e-6, 1e-7]\n}\n\nparam_grid_sparse = {\n    **param_grid_common,\n    \"connectivity\": [0.02, 0.04, 0.06, 0.08, 0.1, 0.2]\n}\n\ndef run_grid_search(model_class, param_grid, model_name):\n    scored_params = []\n    all_combinations = list(itertools.product(*param_grid.values()))\n\n    for comb in all_combinations:\n        params = dict(zip(param_grid.keys(), comb))\n        model = model_class(reservoir_size=300, **params)\n        model.fit_readout(train_input, train_target, discard=100)\n        preds = model.predict_autoregressive(initial_in, n_test_steps)\n        T_VPT, _, _ = report_vpt(\"model\", preds, test_target, t_vals[train_end:train_end+n_test_steps], dt)\n        scored_params.append((T_VPT, params))\n\n    params = sorted(scored_params, key=lambda x: x[0], reverse=True)\n\n    print(f\"results for {model_name}:\")\n    for i, (score, params) in enumerate(params):\n        print(f\"{i+1}) T_VPT={score:.3f} with params {params}\")\n\n    return params","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T05:00:17.420171Z","iopub.execute_input":"2025-04-17T05:00:17.421262Z","iopub.status.idle":"2025-04-17T05:00:17.429259Z","shell.execute_reply.started":"2025-04-17T05:00:17.421231Z","shell.execute_reply":"2025-04-17T05:00:17.428387Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"esn     = run_grid_search(ESN3D, param_grid_common, \"Dense ESN\")\ncr      = run_grid_search(CR3D, param_grid_common, \"Cycle Res\")\nsparse  = run_grid_search(SparseESN3D, param_grid_sparse, \"Sparse ESN\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-17T05:00:18.435855Z","iopub.execute_input":"2025-04-17T05:00:18.436237Z","execution_failed":"2025-04-17T05:00:37.216Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import json\n\n# def save_top2_results(filename, top2_results):\n#     # Convert np.float32/64 and any other non-serializables to basic types\n#     def convert(o):\n#         if isinstance(o, (np.float32, np.float64)):\n#             return float(o)\n#         return o\n    \n#     serializable_data = [\n#         {\"T_VPT\": float(score), \"params\": {k: convert(v) for k, v in params.items()}}\n#         for score, params in top2_results\n#     ]\n\n#     with open(filename, 'w') as f:\n#         json.dump(serializable_data, f, indent=4)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# save_top2_results(\"top2_esn.json\", esn)\n# save_top2_results(\"top2_cr.json\", cr)\n# save_top2_results(\"top2_sparse.json\", sparse)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}