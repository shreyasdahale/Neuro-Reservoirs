{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-17T04:56:50.990153Z",
     "iopub.status.busy": "2025-04-17T04:56:50.989849Z",
     "iopub.status.idle": "2025-04-17T04:56:51.811986Z",
     "shell.execute_reply": "2025-04-17T04:56:51.811054Z",
     "shell.execute_reply.started": "2025-04-17T04:56:50.990126Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import Ridge\n",
    "import itertools\n",
    "from scipy.integrate import odeint\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-17T04:56:58.923108Z",
     "iopub.status.busy": "2025-04-17T04:56:58.922621Z",
     "iopub.status.idle": "2025-04-17T04:56:58.930947Z",
     "shell.execute_reply": "2025-04-17T04:56:58.929923Z",
     "shell.execute_reply.started": "2025-04-17T04:56:58.923075Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def compute_valid_prediction_time(y_true, y_pred, t_vals, threshold, lambda_max, dt):\n",
    "    \"\"\"\n",
    "    Compute the Valid Prediction Time (VPT) and compare it to Lyapunov time T_lambda = 1 / lambda_max.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true : ndarray of shape (N, dim)\n",
    "        True trajectory over time.\n",
    "    y_pred : ndarray of shape (N, dim)\n",
    "        Model's predicted trajectory over time (closed-loop).\n",
    "    t_vals : ndarray of shape (N,)\n",
    "        Time values corresponding to the trajectory steps.\n",
    "    threshold : float, optional\n",
    "        The error threshold, default is 0.4 as in your snippet.\n",
    "    lambda_max : float, optional\n",
    "        Largest Lyapunov exponent. Default=0.9 for Lorenz.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    T_VPT : float\n",
    "        Valid prediction time. The earliest time at which normalized error surpasses threshold\n",
    "        (or the last time if never surpassed).\n",
    "    T_lambda : float\n",
    "        Lyapunov time = 1 / lambda_max\n",
    "    ratio : float\n",
    "        How many Lyapunov times the model prediction remains valid, i.e. T_VPT / T_lambda.\n",
    "    \"\"\"\n",
    "    # 1) Average of y_true\n",
    "    y_mean = np.mean(y_true, axis=0)  # shape (dim,)\n",
    "    \n",
    "    # 2) Time-averaged norm^2 of (y_true - y_mean)\n",
    "    y_centered = y_true - y_mean\n",
    "    denom = np.mean(np.sum(y_centered**2, axis=1))  # scalar\n",
    "    \n",
    "    # 3) Compute the normalized error delta_gamma(t) = ||y_true - y_pred||^2 / denom\n",
    "    diff = y_true - y_pred\n",
    "    err_sq = np.sum(diff**2, axis=1)  # shape (N,)\n",
    "    delta_gamma = err_sq / denom      # shape (N,)\n",
    "    \n",
    "    # 4) Find the first time index where delta_gamma(t) exceeds threshold\n",
    "    idx_exceed = np.where(delta_gamma > threshold)[0]\n",
    "    if len(idx_exceed) == 0:\n",
    "        # never exceeds threshold => set T_VPT to the final time\n",
    "        T_VPT = t_vals[-1]\n",
    "    else:\n",
    "        T_VPT = t_vals[idx_exceed[0]]\n",
    "    \n",
    "    # 5) Compute T_lambda and ratio\n",
    "    T_lambda = 1.0 / lambda_max\n",
    "\n",
    "    # print(f\"\\n--- Valid Prediction Time (VPT) with threshold={threshold}, lambda_max={lambda_max} ---\")\n",
    "\n",
    "    T_VPT = (T_VPT - t_vals[0])  # Adjust T_VPT to be relative to the start time\n",
    "    ratio = T_VPT / T_lambda\n",
    "\n",
    "    return T_VPT, T_lambda, ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-17T04:57:02.886762Z",
     "iopub.status.busy": "2025-04-17T04:57:02.886484Z",
     "iopub.status.idle": "2025-04-17T04:57:02.891412Z",
     "shell.execute_reply": "2025-04-17T04:57:02.890682Z",
     "shell.execute_reply.started": "2025-04-17T04:57:02.886743Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def scale_spectral_radius(W, target_radius=0.95):\n",
    "    \"\"\"\n",
    "    Scales a matrix W so that its largest eigenvalue magnitude = target_radius.\n",
    "    \"\"\"\n",
    "    eigvals = np.linalg.eigvals(W)\n",
    "    radius = np.max(np.abs(eigvals))\n",
    "    if radius == 0:\n",
    "        return W\n",
    "    return (W / radius) * target_radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-17T04:57:04.072756Z",
     "iopub.status.busy": "2025-04-17T04:57:04.072416Z",
     "iopub.status.idle": "2025-04-17T04:57:04.077318Z",
     "shell.execute_reply": "2025-04-17T04:57:04.076551Z",
     "shell.execute_reply.started": "2025-04-17T04:57:04.072732Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def augment_state_with_squares(x):\n",
    "    \"\"\"\n",
    "    Given state vector x in R^N, return [ x, x^2, 1 ] in R^(2N+1).\n",
    "    We'll use this for both training and prediction.\n",
    "    \"\"\"\n",
    "    x_sq = x**2\n",
    "    return np.concatenate([x, x_sq, [1.0]])  # shape: 2N+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-17T04:57:05.988604Z",
     "iopub.status.busy": "2025-04-17T04:57:05.98827Z",
     "iopub.status.idle": "2025-04-17T04:57:06.001005Z",
     "shell.execute_reply": "2025-04-17T04:57:06.000201Z",
     "shell.execute_reply.started": "2025-04-17T04:57:05.988576Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class ESN3D:\n",
    "    \"\"\"\n",
    "    Dense random ESN for 3D->3D single-step.\n",
    "    Teacher forcing for training, autoregressive for testing.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 reservoir_size=300,\n",
    "                 spectral_radius=0.95,\n",
    "                 input_scale=1.0,\n",
    "                 leaking_rate=1.0,\n",
    "                 ridge_alpha=1e-6,\n",
    "                 seed=42):\n",
    "        self.reservoir_size = reservoir_size\n",
    "        self.spectral_radius = spectral_radius\n",
    "        self.input_scale = input_scale\n",
    "        self.leaking_rate = leaking_rate\n",
    "        self.ridge_alpha = ridge_alpha\n",
    "        self.seed = seed\n",
    "\n",
    "        np.random.seed(self.seed)\n",
    "        W = np.random.randn(reservoir_size, reservoir_size)*0.1\n",
    "        W = scale_spectral_radius(W, self.spectral_radius)\n",
    "        self.W = W\n",
    "\n",
    "        np.random.seed(self.seed+1)\n",
    "        self.W_in = (np.random.rand(reservoir_size,3) - 0.5)*2.0*self.input_scale\n",
    "        # self.W_in = np.random.uniform(-self.input_scale, self.input_scale, (reservoir_size, 3))\n",
    "\n",
    "        self.W_out = None\n",
    "        self.x = np.zeros(reservoir_size)\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.x = np.zeros(self.reservoir_size)\n",
    "\n",
    "    def _update(self, u):\n",
    "        pre_activation = self.W @ self.x + self.W_in @ u\n",
    "        x_new = np.tanh(pre_activation)\n",
    "        alpha = self.leaking_rate\n",
    "        self.x = (1.0 - alpha)*self.x + alpha*x_new\n",
    "\n",
    "    def collect_states(self, inputs, discard=100):\n",
    "        self.reset_state()\n",
    "        states = []\n",
    "        for val in inputs:\n",
    "            self._update(val)\n",
    "            states.append(self.x.copy())\n",
    "        states = np.array(states)\n",
    "        return states[discard:], states[:discard]\n",
    "\n",
    "    def fit_readout(self, train_input, train_target, discard=100):\n",
    "        states_use, _ = self.collect_states(train_input, discard=discard)\n",
    "        targets_use = train_target[discard:]\n",
    "        # X_aug = np.hstack([states_use, np.ones((states_use.shape[0],1))])\n",
    "\n",
    "        # polynomial readout\n",
    "        X_list = []\n",
    "        for s in states_use:\n",
    "            X_list.append(augment_state_with_squares(s))\n",
    "        X_aug = np.array(X_list)  # shape => [T-discard, 2N+1]\n",
    "\n",
    "        reg = Ridge(alpha=self.ridge_alpha, fit_intercept=False)\n",
    "        reg.fit(X_aug, targets_use)\n",
    "        self.W_out = reg.coef_\n",
    "\n",
    "    def predict_autoregressive(self, initial_input, n_steps):\n",
    "        preds = []\n",
    "        current_in = np.array(initial_input)\n",
    "        for _ in range(n_steps):\n",
    "            self._update(current_in)\n",
    "            # x_aug = np.concatenate([self.x, [1.0]])\n",
    "            x_aug = augment_state_with_squares(self.x)\n",
    "            out = self.W_out @ x_aug\n",
    "            preds.append(out)\n",
    "            current_in = out\n",
    "        return np.array(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-17T04:57:09.189628Z",
     "iopub.status.busy": "2025-04-17T04:57:09.189061Z",
     "iopub.status.idle": "2025-04-17T04:57:09.201106Z",
     "shell.execute_reply": "2025-04-17T04:57:09.200256Z",
     "shell.execute_reply.started": "2025-04-17T04:57:09.1896Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class SparseESN3D:\n",
    "    \"\"\"\n",
    "    Sparse random ESN for 3D->3D single-step,\n",
    "    teacher forcing for training, autoregressive for testing.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 reservoir_size=300,\n",
    "                 spectral_radius=0.95,\n",
    "                 connectivity=0.05,\n",
    "                 input_scale=1.0,\n",
    "                 leaking_rate=1.0,\n",
    "                 ridge_alpha=1e-6,\n",
    "                 seed=42):\n",
    "        self.reservoir_size = reservoir_size\n",
    "        self.spectral_radius = spectral_radius\n",
    "        self.connectivity = connectivity\n",
    "        self.input_scale = input_scale\n",
    "        self.leaking_rate = leaking_rate\n",
    "        self.ridge_alpha = ridge_alpha\n",
    "        self.seed = seed\n",
    "\n",
    "        np.random.seed(self.seed)\n",
    "        W_full = np.random.randn(reservoir_size, reservoir_size)*0.1\n",
    "        mask = (np.random.rand(reservoir_size, reservoir_size) < self.connectivity)\n",
    "        W = W_full * mask\n",
    "        W = scale_spectral_radius(W, self.spectral_radius)\n",
    "        self.W = W\n",
    "\n",
    "        np.random.seed(self.seed+1)\n",
    "        self.W_in = (np.random.rand(reservoir_size,3) - 0.5)*2.0*self.input_scale\n",
    "\n",
    "        self.W_out = None\n",
    "        self.x = np.zeros(reservoir_size)\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.x = np.zeros(self.reservoir_size)\n",
    "\n",
    "    def _update(self, u):\n",
    "        pre_activation = self.W @ self.x + self.W_in @ u\n",
    "        x_new = np.tanh(pre_activation)\n",
    "        alpha = self.leaking_rate\n",
    "        self.x = (1.0 - alpha)*self.x + alpha*x_new\n",
    "\n",
    "    def collect_states(self, inputs, discard=100):\n",
    "        self.reset_state()\n",
    "        states = []\n",
    "        for val in inputs:\n",
    "            self._update(val)\n",
    "            states.append(self.x.copy())\n",
    "        states = np.array(states)\n",
    "        return states[discard:], states[:discard]\n",
    "\n",
    "    def fit_readout(self, train_input, train_target, discard=100):\n",
    "        states_use, _ = self.collect_states(train_input, discard=discard)\n",
    "        targets_use = train_target[discard:]\n",
    "        # X_aug = np.hstack([states_use, np.ones((states_use.shape[0],1))])\n",
    "\n",
    "        # polynomial readout\n",
    "        X_list = []\n",
    "        for s in states_use:\n",
    "            X_list.append(augment_state_with_squares(s))\n",
    "        X_aug = np.array(X_list)  # shape => [T-discard, 2N+1]\n",
    "\n",
    "        reg = Ridge(alpha=self.ridge_alpha, fit_intercept=False)\n",
    "        reg.fit(X_aug, targets_use)\n",
    "        self.W_out = reg.coef_\n",
    "\n",
    "    def predict_autoregressive(self, initial_input, n_steps):\n",
    "        preds = []\n",
    "        current_in = np.array(initial_input)\n",
    "        for _ in range(n_steps):\n",
    "            self._update(current_in)\n",
    "            # x_aug = np.concatenate([self.x, [1.0]])\n",
    "            x_aug = augment_state_with_squares(self.x)\n",
    "            out = self.W_out @ x_aug\n",
    "            preds.append(out)\n",
    "            current_in = out\n",
    "        return np.array(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-17T04:57:12.749492Z",
     "iopub.status.busy": "2025-04-17T04:57:12.748726Z",
     "iopub.status.idle": "2025-04-17T04:57:12.760229Z",
     "shell.execute_reply": "2025-04-17T04:57:12.75939Z",
     "shell.execute_reply.started": "2025-04-17T04:57:12.749455Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class CR3D:\n",
    "    \"\"\"\n",
    "    Cycle (ring) reservoir for 3D->3D single-step,\n",
    "    teacher forcing for training, autoregressive for testing.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 reservoir_size=300,\n",
    "                 spectral_radius=0.95,\n",
    "                 input_scale=1.0,\n",
    "                 leaking_rate=1.0,\n",
    "                 ridge_alpha=1e-6,\n",
    "                 seed=42):\n",
    "        self.reservoir_size = reservoir_size\n",
    "        self.spectral_radius = spectral_radius\n",
    "        self.input_scale = input_scale\n",
    "        self.leaking_rate = leaking_rate\n",
    "        self.ridge_alpha = ridge_alpha\n",
    "        self.seed = seed\n",
    "\n",
    "        np.random.seed(self.seed)\n",
    "        W = np.zeros((reservoir_size, reservoir_size))\n",
    "        for i in range(reservoir_size):\n",
    "            j = (i+1) % reservoir_size\n",
    "            W[i, j] = 1.0\n",
    "        W = scale_spectral_radius(W, self.spectral_radius)\n",
    "        self.W = W\n",
    "        \n",
    "        np.random.seed(self.seed+1)\n",
    "        self.W_in = (np.random.rand(reservoir_size,3) - 0.5)*2.0*self.input_scale\n",
    "\n",
    "        self.W_out = None\n",
    "        self.x = np.zeros(reservoir_size)\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.x = np.zeros(self.reservoir_size)\n",
    "\n",
    "    def _update(self, u):\n",
    "        pre_activation = self.W @ self.x + self.W_in @ u\n",
    "        x_new = np.tanh(pre_activation)\n",
    "        alpha = self.leaking_rate\n",
    "        self.x = (1.0 - alpha)*self.x + alpha*x_new\n",
    "\n",
    "    def collect_states(self, inputs, discard=100):\n",
    "        self.reset_state()\n",
    "        states = []\n",
    "        for val in inputs:\n",
    "            self._update(val)\n",
    "            states.append(self.x.copy())\n",
    "        states = np.array(states)\n",
    "        return states[discard:], states[:discard]\n",
    "\n",
    "    def fit_readout(self, train_input, train_target, discard=100):\n",
    "        states_use, _ = self.collect_states(train_input, discard=discard)\n",
    "        targets_use = train_target[discard:]\n",
    "        # X_aug = np.hstack([states_use, np.ones((states_use.shape[0],1))])\n",
    "\n",
    "        # polynomial readout\n",
    "        X_list = []\n",
    "        for s in states_use:\n",
    "            X_list.append(augment_state_with_squares(s))\n",
    "        X_aug = np.array(X_list)  # shape => [T-discard, 2N+1]\n",
    "\n",
    "        reg = Ridge(alpha=self.ridge_alpha, fit_intercept=False)\n",
    "        reg.fit(X_aug, targets_use)\n",
    "        self.W_out = reg.coef_\n",
    "\n",
    "    def predict_autoregressive(self, initial_input, n_steps):\n",
    "        preds = []\n",
    "        current_in = np.array(initial_input)\n",
    "        for _ in range(n_steps):\n",
    "            self._update(current_in)\n",
    "            # x_aug = np.concatenate([self.x, [1.0]])\n",
    "            x_aug = augment_state_with_squares(self.x)\n",
    "            out = self.W_out @ x_aug\n",
    "            preds.append(out)\n",
    "            current_in = out\n",
    "        return np.array(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-17T04:57:19.943035Z",
     "iopub.status.busy": "2025-04-17T04:57:19.942391Z",
     "iopub.status.idle": "2025-04-17T04:57:20.063401Z",
     "shell.execute_reply": "2025-04-17T04:57:20.06259Z",
     "shell.execute_reply.started": "2025-04-17T04:57:19.943008Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def lorenz_deriv(state, t, sigma=10.0, rho=28.0, beta=8.0/3.0):\n",
    "    x, y, z = state\n",
    "    dxdt = sigma * (y - x)\n",
    "    dydt = x*(rho - z) - y\n",
    "    dzdt = x*y - beta*z\n",
    "    return [dxdt, dydt, dzdt]\n",
    "\n",
    "def generate_lorenz_data(\n",
    "    initial_state=[1.0, 1.0, 1.0],\n",
    "    tmax=25.0,\n",
    "    dt=0.01,\n",
    "    sigma=10.0,\n",
    "    rho=28.0,\n",
    "    beta=8.0/3.0\n",
    "):\n",
    "    num_steps = int(tmax / dt) + 1 # +1 to include t=0\n",
    "    t_vals = np.linspace(0, tmax, num_steps)\n",
    "    sol = odeint(lorenz_deriv, initial_state, t_vals, args=(sigma, rho, beta))\n",
    "    return t_vals, sol\n",
    "\n",
    "def report_vpt(name, preds, test_target, time_test, dt):\n",
    "    T_VPT, T_lambda, ratio = compute_valid_prediction_time(\n",
    "        test_target, preds, time_test, threshold=0.4, lambda_max=0.9, dt=dt\n",
    "    )\n",
    "    # print(f\"{name:20s} => T_VPT={T_VPT:.3f},  T_lambda={T_lambda:.3f}, ratio={ratio:.3f}\")\n",
    "    return T_VPT, T_lambda, ratio\n",
    "\n",
    "tmax = 250\n",
    "dt   = 0.02\n",
    "t_vals, lorenz_traj = generate_lorenz_data(\n",
    "    initial_state=[1.0,1.0,1.0],\n",
    "    tmax=tmax,\n",
    "    dt=dt\n",
    ")\n",
    "\n",
    "washout = 2000\n",
    "t_vals = t_vals[washout:]\n",
    "lorenz_traj = lorenz_traj[washout:]\n",
    "\n",
    "# normalize\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(lorenz_traj)\n",
    "lorenz_traj = scaler.transform(lorenz_traj)\n",
    "\n",
    "T_data = len(lorenz_traj)\n",
    "print(f\"Data length: {T_data}, from t=0..{tmax} with dt={dt}.\")\n",
    "\n",
    "n_test_steps = 2100\n",
    "\n",
    "# train/test split\n",
    "train_frac = 0.8\n",
    "train_end = int(train_frac*(T_data-1))\n",
    "train_input  = lorenz_traj[:train_end]\n",
    "train_target = lorenz_traj[1:train_end+1]\n",
    "test_input   = lorenz_traj[train_end:train_end+n_test_steps]\n",
    "test_target  = lorenz_traj[train_end+1:train_end+n_test_steps+1]\n",
    "print(f\"Train size: {len(train_input)}  Test size: {len(test_input)}\")\n",
    "\n",
    "initial_in = test_input[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-17T04:57:22.449404Z",
     "iopub.status.busy": "2025-04-17T04:57:22.448792Z",
     "iopub.status.idle": "2025-04-17T04:57:24.267132Z",
     "shell.execute_reply": "2025-04-17T04:57:24.266238Z",
     "shell.execute_reply.started": "2025-04-17T04:57:22.449377Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# (a) Baseline ESN\n",
    "esn = ESN3D(\n",
    "    reservoir_size=300,\n",
    "    spectral_radius=0.1,\n",
    "    input_scale=0.1,\n",
    "    leaking_rate=0.9,\n",
    "    ridge_alpha=1e-09,\n",
    "    seed=42\n",
    ")\n",
    "esn.fit_readout(train_input, train_target, discard=100)\n",
    "\n",
    "# (b) Cycle Reservoir\n",
    "cycle_res = CR3D(\n",
    "    reservoir_size=300,\n",
    "    spectral_radius=0.8,\n",
    "    input_scale=0.4,\n",
    "    leaking_rate=0.5,\n",
    "    ridge_alpha=1e-05,\n",
    "    seed=43\n",
    ")\n",
    "cycle_res.fit_readout(train_input, train_target, discard=100)\n",
    "\n",
    "# (c) Sparse ESN\n",
    "sparse_res = SparseESN3D(\n",
    "    reservoir_size=300,\n",
    "    spectral_radius=0.95,\n",
    "    connectivity=0.04,\n",
    "    input_scale=1.0,\n",
    "    leaking_rate=0.8,\n",
    "    ridge_alpha=1e-9,\n",
    "    seed=44\n",
    ")\n",
    "sparse_res.fit_readout(train_input, train_target, discard=100)\n",
    "\n",
    "esn_preds    = esn.predict_autoregressive(initial_in, n_test_steps)\n",
    "cycle_preds  = cycle_res.predict_autoregressive(initial_in, n_test_steps)\n",
    "sparse_preds = sparse_res.predict_autoregressive(initial_in, n_test_steps)\n",
    "\n",
    "a, _, _ = report_vpt(\"Dense ESN\",    esn_preds, test_target, t_vals[train_end:train_end+n_test_steps], dt)\n",
    "b, _, _ = report_vpt(\"Cycle Res\",  cycle_preds, test_target, t_vals[train_end:train_end+n_test_steps], dt)\n",
    "c, _, _ = report_vpt(\"Sparse ESN\",   sparse_preds, test_target, t_vals[train_end:train_end+n_test_steps], dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-17T05:00:17.421262Z",
     "iopub.status.busy": "2025-04-17T05:00:17.420171Z",
     "iopub.status.idle": "2025-04-17T05:00:17.429259Z",
     "shell.execute_reply": "2025-04-17T05:00:17.428387Z",
     "shell.execute_reply.started": "2025-04-17T05:00:17.421231Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define your parameter grids\n",
    "param_grid_common = {\n",
    "    \"spectral_radius\": [0.8, 0.85, 0.9, 0.92, 0.94, 0.96, 0.98, 0.99],\n",
    "    \"input_scale\": [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "    \"leaking_rate\": [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],\n",
    "    \"ridge_alpha\": [1e-6, 1e-7]\n",
    "}\n",
    "\n",
    "param_grid_sparse = {\n",
    "    **param_grid_common,\n",
    "    \"connectivity\": [0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1]\n",
    "}\n",
    "\n",
    "def run_grid_search(model_class, param_grid, model_name,\n",
    "                    output_path=\"grid_search_results.json\"):\n",
    "    # 1) Cold‐start grid search\n",
    "    scored_params = []\n",
    "    combos = list(itertools.product(*param_grid.values()))\n",
    "    print(f\"\\n== Initial grid search for {model_name} ==\")\n",
    "    for comb in combos:\n",
    "        params = dict(zip(param_grid.keys(), comb))\n",
    "        model = model_class(reservoir_size=300, **params)\n",
    "        model.fit_readout(train_input, train_target, discard=100)\n",
    "        preds = model.predict_autoregressive(initial_in, n_test_steps)\n",
    "        T_VPT, _, _ = report_vpt(\"model\", preds,\n",
    "                                 test_target,\n",
    "                                 t_vals[train_end:train_end+n_test_steps],\n",
    "                                 dt)\n",
    "        scored_params.append((T_VPT, params))\n",
    "        # print(f\"T_VPT={T_VPT:.3f} with params {params}\")\n",
    "    \n",
    "    # 2) Sort by performance\n",
    "    sorted_params = sorted(scored_params, key=lambda x: x[0], reverse=True)\n",
    "    \n",
    "    # 3) Stability check over 10 seeds\n",
    "    print(f\"\\n== Stability check over 10 seeds for each param set ==\")\n",
    "    results = []\n",
    "    for base_score, params in sorted_params:\n",
    "        seed_scores = []\n",
    "        for seed in range(10):\n",
    "            # np.random.seed(seed)\n",
    "            model = model_class(reservoir_size=300, **params, seed=seed)\n",
    "            model.fit_readout(train_input, train_target, discard=100)\n",
    "            preds = model.predict_autoregressive(initial_in, n_test_steps)\n",
    "            T_VPT_s, _, _ = report_vpt(\"model\", preds,\n",
    "                                       test_target,\n",
    "                                       t_vals[train_end:train_end+n_test_steps],\n",
    "                                       dt)\n",
    "            seed_scores.append(T_VPT_s)\n",
    "        \n",
    "        mean_score = float(np.mean(seed_scores))\n",
    "        std_dev    = float(np.std(seed_scores))\n",
    "        is_stable  = std_dev < 1.5\n",
    "        status     = \"Stable\" if is_stable else \"Unstable\"\n",
    "        \n",
    "        print(f\"Params: {params} → Avg T_VPT={mean_score:.3f}, \"\n",
    "              f\"Std Dev={std_dev:.3f} → {status}\")\n",
    "        \n",
    "        results.append({\n",
    "            \"params\":      params,\n",
    "            \"seed_scores\": seed_scores,\n",
    "            \"mean_T_VPT\":  mean_score,\n",
    "            \"std_dev\":     std_dev,\n",
    "            \"stable\":      is_stable\n",
    "        })\n",
    "    \n",
    "    # 4) Dump to JSON for later inspection\n",
    "    with open(output_path, \"w\") as f:\n",
    "        json.dump(results, f, indent=2)\n",
    "    print(f\"\\nAll results saved to `{output_path}`\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-04-17T05:00:37.216Z",
     "iopub.execute_input": "2025-04-17T05:00:18.436237Z",
     "iopub.status.busy": "2025-04-17T05:00:18.435855Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "esn     = run_grid_search(ESN3D, param_grid_common, \"Dense ESN\")\n",
    "cr      = run_grid_search(CR3D, param_grid_common, \"Cycle Res\")\n",
    "sparse  = run_grid_search(SparseESN3D, param_grid_sparse, \"Sparse ESN\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
