{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-06-07T18:24:45.119262Z",
     "iopub.status.busy": "2025-06-07T18:24:45.118958Z",
     "iopub.status.idle": "2025-06-07T18:24:45.837084Z",
     "shell.execute_reply": "2025-06-07T18:24:45.836113Z",
     "shell.execute_reply.started": "2025-06-07T18:24:45.119241Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.integrate import odeint\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import Ridge\n",
    "import json\n",
    "import itertools\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T18:24:45.838891Z",
     "iopub.status.busy": "2025-06-07T18:24:45.838404Z",
     "iopub.status.idle": "2025-06-07T18:24:45.848882Z",
     "shell.execute_reply": "2025-06-07T18:24:45.847731Z",
     "shell.execute_reply.started": "2025-06-07T18:24:45.838861Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def rossler_derivatives(state, t, a=0.2, b=0.2, c=5.7):\n",
    "    \"\"\"Compute time derivatives [dx/dt, dy/dt, dz/dt] for the Rössler system.\"\"\"\n",
    "    x, y, z = state\n",
    "    dxdt = -y - z\n",
    "    dydt = x + a * y\n",
    "    dzdt = b + z * (x - c)\n",
    "    return [dxdt, dydt, dzdt]\n",
    "\n",
    "def generate_rossler_data(\n",
    "    initial_state=[1.0, 0.0, 0.0],\n",
    "    tmax=25.0,\n",
    "    dt=0.01,\n",
    "    a=0.2,\n",
    "    b=0.2,\n",
    "    c=5.7\n",
    "):\n",
    "    \"\"\"\n",
    "    Numerically integrate Rössler equations x'(t), y'(t), z'(t) using odeint.\n",
    "    Returns:\n",
    "       t_vals: array of time points\n",
    "       sol   : array shape [num_steps, 3] of [x(t), y(t), z(t)]\n",
    "    \"\"\"\n",
    "    num_steps = int(tmax / dt)\n",
    "    t_vals = np.linspace(0, tmax, num_steps)\n",
    "    sol = odeint(rossler_derivatives, initial_state, t_vals, args=(a, b, c))\n",
    "    return t_vals, sol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T18:24:45.850287Z",
     "iopub.status.busy": "2025-06-07T18:24:45.849978Z",
     "iopub.status.idle": "2025-06-07T18:24:45.873250Z",
     "shell.execute_reply": "2025-06-07T18:24:45.872014Z",
     "shell.execute_reply.started": "2025-06-07T18:24:45.850266Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def chen_deriv(state, t, a=35.0, b=3.0, c=28.0):\n",
    "    \"\"\"\n",
    "    Computes derivatives [dx/dt, dy/dt, dz/dt] for Chen system:\n",
    "      dx/dt = a*(y - x)\n",
    "      dy/dt = (c - a)*x + c*y - x*z\n",
    "      dz/dt = x*y - b*z\n",
    "    \"\"\"\n",
    "    x, y, z = state\n",
    "    dxdt = a*(y - x)\n",
    "    dydt = (c - a)*x + c*y - x*z\n",
    "    dzdt = x*y - b*z\n",
    "    return [dxdt, dydt, dzdt]\n",
    "\n",
    "def generate_chen_data(\n",
    "    initial_state=[1.0, 1.0, 1.0],\n",
    "    tmax=50.0,\n",
    "    dt=0.01,\n",
    "    a=35.0,\n",
    "    b=3.0,\n",
    "    c=28.0\n",
    "):\n",
    "    \"\"\"\n",
    "    Integrates Chen's system from 'initial_state' up to time 'tmax' with step size 'dt'.\n",
    "    Returns:\n",
    "      t_vals: time array of length T\n",
    "      sol   : array shape [T, 3], the trajectory [x(t), y(t), z(t)]\n",
    "    \"\"\"\n",
    "    num_steps = int(tmax / dt)\n",
    "    t_vals = np.linspace(0, tmax, num_steps)\n",
    "    sol = odeint(chen_deriv, initial_state, t_vals, args=(a, b, c))\n",
    "    return t_vals, sol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T18:24:45.874981Z",
     "iopub.status.busy": "2025-06-07T18:24:45.874379Z",
     "iopub.status.idle": "2025-06-07T18:24:45.896068Z",
     "shell.execute_reply": "2025-06-07T18:24:45.894868Z",
     "shell.execute_reply.started": "2025-06-07T18:24:45.874937Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def lorenz_deriv(state, t, sigma=10.0, rho=28.0, beta=8.0/3.0):\n",
    "    x, y, z = state\n",
    "    dxdt = sigma * (y - x)\n",
    "    dydt = x*(rho - z) - y\n",
    "    dzdt = x*y - beta*z\n",
    "    return [dxdt, dydt, dzdt]\n",
    "\n",
    "def generate_lorenz_data(\n",
    "    initial_state=[1.0, 1.0, 1.0],\n",
    "    tmax=25.0,\n",
    "    dt=0.01,\n",
    "    sigma=10.0,\n",
    "    rho=28.0,\n",
    "    beta=8.0/3.0\n",
    "):\n",
    "    num_steps = int(tmax / dt) + 1 # +1 to include t=0\n",
    "    t_vals = np.linspace(0, tmax, num_steps)\n",
    "    sol = odeint(lorenz_deriv, initial_state, t_vals, args=(sigma, rho, beta))\n",
    "    return t_vals, sol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T18:24:45.897662Z",
     "iopub.status.busy": "2025-06-07T18:24:45.897265Z",
     "iopub.status.idle": "2025-06-07T18:24:45.924996Z",
     "shell.execute_reply": "2025-06-07T18:24:45.923853Z",
     "shell.execute_reply.started": "2025-06-07T18:24:45.897576Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def evaluate_nrmse(all_preds, test_target, horizons):\n",
    "    \"\"\"\n",
    "    Evaluate model performance over multiple prediction horizons\n",
    "    for teacher-forced single-step forecasting or autoregressive rollout.\n",
    "    \"\"\"\n",
    "    horizon_nrmse = {}\n",
    "    for horizon in horizons:\n",
    "        preds = all_preds[:horizon]\n",
    "        targets = test_target[:horizon]\n",
    "        squared_errors = (preds - targets) ** 2\n",
    "        variance = np.var(targets, axis=0)\n",
    "        variance[variance == 0] = 1e-8  # avoid divide-by-zero\n",
    "        nrmse = np.sqrt(np.sum(squared_errors) / (horizon * np.sum(variance)))\n",
    "        horizon_nrmse[horizon] = nrmse\n",
    "    return horizon_nrmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T18:24:45.928846Z",
     "iopub.status.busy": "2025-06-07T18:24:45.928521Z",
     "iopub.status.idle": "2025-06-07T18:24:45.947575Z",
     "shell.execute_reply": "2025-06-07T18:24:45.946464Z",
     "shell.execute_reply.started": "2025-06-07T18:24:45.928820Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def compute_valid_prediction_time(y_true, y_pred, t_vals, threshold, lambda_max, dt):\n",
    "    \"\"\"\n",
    "    Compute the Valid Prediction Time (VPT) and compare it to Lyapunov time T_lambda = 1 / lambda_max.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true : ndarray of shape (N, dim)\n",
    "        True trajectory over time.\n",
    "    y_pred : ndarray of shape (N, dim)\n",
    "        Model's predicted trajectory over time (closed-loop).\n",
    "    t_vals : ndarray of shape (N,)\n",
    "        Time values corresponding to the trajectory steps.\n",
    "    threshold : float, optional\n",
    "        The error threshold, default is 0.4 as in your snippet.\n",
    "    lambda_max : float, optional\n",
    "        Largest Lyapunov exponent. Default=0.9 for Lorenz.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    T_VPT : float\n",
    "        Valid prediction time. The earliest time at which normalized error surpasses threshold\n",
    "        (or the last time if never surpassed).\n",
    "    T_lambda : float\n",
    "        Lyapunov time = 1 / lambda_max\n",
    "    ratio : float\n",
    "        How many Lyapunov times the model prediction remains valid, i.e. T_VPT / T_lambda.\n",
    "    \"\"\"\n",
    "    # 1) Average of y_true\n",
    "    y_mean = np.mean(y_true, axis=0)  # shape (dim,)\n",
    "    \n",
    "    # 2) Time-averaged norm^2 of (y_true - y_mean)\n",
    "    y_centered = y_true - y_mean\n",
    "    denom = np.mean(np.sum(y_centered**2, axis=1))  # scalar\n",
    "    \n",
    "    # 3) Compute the normalized error delta_gamma(t) = ||y_true - y_pred||^2 / denom\n",
    "    diff = y_true - y_pred\n",
    "    err_sq = np.sum(diff**2, axis=1)  # shape (N,)\n",
    "    delta_gamma = err_sq / denom      # shape (N,)\n",
    "    \n",
    "    # 4) Find the first time index where delta_gamma(t) exceeds threshold\n",
    "    idx_exceed = np.where(delta_gamma > threshold)[0]\n",
    "    if len(idx_exceed) == 0:\n",
    "        # never exceeds threshold => set T_VPT to the final time\n",
    "        T_VPT = t_vals[-1]\n",
    "    else:\n",
    "        T_VPT = t_vals[idx_exceed[0]]\n",
    "    \n",
    "    # 5) Compute T_lambda and ratio\n",
    "    T_lambda = 1.0 / lambda_max\n",
    "\n",
    "    # print(f\"\\n--- Valid Prediction Time (VPT) with threshold={threshold}, lambda_max={lambda_max} ---\")\n",
    "\n",
    "    T_VPT = (T_VPT - t_vals[0])  # Adjust T_VPT to be relative to the start time\n",
    "    ratio = T_VPT / T_lambda\n",
    "\n",
    "    return T_VPT, T_lambda, ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T18:24:45.949022Z",
     "iopub.status.busy": "2025-06-07T18:24:45.948699Z",
     "iopub.status.idle": "2025-06-07T18:24:45.974919Z",
     "shell.execute_reply": "2025-06-07T18:24:45.973710Z",
     "shell.execute_reply.started": "2025-06-07T18:24:45.948988Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def compute_attractor_deviation(predictions, targets, cube_size=(0.1, 0.1, 0.1)):\n",
    "    \"\"\"\n",
    "    Compute the Attractor Deviation (ADev) metric.\n",
    "\n",
    "    Parameters:\n",
    "        predictions (numpy.ndarray): Predicted trajectories of shape (n, 3).\n",
    "        targets (numpy.ndarray): True trajectories of shape (n, 3).\n",
    "        cube_size (tuple): Dimensions of the cube (dx, dy, dz).\n",
    "\n",
    "    Returns:\n",
    "        float: The ADev metric.\n",
    "    \"\"\"\n",
    "    # Define the cube grid based on the range of the data and cube size\n",
    "    min_coords = np.min(np.vstack((predictions, targets)), axis=0)\n",
    "    max_coords = np.max(np.vstack((predictions, targets)), axis=0)\n",
    "\n",
    "    # Create a grid of cubes\n",
    "    grid_shape = ((max_coords - min_coords) / cube_size).astype(int) + 1\n",
    "\n",
    "    # Initialize the cube occupancy arrays\n",
    "    pred_cubes = np.zeros(grid_shape, dtype=int)\n",
    "    target_cubes = np.zeros(grid_shape, dtype=int)\n",
    "\n",
    "    # Map trajectories to cubes\n",
    "    pred_indices = ((predictions - min_coords) / cube_size).astype(int)\n",
    "    target_indices = ((targets - min_coords) / cube_size).astype(int)\n",
    "\n",
    "    # Mark cubes visited by predictions and targets\n",
    "    for idx in pred_indices:\n",
    "        pred_cubes[tuple(idx)] = 1\n",
    "    for idx in target_indices:\n",
    "        target_cubes[tuple(idx)] = 1\n",
    "\n",
    "    # Compute the ADev metric\n",
    "    adev = np.sum(np.abs(pred_cubes - target_cubes))\n",
    "    return adev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T18:24:45.976604Z",
     "iopub.status.busy": "2025-06-07T18:24:45.976297Z",
     "iopub.status.idle": "2025-06-07T18:24:46.015005Z",
     "shell.execute_reply": "2025-06-07T18:24:46.013659Z",
     "shell.execute_reply.started": "2025-06-07T18:24:45.976575Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def scale_spectral_radius(W, target_radius=0.95):\n",
    "    \"\"\"\n",
    "    Scales a matrix W so that its largest eigenvalue magnitude = target_radius.\n",
    "    \"\"\"\n",
    "    eigvals = np.linalg.eigvals(W)\n",
    "    radius = np.max(np.abs(eigvals))\n",
    "    if radius == 0:\n",
    "        return W\n",
    "    return (W / radius) * target_radius\n",
    "\n",
    "def augment_state_with_squares(x):\n",
    "    \"\"\"\n",
    "    Given state vector x in R^N, return [ x, x^2, 1 ] in R^(2N+1).\n",
    "    We'll use this for both training and prediction.\n",
    "    \"\"\"\n",
    "    x_sq = x**2\n",
    "    return np.concatenate([x, x_sq, [1.0]])  # shape: 2N+1\n",
    "\n",
    "class HFRRes3D:\n",
    "    \"\"\"\n",
    "    Hierarchical Fractal Reservoir (HFR) for 3D chaotic systems.\n",
    "    \n",
    "    This novel reservoir architecture partitions the chaotic attractor at multiple\n",
    "    hierarchical scales, combining them in a fractal-like adjacency structure.\n",
    "    The method is model-free, relying solely on the observed trajectory in R^3,\n",
    "    and does not require knowledge of any system parameters such as sigma, rho, beta\n",
    "    for Lorenz63. \n",
    "    \n",
    "    Key Idea:\n",
    "     1) Define multiple 'scales' of partition of the data's bounding region.\n",
    "     2) Each scale is subdivided into a certain number of cells (regions).\n",
    "     3) Each cell at level l has links to both:\n",
    "        - other cells at the same level (horizontal adjacency),\n",
    "        - 'child' cells at the finer level l+1 (vertical adjacency).\n",
    "     4) We gather all cells across levels => a multi-level fractal graph => adjacency => W.\n",
    "     5) We build a typical ESN from this adjacency, feed data with W_in, run leaky tanh updates,\n",
    "        then do a polynomial readout for 3D next-step prediction.\n",
    "\n",
    "    This approach is suitable for chaotic systems whose attractors often exhibit fractal\n",
    "    self-similarity, thus capturing multi-scale structures in a single reservoir.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 n_levels=3,             # number of hierarchical levels\n",
    "                 cells_per_level=None,   # list of number of cells at each level, e.g. [8, 32, 128]\n",
    "                 spectral_radius=0.95,\n",
    "                 input_scale=1.0,\n",
    "                 leaking_rate=1.0,\n",
    "                 ridge_alpha=1e-6,\n",
    "                 seed=42):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_levels       : int, number of hierarchical scales\n",
    "        cells_per_level: list[int], the number of partitions/cells at each level\n",
    "                         if None, we auto-generate e.g. 2^(level+2)\n",
    "        spectral_radius: final scaling for adjacency\n",
    "        input_scale    : random input scale W_in\n",
    "        leaking_rate   : ESN leaky alpha\n",
    "        ridge_alpha    : readout ridge penalty\n",
    "        seed           : random seed\n",
    "        \"\"\"\n",
    "        self.n_levels        = n_levels\n",
    "        self.cells_per_level = cells_per_level\n",
    "        self.spectral_radius = spectral_radius\n",
    "        self.input_scale     = input_scale\n",
    "        self.leaking_rate    = leaking_rate\n",
    "        self.ridge_alpha     = ridge_alpha\n",
    "        self.seed            = seed\n",
    "\n",
    "        if self.cells_per_level is None:\n",
    "            # default scheme e.g. 8, 16, 32 for 3 levels\n",
    "            self.cells_per_level = [8*(2**i) for i in range(n_levels)]\n",
    "\n",
    "        # We'll store adjacency W, input W_in, readout W_out, reservoir state x\n",
    "        self.W     = None\n",
    "        self.W_in  = None\n",
    "        self.W_out = None\n",
    "        self.x     = None\n",
    "        self.n_levels = len(self.cells_per_level)\n",
    "\n",
    "        # We'll define a total number of nodes = sum(cells_per_level)\n",
    "        self.n_nodes = sum(self.cells_per_level)\n",
    "\n",
    "    def _build_partitions(self, data_3d):\n",
    "        \"\"\"\n",
    "        Build hierarchical partitions for each level.\n",
    "        We'll store the bounding box for data_3d, then for each level l in [0..n_levels-1]\n",
    "        run e.g. k-means with K = cells_per_level[l], each point gets a label => we track transitions.\n",
    "\n",
    "        Return: \n",
    "          partitions => list of arrays, partitions[l] => shape (N, ) cluster assignment in [0..cells_per_level[l]-1]\n",
    "        \"\"\"\n",
    "        from sklearn.cluster import KMeans\n",
    "        N = len(data_3d)\n",
    "        partitions = []\n",
    "\n",
    "        for level in range(self.n_levels):\n",
    "            k = self.cells_per_level[level]\n",
    "            # cluster\n",
    "            kmeans = KMeans(n_clusters=k, random_state=self.seed+10*level, n_init='auto')\n",
    "            kmeans.fit(data_3d)\n",
    "            labels = kmeans.predict(data_3d)\n",
    "            partitions.append(labels)\n",
    "\n",
    "        return partitions\n",
    "\n",
    "    def _build_hierarchical_adjacency(self, data_3d):\n",
    "        \"\"\"\n",
    "        Build a block adjacency with cross-level links, then scale spectral radius.\n",
    "        Steps:\n",
    "          1) Build partitions for each level => partitions[l] in [0..cells_per_level[l]-1]\n",
    "          2) For each level l, build a transition matrix T_l of shape (cells_per_level[l], cells_per_level[l]).\n",
    "          3) Link scale l to scale l+1 by figuring out which cluster i at scale l maps to which cluster j at scale l+1\n",
    "             for each sample t => link i-> j if data_3d[t] is in i at scale l and j at scale l+1.\n",
    "          4) Combine all transitions in one big adjacency W in R^(n_nodes x n_nodes).\n",
    "          5) row-normalize W => scale largest eigenvalue => spectral_radius\n",
    "        \"\"\"\n",
    "        partitions = self._build_partitions(data_3d)\n",
    "        N = len(data_3d)\n",
    "\n",
    "        # offsets for each level => to index big W\n",
    "        offsets = []\n",
    "        running = 0\n",
    "        for level in range(self.n_levels):\n",
    "            offsets.append(running)\n",
    "            running += self.cells_per_level[level]\n",
    "\n",
    "        # total nodes\n",
    "        n_tot = self.n_nodes\n",
    "        # initialize adjacency\n",
    "        A = np.zeros((n_tot, n_tot))\n",
    "\n",
    "        # 1) horizontal adjacency in each level\n",
    "        for level in range(self.n_levels):\n",
    "            k = self.cells_per_level[level]\n",
    "            labels = partitions[level]\n",
    "            # T_l => shape (k, k)\n",
    "            T_l = np.zeros((k, k))\n",
    "            for t in range(N-1):\n",
    "                i = labels[t]\n",
    "                j = labels[t+1]\n",
    "                T_l[i,j]+=1\n",
    "            # row normalize\n",
    "            row_sum = T_l.sum(axis=1, keepdims=True)\n",
    "            row_sum[row_sum==0.0] = 1.0\n",
    "            T_l /= row_sum\n",
    "            # place T_l into big A\n",
    "            off = offsets[level]\n",
    "            A[off:off+k, off:off+k] = T_l\n",
    "\n",
    "        # 2) vertical adjacency between scale l and l+1\n",
    "        for level in range(self.n_levels-1):\n",
    "            k_l   = self.cells_per_level[level]\n",
    "            k_lp1 = self.cells_per_level[level+1]\n",
    "            labels_l   = partitions[level]\n",
    "            labels_lp1 = partitions[level+1]\n",
    "            # we define adjacency from i in [0..k_l-1] to j in [0..k_lp1-1] if the same sample t belongs to i at level l and j at l+1\n",
    "            # Count how many times\n",
    "            Xvert1 = np.zeros((k_l, k_lp1))\n",
    "            for t in range(N):\n",
    "                i = labels_l[t]\n",
    "                j = labels_lp1[t]\n",
    "                Xvert1[i,j]+=1\n",
    "            # row normalize\n",
    "            row_sum = Xvert1.sum(axis=1, keepdims=True)\n",
    "            row_sum[row_sum==0.0] = 1.0\n",
    "            Xvert = Xvert1/row_sum\n",
    "            # place in big A\n",
    "            off_l   = offsets[level]\n",
    "            off_lp1 = offsets[level+1]\n",
    "            A[off_l:off_l+k_l, off_lp1:off_lp1+k_lp1] = Xvert\n",
    "            # tentative idea, we could also define adjacency from l+1 -> l (parent link), if desired\n",
    "            # we do the same for the 'child -> parent' link or skip it if we only want forward adjacency\n",
    "            # For now, let's do symmetrical\n",
    "            Yvert = Xvert1.T\n",
    "            col_sum = Yvert.sum(axis=1, keepdims=True)\n",
    "            col_sum[col_sum==0.0] = 1.0\n",
    "            Yvert /= col_sum\n",
    "            A[off_lp1:off_lp1+k_lp1, off_l:off_l+k_l] = Yvert\n",
    "\n",
    "        # now we have a big adjacency => row normalize again, then scale spectral radius\n",
    "        row_sum = A.sum(axis=1, keepdims=True)\n",
    "        row_sum[row_sum==0.0] = 1.0\n",
    "        A /= row_sum\n",
    "\n",
    "        A = scale_spectral_radius(A, self.spectral_radius)\n",
    "        return A\n",
    "\n",
    "    def fit_readout(self, train_input, train_target, discard=100):\n",
    "        \"\"\"\n",
    "        Main training routine:\n",
    "          1) Build hierarchical adjacency from fractal partition => self.W\n",
    "          2) define W_in => shape(n_nodes, 3)\n",
    "          3) teacher forcing => polynomial readout => solve => self.W_out\n",
    "        \"\"\"\n",
    "        np.random.seed(self.seed)\n",
    "        # Build adjacency\n",
    "        W_big = self._build_hierarchical_adjacency(train_input)\n",
    "        self.W = W_big\n",
    "\n",
    "        # define W_in => shape(n_nodes,3)\n",
    "        self.n_nodes = W_big.shape[0]\n",
    "        self.W_in = (np.random.rand(self.n_nodes,3)-0.5)*2.0*self.input_scale\n",
    "\n",
    "        # define reservoir state\n",
    "        self.x = np.zeros(self.n_nodes)\n",
    "\n",
    "        # gather states => teacher forcing => polynomial => readout\n",
    "        states_use, _ = self.collect_states(train_input, discard=discard)\n",
    "        target_use = train_target[discard:]\n",
    "        X_list= []\n",
    "        for s in states_use:\n",
    "            X_list.append( augment_state_with_squares(s) )\n",
    "        X_aug= np.array(X_list)\n",
    "\n",
    "        reg= Ridge(alpha=self.ridge_alpha, fit_intercept=False)\n",
    "        reg.fit(X_aug, target_use)\n",
    "        self.W_out= reg.coef_\n",
    "\n",
    "    def collect_states(self, inputs, discard=100):\n",
    "        \"\"\"\n",
    "        Teacher forcing => feed real 3D => gather states => shape => [T-discard, n_nodes].\n",
    "        returns (states_after_discard, states_discarded).\n",
    "        \"\"\"\n",
    "        self.reset_state()\n",
    "        states= []\n",
    "        for val in inputs:\n",
    "            self._update(val)\n",
    "            states.append(self.x.copy())\n",
    "        states= np.array(states)\n",
    "        return states[discard:], states[:discard]\n",
    "\n",
    "    def reset_state(self):\n",
    "        if self.x is not None:\n",
    "            self.x.fill(0.0)\n",
    "\n",
    "    def _update(self, u):\n",
    "        \"\"\"\n",
    "        x(t+1)= (1-alpha)x(t)+ alpha tanh( W*x(t)+ W_in*u(t) ).\n",
    "        \"\"\"\n",
    "        alpha= self.leaking_rate\n",
    "        pre_acts= self.W@self.x + self.W_in@u\n",
    "        x_new= np.tanh(pre_acts)\n",
    "        self.x= (1.0- alpha)*self.x+ alpha*x_new\n",
    "\n",
    "    def predict_autoregressive(self, initial_input, n_steps):\n",
    "        \"\"\"\n",
    "        fully autonomous => feed last predicted => next input\n",
    "        \"\"\"\n",
    "        preds= []\n",
    "        #self.reset_state()\n",
    "        current_in= np.array(initial_input)\n",
    "        for _ in range(n_steps):\n",
    "            self._update(current_in)\n",
    "            big_x= augment_state_with_squares(self.x)\n",
    "            out= self.W_out@big_x\n",
    "            preds.append(out)\n",
    "            current_in= out\n",
    "        return np.array(preds)\n",
    "    \n",
    "    def predict_open_loop(self, test_input):\n",
    "        preds = []\n",
    "        for true_input in test_input:\n",
    "            self._update(true_input)\n",
    "            x_aug = augment_state_with_squares(self.x)\n",
    "            out = self.W_out @ x_aug\n",
    "            preds.append(out)\n",
    "        return np.array(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T18:24:46.016579Z",
     "iopub.status.busy": "2025-06-07T18:24:46.016247Z",
     "iopub.status.idle": "2025-06-07T18:24:46.049355Z",
     "shell.execute_reply": "2025-06-07T18:24:46.048266Z",
     "shell.execute_reply.started": "2025-06-07T18:24:46.016553Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class CRJ3D:\n",
    "    \"\"\"\n",
    "    Cycle Reservoir with Jumps (CRJ) for 3D->3D single-step tasks.\n",
    "    We form a ring adjacency with an extra 'jump' edge in each row.\n",
    "    This can help capture multiple timescales or delayed memory\n",
    "    while retaining the easy ring structure.\n",
    "\n",
    "    The adjacency is built as follows (reservoir_size = mod N):\n",
    "      For each i in [0..N-1]:\n",
    "        W[i, (i+1) % mod N] = 1.0\n",
    "        W[i, (i+jump) % mod N] = 1.0\n",
    "    Then we scale by 'spectral_radius.' We do an ESN update\n",
    "    with readout [ x, x^2, 1 ] -> next step in R^3.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 reservoir_size=300,\n",
    "                 jump=10,                # offset for the jump\n",
    "                 spectral_radius=0.95,\n",
    "                 input_scale=1.0,\n",
    "                 leaking_rate=1.0,\n",
    "                 ridge_alpha=1e-6,\n",
    "                 seed=42):\n",
    "        \"\"\"\n",
    "        reservoir_size: how many nodes in the ring\n",
    "        jump            : the offset for the 2nd connection from node i\n",
    "        spectral_radius : scale adjacency\n",
    "        input_scale     : scale factor for W_in\n",
    "        leaking_rate    : ESN 'alpha'\n",
    "        ridge_alpha     : ridge penalty for readout\n",
    "        seed            : random seed\n",
    "        \"\"\"\n",
    "        self.reservoir_size = reservoir_size\n",
    "        self.jump = jump\n",
    "        self.spectral_radius = spectral_radius\n",
    "        self.input_scale = input_scale\n",
    "        self.leaking_rate = leaking_rate\n",
    "        self.ridge_alpha = ridge_alpha\n",
    "        self.seed = seed\n",
    "\n",
    "        # build adjacency\n",
    "        np.random.seed(self.seed)\n",
    "        W = np.zeros((reservoir_size, reservoir_size))\n",
    "        for i in range(reservoir_size):\n",
    "            # cycle edge: i -> (i+1)%N\n",
    "            W[i, (i+1) % reservoir_size] = 1.0\n",
    "            # jump edge: i -> (i+jump)%N\n",
    "            W[i, (i + self.jump) % reservoir_size] = 1.0\n",
    "\n",
    "        # scale spectral radius\n",
    "        W = scale_spectral_radius(W, self.spectral_radius)\n",
    "        self.W = W\n",
    "\n",
    "        # input weights => shape [N,3]\n",
    "        np.random.seed(self.seed+100)\n",
    "        W_in = (np.random.rand(reservoir_size, 3) - 0.5)*2.0*self.input_scale\n",
    "        self.W_in = W_in\n",
    "\n",
    "        # readout\n",
    "        self.W_out = None\n",
    "        self.x = np.zeros(self.reservoir_size)\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.x = np.zeros(self.reservoir_size)\n",
    "\n",
    "    def _update(self, u):\n",
    "        \"\"\"\n",
    "        Single-step ESN update:\n",
    "          x(t+1) = (1-alpha)*x(t) + alpha*tanh( W x(t) + W_in u(t) )\n",
    "        \"\"\"\n",
    "        pre_activation = self.W @ self.x + self.W_in @ u\n",
    "        x_new = np.tanh(pre_activation)\n",
    "        alpha = self.leaking_rate\n",
    "        self.x = (1.0 - alpha)*self.x + alpha*x_new\n",
    "\n",
    "    def collect_states(self, inputs, discard=100):\n",
    "        \"\"\"\n",
    "        Teacher forcing => feed the real 3D inputs => gather states.\n",
    "        Return (states_after_discard, states_discarded).\n",
    "        \"\"\"\n",
    "        self.reset_state()\n",
    "        states = []\n",
    "        for val in inputs:\n",
    "            self._update(val)\n",
    "            states.append(self.x.copy())\n",
    "        states = np.array(states)\n",
    "        return states[discard:], states[:discard]\n",
    "\n",
    "    def fit_readout(self, train_input, train_target, discard=100):\n",
    "        \"\"\"\n",
    "        gather states => polynomial readout => solve ridge\n",
    "        \"\"\"\n",
    "        states_use, _ = self.collect_states(train_input, discard=discard)\n",
    "        target_use = train_target[discard:]\n",
    "        X_list = []\n",
    "        for s in states_use:\n",
    "            # polynomial expansion => [ x, x^2, 1 ]\n",
    "            X_list.append(augment_state_with_squares(s))\n",
    "        X_aug = np.array(X_list)\n",
    "\n",
    "        reg = Ridge(alpha=self.ridge_alpha, fit_intercept=False)\n",
    "        reg.fit(X_aug, target_use)\n",
    "        self.W_out = reg.coef_  # shape => (3, 2N+1)\n",
    "\n",
    "    def predict_autoregressive(self, initial_input, n_steps):\n",
    "        \"\"\"\n",
    "        fully autoregressive => feed last output => next input\n",
    "        \"\"\"\n",
    "        preds = []\n",
    "        #self.reset_state()\n",
    "        current_in = np.array(initial_input)\n",
    "        for _ in range(n_steps):\n",
    "            self._update(current_in)\n",
    "            big_x = augment_state_with_squares(self.x)\n",
    "            out = self.W_out @ big_x  # shape => (3,)\n",
    "            preds.append(out)\n",
    "            current_in = out\n",
    "        return np.array(preds)\n",
    "        \n",
    "    def predict_open_loop(self, test_input):\n",
    "        preds = []\n",
    "        for true_input in test_input:\n",
    "            self._update(true_input)\n",
    "            x_aug = augment_state_with_squares(self.x)\n",
    "            out = self.W_out @ x_aug\n",
    "            preds.append(out)\n",
    "        return np.array(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T18:24:46.052075Z",
     "iopub.status.busy": "2025-06-07T18:24:46.051705Z",
     "iopub.status.idle": "2025-06-07T18:24:46.079191Z",
     "shell.execute_reply": "2025-06-07T18:24:46.077929Z",
     "shell.execute_reply.started": "2025-06-07T18:24:46.052018Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class SparseESN3D:\n",
    "    \"\"\"\n",
    "    Sparse random ESN for 3D->3D single-step,\n",
    "    teacher forcing for training, autoregressive for testing.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 reservoir_size=300,\n",
    "                 spectral_radius=0.95,\n",
    "                 connectivity=0.05,\n",
    "                 input_scale=1.0,\n",
    "                 leaking_rate=1.0,\n",
    "                 ridge_alpha=1e-6,\n",
    "                 seed=42):\n",
    "        self.reservoir_size = reservoir_size\n",
    "        self.spectral_radius = spectral_radius\n",
    "        self.connectivity = connectivity\n",
    "        self.input_scale = input_scale\n",
    "        self.leaking_rate = leaking_rate\n",
    "        self.ridge_alpha = ridge_alpha\n",
    "        self.seed = seed\n",
    "\n",
    "        np.random.seed(self.seed)\n",
    "        W_full = np.random.randn(reservoir_size, reservoir_size)*0.1\n",
    "        mask = (np.random.rand(reservoir_size, reservoir_size) < self.connectivity)\n",
    "        W = W_full * mask\n",
    "        W = scale_spectral_radius(W, self.spectral_radius)\n",
    "        self.W = W\n",
    "\n",
    "        np.random.seed(self.seed+1)\n",
    "        self.W_in = (np.random.rand(reservoir_size,3) - 0.5)*2.0*self.input_scale\n",
    "\n",
    "        self.W_out = None\n",
    "        self.x = np.zeros(reservoir_size)\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.x = np.zeros(self.reservoir_size)\n",
    "\n",
    "    def _update(self, u):\n",
    "        pre_activation = self.W @ self.x + self.W_in @ u\n",
    "        x_new = np.tanh(pre_activation)\n",
    "        alpha = self.leaking_rate\n",
    "        self.x = (1.0 - alpha)*self.x + alpha*x_new\n",
    "\n",
    "    def collect_states(self, inputs, discard=100):\n",
    "        self.reset_state()\n",
    "        states = []\n",
    "        for val in inputs:\n",
    "            self._update(val)\n",
    "            states.append(self.x.copy())\n",
    "        states = np.array(states)\n",
    "        return states[discard:], states[:discard]\n",
    "\n",
    "    def fit_readout(self, train_input, train_target, discard=100):\n",
    "        states_use, _ = self.collect_states(train_input, discard=discard)\n",
    "        targets_use = train_target[discard:]\n",
    "        # X_aug = np.hstack([states_use, np.ones((states_use.shape[0],1))])\n",
    "\n",
    "        # polynomial readout\n",
    "        X_list = []\n",
    "        for s in states_use:\n",
    "            X_list.append(augment_state_with_squares(s))\n",
    "        X_aug = np.array(X_list)  # shape => [T-discard, 2N+1]\n",
    "\n",
    "        reg = Ridge(alpha=self.ridge_alpha, fit_intercept=False)\n",
    "        reg.fit(X_aug, targets_use)\n",
    "        self.W_out = reg.coef_\n",
    "\n",
    "    def predict_autoregressive(self, initial_input, n_steps):\n",
    "        preds = []\n",
    "        current_in = np.array(initial_input)\n",
    "        for _ in range(n_steps):\n",
    "            self._update(current_in)\n",
    "            # x_aug = np.concatenate([self.x, [1.0]])\n",
    "            x_aug = augment_state_with_squares(self.x)\n",
    "            out = self.W_out @ x_aug\n",
    "            preds.append(out)\n",
    "            current_in = out\n",
    "        return np.array(preds)\n",
    "        \n",
    "    def predict_open_loop(self, test_input):\n",
    "        preds = []\n",
    "        for true_input in test_input:\n",
    "            self._update(true_input)\n",
    "            x_aug = augment_state_with_squares(self.x)\n",
    "            out = self.W_out @ x_aug\n",
    "            preds.append(out)\n",
    "        return np.array(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T18:30:07.416133Z",
     "iopub.status.busy": "2025-06-07T18:30:07.415647Z",
     "iopub.status.idle": "2025-06-07T18:30:07.444268Z",
     "shell.execute_reply": "2025-06-07T18:30:07.442079Z",
     "shell.execute_reply.started": "2025-06-07T18:30:07.416097Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class DeepESN3D:\n",
    "    \"\"\"\n",
    "    Deep Echo State Network (DeepESN) for multi-layered reservoir computing.\n",
    "    Each layer has its own reservoir, and the states are propagated through layers.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 num_layers=3,\n",
    "                 reservoir_size=100,\n",
    "                 spectral_radius=0.95,\n",
    "                 connectivity=0.1,\n",
    "                 input_scale=1.0,\n",
    "                 leaking_rate=1.0,\n",
    "                 ridge_alpha=1e-6,\n",
    "                 activation_choices=('tanh','relu','sin','linear'),\n",
    "                 seed=42):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        - num_layers: Number of reservoir layers.\n",
    "        - reservoir_size: Number of neurons in each reservoir layer.\n",
    "        \"\"\"\n",
    "        self.num_layers = num_layers\n",
    "        self.reservoir_size = reservoir_size\n",
    "        self.spectral_radius = spectral_radius\n",
    "        self.connectivity = connectivity\n",
    "        self.input_scale = input_scale\n",
    "        self.leaking_rate = leaking_rate\n",
    "        self.ridge_alpha = ridge_alpha\n",
    "        self.activation_choices = activation_choices\n",
    "        self.seed = seed\n",
    "\n",
    "        # Initialize reservoirs and input weights for each layer\n",
    "        self.reservoirs = []\n",
    "        self.input_weights = []\n",
    "        self.states = []\n",
    "\n",
    "        np.random.seed(self.seed)\n",
    "        for layer in range(num_layers):\n",
    "            np.random.seed(seed + layer)\n",
    "            W = np.random.randn(reservoir_size, reservoir_size) * 0.1\n",
    "            mask = (np.random.rand(reservoir_size, reservoir_size) < self.connectivity)\n",
    "            W = W * mask\n",
    "            W = scale_spectral_radius(W, spectral_radius)\n",
    "            self.reservoirs.append(W)\n",
    "\n",
    "            if layer == 0 : \n",
    "                W_in = (np.random.rand(reservoir_size, 3) - 0.5) * 2.0 * input_scale\n",
    "            else:\n",
    "                W_in = (np.random.rand(reservoir_size, reservoir_size) - 0.5) * 2.0 * input_scale\n",
    "            self.input_weights.append(W_in)\n",
    "\n",
    "        np.random.seed(self.seed + 200)\n",
    "        self.node_activations = np.random.choice(self.activation_choices, size=self.reservoir_size)\n",
    "        \n",
    "        self.W_out = None\n",
    "        self.reset_state()\n",
    "\n",
    "    def reset_state(self):\n",
    "        \"\"\"\n",
    "        Reset the states of all reservoir layers.\n",
    "        \"\"\"\n",
    "        self.states = [np.zeros(self.reservoir_size) for _ in range(self.num_layers)]\n",
    "\n",
    "    def _apply_activation(self, act_type, val):\n",
    "        return np.tanh(val)\n",
    "        # if act_type=='tanh':\n",
    "        #     return np.tanh(val)\n",
    "        # elif act_type=='relu':\n",
    "        #     return max(0.0, val)\n",
    "        # elif act_type=='sin':\n",
    "        #     return np.sin(val)\n",
    "        # elif act_type=='linear':\n",
    "        #     return val\n",
    "        # else:\n",
    "        #     return np.tanh(val)\n",
    "\n",
    "    def _update_layer(self, layer_idx, u):\n",
    "        \"\"\"\n",
    "        Update a single reservoir layer.\n",
    "        \"\"\"\n",
    "        pre_activation = self.reservoirs[layer_idx] @ self.states[layer_idx]\n",
    "        if layer_idx == 0:\n",
    "            pre_activation += self.input_weights[layer_idx] @ u\n",
    "        else:\n",
    "            pre_activation += self.input_weights[layer_idx] @ self.states[layer_idx - 1]\n",
    "\n",
    "        x_new = np.zeros_like(pre_activation)\n",
    "        for i in range(self.reservoir_size):\n",
    "            activation = self.node_activations[i]\n",
    "            x_new[i] = self._apply_activation(activation, pre_activation[i])\n",
    "        alpha = self.leaking_rate\n",
    "        self.states[layer_idx] = (1.0 - alpha) * self.states[layer_idx] + alpha * x_new\n",
    "\n",
    "    def collect_states(self, inputs, discard=100):\n",
    "        self.reset_state()\n",
    "        all_states = []\n",
    "        for u in inputs:\n",
    "            for layer_idx in range(self.num_layers):\n",
    "                self._update_layer(layer_idx, u)\n",
    "            all_states.append(np.concatenate(self.states))\n",
    "        all_states = np.array(all_states)\n",
    "        return all_states[discard:], all_states[:discard]\n",
    "\n",
    "    def fit_readout(self, train_input, train_target, discard=100):\n",
    "        \"\"\"\n",
    "        Train the readout layer using ridge regression.\n",
    "        \"\"\"\n",
    "        states_use, _ = self.collect_states(train_input, discard=discard)\n",
    "        targets_use = train_target[discard:]\n",
    "\n",
    "        # Augment states with bias\n",
    "        # X_aug = np.hstack([states_use, np.ones((states_use.shape[0], 1))])  # shape [T-discard, N*L+1]\n",
    "\n",
    "        # Quadratic readout\n",
    "        # Build augmented matrix [ x, x^2, 1 ]\n",
    "        X_list = []\n",
    "        for s in states_use:\n",
    "            X_list.append( np.concatenate([s, s**2, [1.0]]) )\n",
    "        X_aug = np.array(X_list)                                    # shape [T-discard, 2N*L+1]\n",
    "\n",
    "        reg = Ridge(alpha=self.ridge_alpha, fit_intercept=False)\n",
    "        reg.fit(X_aug, targets_use)\n",
    "        self.W_out = reg.coef_\n",
    "\n",
    "    def predict_open_loop(self, inputs):\n",
    "        \"\"\"\n",
    "        Single-step-ahead inference on test data.\n",
    "        \"\"\"\n",
    "        preds = []\n",
    "        for u in inputs:\n",
    "            for layer_idx in range(self.num_layers):\n",
    "                self._update_layer(layer_idx, u)\n",
    "            state = np.concatenate(self.states)\n",
    "            # x_aug = np.concatenate([state, [1.0]])\n",
    "            x_aug = np.concatenate([state, (state)**2, [1.0]])  # For quadrartic readout\n",
    "            out = self.W_out @ x_aug\n",
    "            preds.append(out)\n",
    "        return np.array(preds)\n",
    "\n",
    "    def predict_autoregressive(self, initial_input, num_steps):\n",
    "        \"\"\"\n",
    "        Autoregressive multi-step forecasting for num_steps\n",
    "        \"\"\"\n",
    "        preds = []\n",
    "        current_input = initial_input.copy()\n",
    "\n",
    "        for _ in range(num_steps):\n",
    "            for layer_idx in range(self.num_layers):\n",
    "                self._update_layer(layer_idx, current_input)\n",
    "            state = np.concatenate(self.states)\n",
    "            # x_aug = np.concatenate([state, [1.0]])\n",
    "            x_aug = np.concatenate([state, (state)**2, [1.0]])  # For quadrartic readout\n",
    "            out = self.W_out @ x_aug\n",
    "            preds.append(out)\n",
    "            current_input = out\n",
    "        \n",
    "        return np.array(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T18:24:46.113408Z",
     "iopub.status.busy": "2025-06-07T18:24:46.112973Z",
     "iopub.status.idle": "2025-06-07T18:24:46.773140Z",
     "shell.execute_reply": "2025-06-07T18:24:46.771944Z",
     "shell.execute_reply.started": "2025-06-07T18:24:46.113376Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import Ridge\n",
    "from scipy.integrate import odeint\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "\n",
    "def scale_spectral_radius(W, target_radius=0.95):   \n",
    "    \"\"\"\n",
    "    Scales a matrix W so that its largest eigenvalue magnitude = target_radius.\n",
    "    \"\"\"\n",
    "    eigvals = np.linalg.eigvals(W)\n",
    "    radius = np.max(np.abs(eigvals))\n",
    "    if radius == 0:\n",
    "        return W\n",
    "    return (W / radius) * target_radius\n",
    "\n",
    "def augment_state_with_squares(x):\n",
    "    \"\"\"\n",
    "    Given state vector x in R^N, return [ x, x^2, 1 ] in R^(2N+1).\n",
    "    We'll use this for both training and prediction.\n",
    "    \"\"\"\n",
    "    x_sq = x**2\n",
    "    return np.concatenate([x, x_sq, [1.0]])  # shape: 2N+1\n",
    "\n",
    "class CR3D:\n",
    "    \"\"\"\n",
    "    Cycle (ring) reservoir for 3D->3D single-step,\n",
    "    teacher forcing for training, autoregressive for testing.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 reservoir_size=300,\n",
    "                 spectral_radius=0.95,\n",
    "                 input_scale=1.0,\n",
    "                 leaking_rate=1.0,\n",
    "                 ridge_alpha=1e-6,\n",
    "                 seed=42):\n",
    "        self.reservoir_size = reservoir_size\n",
    "        self.spectral_radius = spectral_radius\n",
    "        self.input_scale = input_scale\n",
    "        self.leaking_rate = leaking_rate\n",
    "        self.ridge_alpha = ridge_alpha\n",
    "        self.seed = seed\n",
    "\n",
    "        np.random.seed(self.seed)\n",
    "        W = np.zeros((reservoir_size, reservoir_size))\n",
    "        for i in range(reservoir_size):\n",
    "            j = (i+1) % reservoir_size\n",
    "            W[i, j] = 1.0\n",
    "        W = scale_spectral_radius(W, self.spectral_radius)\n",
    "        self.W = W\n",
    "        \n",
    "        np.random.seed(self.seed+1)\n",
    "        self.W_in = (np.random.rand(reservoir_size,3) - 0.5)*2.0*self.input_scale\n",
    "\n",
    "        self.W_out = None\n",
    "        self.x = np.zeros(reservoir_size)\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.x = np.zeros(self.reservoir_size)\n",
    "    \n",
    "    def _update(self, u):\n",
    "        pre_activation = self.W @ self.x + self.W_in @ u\n",
    "        x_new = np.tanh(pre_activation)\n",
    "        alpha = self.leaking_rate\n",
    "        self.x = (1.0 - alpha)*self.x + alpha*x_new\n",
    "\n",
    "    def collect_states(self, inputs, discard=100):\n",
    "        self.reset_state()\n",
    "        states = []\n",
    "        for val in inputs:\n",
    "            self._update(val)\n",
    "            states.append(self.x.copy())\n",
    "        states = np.array(states)\n",
    "        return states[discard:], states[:discard]\n",
    "\n",
    "    def fit_readout(self, train_input, train_target, discard=100):\n",
    "        states_use, _ = self.collect_states(train_input, discard=discard)\n",
    "        targets_use = train_target[discard:]\n",
    "        X_list = []\n",
    "        for s in states_use:\n",
    "            X_list.append( np.concatenate([s, s**2, [1.0]]) )\n",
    "        X_aug = np.array(X_list) \n",
    "        reg = Ridge(alpha=self.ridge_alpha, fit_intercept=False)\n",
    "        reg.fit(X_aug, targets_use)\n",
    "        self.W_out = reg.coef_\n",
    "\n",
    "    def predict_autoregressive(self, initial_input, n_steps):\n",
    "        preds = []\n",
    "        current_in = np.array(initial_input)\n",
    "        for _ in range(n_steps):\n",
    "            self._update(current_in)\n",
    "            x_aug = np.concatenate([self.x, [1.0]])\n",
    "            out = self.W_out @ x_aug\n",
    "            preds.append(out)\n",
    "            current_in = out\n",
    "        return np.array(preds)\n",
    "    \n",
    "    def predict_open_loop(self, test_input):\n",
    "        preds = []\n",
    "        for true_input in test_input:\n",
    "            self._update(true_input)\n",
    "            x_aug = augment_state_with_squares(self.x)\n",
    "            out = self.W_out @ x_aug\n",
    "            preds.append(out)\n",
    "        return np.array(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T18:24:46.775011Z",
     "iopub.status.busy": "2025-06-07T18:24:46.774409Z",
     "iopub.status.idle": "2025-06-07T18:24:46.801984Z",
     "shell.execute_reply": "2025-06-07T18:24:46.800622Z",
     "shell.execute_reply.started": "2025-06-07T18:24:46.774970Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class MCI3D:\n",
    "    \"\"\"\n",
    "    Minimum Complexity Interaction ESN (MCI-ESN).\n",
    "\n",
    "    This class implements the approach described in:\n",
    "      \"A Minimum Complexity Interaction Echo State Network\"\n",
    "        by Jianming Liu, Xu Xu, Eric Li (2024).\n",
    "    \n",
    "    The model structure:\n",
    "      - We maintain two 'simple cycle' reservoirs (each of size N).\n",
    "      - Each reservoir is a ring with weight = l, i.e. \n",
    "            W_res[i, (i+1)%N] = l\n",
    "        plus the corner wrap from (N-1)->0, also = l. ##(unnecessary as already called for in the prev. line)\n",
    "      - The two reservoirs interact via a minimal connection matrix: \n",
    "         exactly 2 cross-connections with weight = g. \n",
    "         (One might connect x2[-1], x2[-2], ... \n",
    "          But we do where reservoir1 sees x2[-1] \n",
    "          in one location, and reservoir2 sees x1[-1] likewise.)\n",
    "      - Activation function in reservoir1 is cos(·), and in reservoir2 is sin(·).\n",
    "      - They each have a separate input weight matrix: Win1 and Win2. \n",
    "        The final state is a linear combination \n",
    "           x(t) = h*x1(t) + (1-h)*x2(t).\n",
    "      - Then we do a polynomial readout [x, x^2, 1] -> output.\n",
    "      - We feed teacher forcing in collect_states, \n",
    "        then solve readout with Ridge regression.\n",
    "\n",
    "    References:\n",
    "      - Liu, J., Xu, X., & Li, E. (2024). \n",
    "        \"A minimum complexity interaction echo state network,\" \n",
    "         Neural Computing and Applications.\n",
    "    \n",
    "    notes:\n",
    "      - The reservoir_size is N for each reservoir, \n",
    "        so total param dimension is 2*N for states, \n",
    "        but we produce a single final \"combined\" state x(t) in R^N for readout.\n",
    "      - The activation f1=cos(...) for reservoir1, f2=sin(...) for reservoir2, \n",
    "        as recommended by the paper for MCI-ESN.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        reservoir_size=500,\n",
    "        cycle_weight=0.9,      # 'l' in the paper\n",
    "        connect_weight=0.9,    # 'g' in the paper\n",
    "        input_scale=0.2,\n",
    "        leaking_rate=1.0,\n",
    "        ridge_alpha=1e-6,\n",
    "        combine_factor=0.1,    # 'h' in the paper\n",
    "        seed=47,\n",
    "        v1=0.6, v2=0.6         # fixed values for v1, v2\n",
    "    ):\n",
    "        \"\"\"\n",
    "        reservoir_size: N, size of each cycle reservoir \n",
    "        cycle_weight : l, ring adjacency weight in [0,1), ensures cycle synergy\n",
    "        connect_weight: g, cross-connection weight between the two cycle reservoirs\n",
    "        input_scale   : scale factor for input->reservoir weights\n",
    "        leaking_rate  : ESN update alpha \n",
    "        ridge_alpha   : readout ridge penalty\n",
    "        combine_factor: h in [0,1], to form x(t)= h*x1(t)+(1-h)*x2(t) as final combined state\n",
    "        seed          : random seed\n",
    "        \"\"\"\n",
    "        self.reservoir_size = reservoir_size\n",
    "        self.cycle_weight   = cycle_weight\n",
    "        self.connect_weight = connect_weight\n",
    "        self.input_scale    = input_scale\n",
    "        self.leaking_rate   = leaking_rate\n",
    "        self.ridge_alpha    = ridge_alpha\n",
    "        self.combine_factor = combine_factor\n",
    "        self.seed           = seed\n",
    "        self.v1 = v1\n",
    "        self.v2 = v2\n",
    "\n",
    "        # We'll define (and build) adjacency for each cycle, \n",
    "        # plus cross-connection for two sub-reservoirs.\n",
    "        # We'll define 2 input weight mats: Win1, Win2.\n",
    "        # We'll define states x1(t), x2(t).\n",
    "        # We'll define readout W_out after training.\n",
    "\n",
    "        self._build_mci_esn()\n",
    "\n",
    "    def _build_mci_esn(self):\n",
    "        \"\"\"\n",
    "        Build all the internal parameters: \n",
    "         - ring adjacency for each reservoir\n",
    "         - cross-reservoir connection\n",
    "         - input weights for each reservoir\n",
    "         - initial states\n",
    "        \"\"\"\n",
    "        np.random.seed(self.seed)\n",
    "\n",
    "        N = self.reservoir_size\n",
    "\n",
    "        # Build ring adjacency W_res in shape [N, N], with cycle_weight on ring\n",
    "        W_res = np.zeros((N, N))\n",
    "        for i in range(N):\n",
    "            j = (i+1) % N\n",
    "            W_res[j, i] = self.cycle_weight\n",
    "        self.W_res = W_res  # shared by both sub-reservoirs\n",
    "\n",
    "        # Build cross-connection W_cn for shape [N,N], \n",
    "        # minimal 2 nonzero elements. \n",
    "        # For the simplest approach from the paper:\n",
    "        #   W_cn[0, N-1] = g, W_cn[1, N-2] = g or similar.\n",
    "        # The paper's eq(7) suggests the last 2 elements in x(t) cross to first 2 in the other reservoir:\n",
    "        # We'll do the simplest reference: if i=0 or i=1, we connect from the other reservoir's last or second-last. \n",
    "        # We'll define a function for each sub-res to pick up from the other sub-res. \n",
    "        # We can store them in separate arrays, or define them in code. \n",
    "        # We'll just store \"We want index 0 to see x2[-1], index 1 to see x2[-2].\"\n",
    "\n",
    "        # But as done in the original code snippet from the paper:\n",
    "        #   Wcn has\n",
    "        # effectively 2 nonzero positions. We'll define that pattern:\n",
    "        W_cn = np.zeros((N, N))\n",
    "        # e.g. W_cn[0, N-1] = g, W_cn[N-1, N-2] = g or something. \n",
    "        # The paper example used W_cn = diag(0,g,...) plus the corner. We'll do the simplest:\n",
    "        # let W_cn[0, N-1]=g, W_cn[1, N-2]=g.\n",
    "        # This matches the minimal cross. \n",
    "        # For clarity we do:\n",
    "        W_cn[0, N-1] = self.connect_weight\n",
    "        if N>1:\n",
    "            # W_cn[1, N-2] = self.connect_weight\n",
    "            W_cn[N-1, 0] = self.connect_weight\n",
    "        self.W_cn = W_cn\n",
    "\n",
    "        # We'll define input weights for each sub-reservoir, shape [N, dim_input].\n",
    "        # The paper sets them as eq(10) in the snippet, with different signs. \n",
    "        # We'll define them as parted. \n",
    "        # We define V1, V2 => shape [N, dim_input], with constant magnitude t1, t2, random sign. \n",
    "        # We'll do random. Need to check this in the paper again\n",
    "        # We'll keep \"two\" separate. user can define input_scale but not two separate. \n",
    "        # We'll do the simplest approach: the absolute value is the same => input_scale, \n",
    "        # sign is random. Then we define Win1 = V1 - V2, Win2 = V1 + V2.\n",
    "        # This is consistent with eq(10) from the paper.\n",
    "\n",
    "        self.Win1 = None\n",
    "        self.Win2 = None\n",
    "\n",
    "        # We'll define states x1(t), x2(t). We'll do them after dimension known. \n",
    "        self.x1 = None\n",
    "        self.x2 = None\n",
    "\n",
    "        self.W_out = None\n",
    "\n",
    "    def _init_substates(self):\n",
    "        \"\"\"\n",
    "        Once we know reservoir_size, we define x1, x2 as zeros. \n",
    "        We'll call this in reset_state or at fit time.\n",
    "        \"\"\"\n",
    "        N = self.reservoir_size\n",
    "        self.x1 = np.zeros(N)\n",
    "        self.x2 = np.zeros(N)\n",
    "\n",
    "    def reset_state(self):\n",
    "        if self.x1 is not None:\n",
    "            self.x1[:] = 0.0\n",
    "        if self.x2 is not None:\n",
    "            self.x2[:] = 0.0\n",
    "\n",
    "    def _update(self, u):\n",
    "        \"\"\"\n",
    "        Single-step reservoir update.\n",
    "        x1(t+1) = cos( Win1*u(t+1) + W_res*x1(t) + W_cn*x2(t) )\n",
    "        x2(t+1) = sin( Win2*u(t+1) + W_res*x2(t) + W_cn*x1(t) )\n",
    "        Then x(t)= h*x1(t+1) + (1-h)* x2(t+1).\n",
    "        We'll define the leaky integration. \n",
    "        But the paper uses an approach with no leak? Be careful.\n",
    "        We'll do the approach: x1(t+1)= (1-alpha)* x1(t) + alpha*cos(...).\n",
    "        \"\"\"\n",
    "        alpha = self.leaking_rate\n",
    "\n",
    "        # pre activation for reservoir1\n",
    "        pre1 = self.Win1 @ u + self.W_res @ self.x1 + self.W_cn @ self.x2\n",
    "        # reservoir1 uses cos\n",
    "        new_x1 = np.cos(pre1)\n",
    "\n",
    "        # reservoir2 uses sin\n",
    "        pre2 = self.Win2 @ u + self.W_res @ self.x2 + self.W_cn @ self.x1\n",
    "        new_x2 = np.sin(pre2)\n",
    "\n",
    "        self.x1 = (1.0 - alpha)*self.x1 + alpha*new_x1\n",
    "        self.x2 = (1.0 - alpha)*self.x2 + alpha*new_x2\n",
    "\n",
    "    def _combine_state(self):\n",
    "        \"\"\"\n",
    "        Combine x1(t), x2(t) => x(t) = h*x1 + (1-h)*x2\n",
    "        \"\"\"\n",
    "        h = self.combine_factor\n",
    "        return h*self.x1 + (1.0 - h)*self.x2\n",
    "\n",
    "    def collect_states(self, inputs, discard=100):\n",
    "        # We reset the reservoir to zero\n",
    "        self.reset_state()\n",
    "        states = []\n",
    "        for t in range(len(inputs)):\n",
    "            self._update(inputs[t])   # feed the REAL input from the dataset\n",
    "            combined = self._combine_state()\n",
    "            states.append(combined.copy())\n",
    "        states = np.array(states)  # shape => [T, N]\n",
    "        return states[discard:], states[:discard]\n",
    "\n",
    "\n",
    "    def fit_readout(self, train_input, train_target, discard=100):\n",
    "        \"\"\"\n",
    "        Build input weights if needed, gather states on the training data (teacher forcing),\n",
    "        then solve a polynomial readout [x, x^2, 1]->train_target(t).\n",
    "\n",
    "        train_input : shape [T, d_in]\n",
    "        train_target: shape [T, d_out]\n",
    "        discard     : # of states to discard for warmup\n",
    "        \"\"\"\n",
    "        T = len(train_input)\n",
    "        if T<2:\n",
    "            raise ValueError(\"Not enough training data\")\n",
    "\n",
    "        d_in = train_input.shape[1]\n",
    "        # d_out = train_target.shape[1]\n",
    "\n",
    "        # built Win1, Win2\n",
    "        if self.Win1 is None or self.Win2 is None:\n",
    "            np.random.seed(self.seed+100)\n",
    "            # build V1, V2 in shape [N, d_in]\n",
    "            N = self.reservoir_size\n",
    "            # V1 = (np.random.rand(N, d_in)-0.5)*2.0*self.input_scale\n",
    "            # V2 = (np.random.rand(N, d_in)-0.5)*2.0*self.input_scale\n",
    "\n",
    "            sign_V1 = np.random.choice([-1, 1], size=(N, d_in))\n",
    "            sign_V2 = np.random.choice([-1, 1], size=(N, d_in))\n",
    "\n",
    "            v1, v2 = self.v1, self.v2  # fixed values for V1, V2\n",
    "\n",
    "            V1 = v1 * sign_V1 * self.input_scale\n",
    "            V2 = v2 * sign_V2 * self.input_scale\n",
    "\n",
    "            # eq(10): Win1= V1 - V2, Win2= V1 + V2\n",
    "            self.Win1 = V1 - V2\n",
    "            self.Win2 = V1 + V2\n",
    "\n",
    "        # define x1, x2\n",
    "        self._init_substates()\n",
    "\n",
    "        # gather states\n",
    "        states_use, _ = self.collect_states(train_input, discard=discard)\n",
    "        target_use = train_target[discard:]  # shape => [T-discard, d_out]\n",
    "\n",
    "        # polynomial readout\n",
    "        X_list = []\n",
    "        for s in states_use:\n",
    "            X_list.append(augment_state_with_squares(s))\n",
    "        X_aug = np.array(X_list)  # shape => [T-discard, 2N+1]\n",
    "\n",
    "        # Solve ridge\n",
    "        reg = Ridge(alpha=self.ridge_alpha, fit_intercept=False)\n",
    "        reg.fit(X_aug, target_use)\n",
    "        # W_out => shape [d_out, 2N+1]\n",
    "        self.W_out = reg.coef_\n",
    "\n",
    "    def predict_autoregressive(self, initial_input, n_steps):\n",
    "        \"\"\"\n",
    "        Fully autoregressive: \n",
    "          We do not use teacher forcing, \n",
    "          we feed the model's last output as the next input \n",
    "        Typically, for MCI-ESN the paper does input(t+1) in R^d. \n",
    "        We do the test_input\n",
    "        For multi-step chaotic forecast, we feed the model's output as input? \n",
    "        That means the system dimension d_in must match d_out. \n",
    "        \"\"\"\n",
    "        preds = []\n",
    "        # re-init states\n",
    "        #self._init_substates()\n",
    "\n",
    "        # we assume initial_input => shape (d_in,)\n",
    "        current_in = np.array(initial_input)\n",
    "\n",
    "        for _ in range(n_steps):\n",
    "            self._update(current_in)\n",
    "            # read out\n",
    "            combined = self._combine_state()\n",
    "            big_x = augment_state_with_squares(combined)\n",
    "            out = self.W_out @ big_x  # shape => (d_out,)\n",
    "\n",
    "            preds.append(out)\n",
    "            current_in = out  # feed output back as next input\n",
    "\n",
    "        return np.array(preds)\n",
    "        \n",
    "    def predict_open_loop(self, test_input):\n",
    "        preds = []\n",
    "        for true_input in test_input:\n",
    "            self._update(true_input)\n",
    "            combined = self._combine_state()\n",
    "            x_aug = augment_state_with_squares(combined)\n",
    "            out = self.W_out @ x_aug\n",
    "            preds.append(out)\n",
    "        return np.array(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T18:58:05.407943Z",
     "iopub.status.busy": "2025-06-07T18:58:05.407630Z",
     "iopub.status.idle": "2025-06-07T18:58:05.419024Z",
     "shell.execute_reply": "2025-06-07T18:58:05.417891Z",
     "shell.execute_reply.started": "2025-06-07T18:58:05.407920Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def run_grid_search(genfunc,model_class, param_grid, model_name,fracs):\n",
    "    combos = list(itertools.product(*param_grid.values()))\n",
    "    param_keys = list(param_grid.keys())\n",
    "\n",
    "    results = []\n",
    "    horizons = [200, 400, 600, 800, 1000]\n",
    "\n",
    "    for comb in combos:\n",
    "        params = dict(zip(param_keys, comb))\n",
    "        # seed_scores_vpt = []\n",
    "        horizon_nrmse_all = {h: [] for h in horizons}\n",
    "        # adev_scores = []\n",
    "        # ldev_scores = []\n",
    "\n",
    "        for initial_state in [[1.0, 1.0, 1.0], [1.0, 2.0, 3.0], [2.0, 1.5, 4.0]]:\n",
    "            tmax = 250\n",
    "            dt = 0.02\n",
    "            t_vals, lorenz_traj = genfunc(\n",
    "                initial_state=initial_state,\n",
    "                tmax=tmax,\n",
    "                dt=dt\n",
    "            )\n",
    "\n",
    "            washout = 2000\n",
    "            t_vals = t_vals[washout:]\n",
    "            lorenz_traj = lorenz_traj[washout:]\n",
    "\n",
    "            scaler = MinMaxScaler()\n",
    "            scaler.fit(lorenz_traj)\n",
    "            lorenz_traj = scaler.transform(lorenz_traj)\n",
    "\n",
    "            T_data = len(lorenz_traj)\n",
    "            for train_frac in fracs:\n",
    "                train_end = int(train_frac * (T_data - 1))\n",
    "                train_input = lorenz_traj[:train_end]\n",
    "                train_target = lorenz_traj[1:train_end + 1]\n",
    "                test_input = lorenz_traj[train_end:-1]\n",
    "                test_target = lorenz_traj[train_end + 1:]\n",
    "                n_test_steps = len(test_input)\n",
    "                initial_in = test_input[0]\n",
    "\n",
    "                for seed in np.arange(1, 6):\n",
    "                    model = model_class(**params, seed=seed)\n",
    "                    model.fit_readout(train_input, train_target, discard=100)\n",
    "                    preds = model.predict_open_loop(test_input)\n",
    "\n",
    "                    # T_VPT_s, _, _ = compute_valid_prediction_time(test_target, preds, t_vals, 0.4, 0.9, dt)\n",
    "                    # seed_scores_vpt.append(T_VPT_s)\n",
    "\n",
    "                    horizon_nrmse = evaluate_nrmse(preds, test_target, horizons)\n",
    "                    for h in horizons:\n",
    "                        horizon_nrmse_all[h].append(horizon_nrmse[h])\n",
    "\n",
    "                    # adev = compute_attractor_deviation(preds, test_target)\n",
    "                    # adev_scores.append(adev)\n",
    "\n",
    "                    # ldev = compute_lyapunov_exponent(\"Lorenz\", preds, dt)\n",
    "                    # ldev_scores.append(ldev)\n",
    "\n",
    "        # mean_vpt = float(np.mean(seed_scores_vpt))\n",
    "        # std_vpt = float(np.std(seed_scores_vpt))\n",
    "        mean_nrmse_dict = {str(h): float(np.mean(horizon_nrmse_all[h])) for h in horizons}\n",
    "        std_nrmse_dict  = {str(h): float(np.std(horizon_nrmse_all[h]))  for h in horizons}\n",
    "        # mean_adev = float(np.mean(adev_scores))\n",
    "        # std_adev = float(np.std(adev_scores))\n",
    "        # mean_ldev = float(np.mean(ldev_scores))\n",
    "        # std_ldev = float(np.std(ldev_scores))\n",
    "        dataset=genfunc.__name__\n",
    "\n",
    "        results.append({\n",
    "            \"dataset\":dataset[9:-5],\n",
    "            \"model\":model_class.__name__,\n",
    "            \"params\": params,\n",
    "            # \"seed_scores_T_VPT\": seed_scores_vpt,\n",
    "            # \"mean_T_VPT\": mean_vpt,\n",
    "            # \"std_T_VPT\": std_vpt,\n",
    "            \"mean_NRMSEs\": mean_nrmse_dict,\n",
    "            \"std_NRMSEs\": std_nrmse_dict,\n",
    "            # \"mean_ADev\": mean_adev,\n",
    "            # \"std_ADev\": std_adev,\n",
    "            # \"mean_LDev\": mean_ldev,\n",
    "            # \"std_LDev\": std_ldev\n",
    "        })\n",
    "        print(results)\n",
    "\n",
    "    # with open(output_path, \"w\") as f:\n",
    "    #     json.dump(results, f, indent=2)\n",
    "    # print(f\"\\nAll results saved to `{output_path}`\")\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T18:56:15.878919Z",
     "iopub.status.busy": "2025-06-07T18:56:15.878616Z",
     "iopub.status.idle": "2025-06-07T18:56:15.893335Z",
     "shell.execute_reply": "2025-06-07T18:56:15.891959Z",
     "shell.execute_reply.started": "2025-06-07T18:56:15.878897Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "grid={\n",
    "    generate_lorenz_data:{\n",
    "        SparseESN3D:{\n",
    "            \"spectral_radius\":[0.98],\n",
    "            \"connectivity\":[0.05],\n",
    "            \"input_scale\":[1.0],\n",
    "            \"ridge_alpha\":[1e-7],\n",
    "            \"leaking_rate\":[0.9],\n",
    "        },\n",
    "        CR3D:{\n",
    "            \"spectral_radius\":[0.92],\n",
    "            \"input_scale\":[1.0],\n",
    "            \"ridge_alpha\":[0.00000001],\n",
    "            \"leaking_rate\":[0.6],\n",
    "        },\n",
    "        CRJ3D:{\n",
    "            \"spectral_radius\":[0.98],\n",
    "            \"jump\":[15],\n",
    "            \"input_scale\":[1.0],\n",
    "            \"ridge_alpha\":[1e-7],\n",
    "            \"leaking_rate\":[0.7],\n",
    "        },\n",
    "        DeepESN3D:{\n",
    "            \"spectral_radius\":[0.92],\n",
    "            \"connectivity\":[0.01],\n",
    "            \"input_scale\":[0.6],\n",
    "            \"ridge_alpha\":[1e-7],\n",
    "            \"leaking_rate\":[0.5],\n",
    "        },\n",
    "        MCI3D:{\n",
    "            \"cycle_weight\":[0.8],\n",
    "            \"connect_weight\":[0.6],\n",
    "            \"input_scale\":[0.7],\n",
    "            \"leaking_rate\":[0.9],\n",
    "            \"combine_factor\":[0.2],\n",
    "            \"ridge_alpha\":[1e-7],\n",
    "        },\n",
    "        HFRRes3D:{\n",
    "            \"cells_per_level\":[[5, 10, 15, 20, 25, 35, 45, 50, 95]],\n",
    "            \"spectral_radius\":[0.92],\n",
    "            \"input_scale\":[1],\n",
    "            \"leaking_rate\":[0.9],\n",
    "            \"ridge_alpha\":[1e-8]\n",
    "        }\n",
    "    },\n",
    "    generate_rossler_data:{\n",
    "        SparseESN3D:{\n",
    "            \"spectral_radius\":[0.92],\n",
    "            \"connectivity\":[0.3],\n",
    "            \"input_scale\":[0.5],\n",
    "            \"ridge_alpha\":[1e-7],\n",
    "            \"leaking_rate\":[0.9],\n",
    "        },\n",
    "        CR3D:{\n",
    "            \"spectral_radius\":[0.85],\n",
    "            \"input_scale\":[1.0],\n",
    "            \"ridge_alpha\":[1e-8],\n",
    "            \"leaking_rate\":[0.05],\n",
    "        },\n",
    "        CRJ3D:{\n",
    "            \"spectral_radius\":[0.92],\n",
    "            \"jump\":[10],\n",
    "            \"input_scale\":[0.6],\n",
    "            \"ridge_alpha\":[1e-7],\n",
    "            \"leaking_rate\":[0.9],\n",
    "        },\n",
    "        DeepESN3D:{\n",
    "            \"spectral_radius\":[0.88],\n",
    "            \"connectivity\":[0.001],\n",
    "            \"input_scale\":[0.4],\n",
    "            \"ridge_alpha\":[1e-7],\n",
    "            \"leaking_rate\":[0.5],\n",
    "        },\n",
    "        MCI3D:{\n",
    "            \"cycle_weight\":[0.8],\n",
    "            \"connect_weight\":[1],\n",
    "            \"input_scale\":[0.7],\n",
    "            \"leaking_rate\":[0.9],\n",
    "            \"combine_factor\":[0.8],\n",
    "            \"ridge_alpha\":[1e-7],\n",
    "        },\n",
    "        HFRRes3D:{\n",
    "            \"cells_per_level\":[[5, 35, 105, 155]],\n",
    "            \"spectral_radius\":[0.92],\n",
    "            \"input_scale\":[0.3],\n",
    "            \"leaking_rate\":[0.8],\n",
    "            \"ridge_alpha\":[1e-8]\n",
    "        }\n",
    "    },\n",
    "    generate_chen_data:{\n",
    "        SparseESN3D:{\n",
    "            \"spectral_radius\":[0.92],\n",
    "            \"connectivity\":[0.2],\n",
    "            \"input_scale\":[1.0],\n",
    "            \"ridge_alpha\":[1e-7],\n",
    "            \"leaking_rate\":[0.9],\n",
    "        },\n",
    "        CR3D:{\n",
    "            \"spectral_radius\":[0.65],\n",
    "            \"input_scale\":[1.0],\n",
    "            \"ridge_alpha\":[1e-8],\n",
    "            \"leaking_rate\":[0.7],\n",
    "        },\n",
    "        CRJ3D:{\n",
    "            \"spectral_radius\":[0.92],\n",
    "            \"jump\":[5],\n",
    "            \"input_scale\":[1.0],\n",
    "            \"ridge_alpha\":[1e-7],\n",
    "            \"leaking_rate\":[0.9],\n",
    "        },\n",
    "        DeepESN3D:{\n",
    "            \"spectral_radius\":[0.85],\n",
    "            \"connectivity\":[0.001],\n",
    "            \"input_scale\":[0.6],\n",
    "            \"ridge_alpha\":[1e-7],\n",
    "            \"leaking_rate\":[0.9],\n",
    "        },\n",
    "        MCI3D:{\n",
    "            \"cycle_weight\":[0.4],\n",
    "            \"connect_weight\":[0.6],\n",
    "            \"input_scale\":[0.7],\n",
    "            \"leaking_rate\":[0.9],\n",
    "            \"combine_factor\":[0.6],\n",
    "            \"ridge_alpha\":[1e-7],\n",
    "        },\n",
    "        HFRRes3D:{\n",
    "            \"cells_per_level\":[[5, 10, 60, 225]],\n",
    "            \"spectral_radius\":[0.92],\n",
    "            \"input_scale\":[1],\n",
    "            \"leaking_rate\":[0.9],\n",
    "            \"ridge_alpha\":[1e-8]\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T18:58:10.684639Z",
     "iopub.status.busy": "2025-06-07T18:58:10.684326Z",
     "iopub.status.idle": "2025-06-07T19:26:51.006429Z",
     "shell.execute_reply": "2025-06-07T19:26:51.005315Z",
     "shell.execute_reply.started": "2025-06-07T18:58:10.684614Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search class:  17%|█▋        | 1/6 [05:06<25:30, 306.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'dataset': 'rossler', 'model': 'DeepESN3D', 'params': {'spectral_radius': 0.88, 'connectivity': 0.001, 'input_scale': 0.4, 'ridge_alpha': 1e-07, 'leaking_rate': 0.5}, 'mean_NRMSEs': {'200': 1.3939054535449893e-05, '400': 2.1023997965808694e-05, '600': 6.414302000461885e-05, '800': 6.725186643245913e-05, '1000': 6.295839945185456e-05}, 'std_NRMSEs': {'200': 1.4791827417299545e-05, '400': 2.907114838085992e-05, '600': 0.00013557662739626942, '800': 0.0001294791596085803, '1000': 0.00012103950059932257}}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search class:  33%|███▎      | 2/6 [07:07<13:09, 197.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'dataset': 'rossler', 'model': 'MCI3D', 'params': {'cycle_weight': 0.8, 'connect_weight': 1, 'input_scale': 0.7, 'leaking_rate': 0.9, 'combine_factor': 0.8, 'ridge_alpha': 1e-07}, 'mean_NRMSEs': {'200': 4.5515294118464235e-06, '400': 1.115541882879383e-05, '600': 5.226558217505906e-05, '800': 5.414477779545703e-05, '1000': 5.0971154912126235e-05}, 'std_NRMSEs': {'200': 4.949412055871319e-06, '400': 1.7738153701609998e-05, '600': 0.00012025545878571151, '800': 0.0001145264744326394, '1000': 0.000107005196505032}}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search class:  50%|█████     | 3/6 [07:40<06:06, 122.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'dataset': 'rossler', 'model': 'CR3D', 'params': {'spectral_radius': 0.85, 'input_scale': 1.0, 'ridge_alpha': 1e-08, 'leaking_rate': 0.05}, 'mean_NRMSEs': {'200': 0.00024058605812449615, '400': 0.0002645674813399867, '600': 0.0003112973727871301, '800': 0.00029179748792673786, '1000': 0.0003118167012444516}, 'std_NRMSEs': {'200': 0.0004837465587795319, '400': 0.0004697212308467063, '600': 0.00041153055698618993, '800': 0.0003606390667685025, '1000': 0.000411155494064371}}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search class:  67%|██████▋   | 4/6 [08:06<02:49, 84.51s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'dataset': 'rossler', 'model': 'CRJ3D', 'params': {'spectral_radius': 0.92, 'jump': 10, 'input_scale': 0.6, 'ridge_alpha': 1e-07, 'leaking_rate': 0.9}, 'mean_NRMSEs': {'200': 5.857901340586898e-06, '400': 8.734033189101012e-06, '600': 2.7959389089878936e-05, '800': 2.8455739094670066e-05, '1000': 2.6662696648585417e-05}, 'std_NRMSEs': {'200': 5.616453713134303e-06, '400': 1.0803553185898816e-05, '600': 5.8651405172099245e-05, '800': 5.606008204593169e-05, '1000': 5.242560746264099e-05}}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search class:  83%|████████▎ | 5/6 [08:33<01:03, 63.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'dataset': 'rossler', 'model': 'SparseESN3D', 'params': {'spectral_radius': 0.92, 'connectivity': 0.3, 'input_scale': 0.5, 'ridge_alpha': 1e-07, 'leaking_rate': 0.9}, 'mean_NRMSEs': {'200': 5.14048549788965e-06, '400': 8.323572425693124e-06, '600': 2.933010925845956e-05, '800': 3.003865251243186e-05, '1000': 2.8122474482086253e-05}, 'std_NRMSEs': {'200': 4.010572407480985e-06, '400': 1.0724834520048001e-05, '600': 6.849854600720692e-05, '800': 6.544135272021859e-05, '1000': 6.121329770782816e-05}}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search class: 100%|██████████| 6/6 [09:11<00:00, 91.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'dataset': 'rossler', 'model': 'HFRRes3D', 'params': {'cells_per_level': [5, 35, 105, 155], 'spectral_radius': 0.92, 'input_scale': 0.3, 'leaking_rate': 0.8, 'ridge_alpha': 1e-08}, 'mean_NRMSEs': {'200': 5.553419095877834e-06, '400': 7.861558646553292e-06, '600': 2.105251194651262e-05, '800': 2.1717780924341857e-05, '1000': 2.03765098807574e-05}, 'std_NRMSEs': {'200': 6.598306015410157e-06, '400': 9.395735241601716e-06, '600': 4.175656821703861e-05, '800': 3.9874393927300235e-05, '1000': 3.73187474641881e-05}}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search class:  17%|█▋        | 1/6 [05:12<26:03, 312.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'dataset': 'lorenz', 'model': 'DeepESN3D', 'params': {'spectral_radius': 0.92, 'connectivity': 0.01, 'input_scale': 0.6, 'ridge_alpha': 1e-07, 'leaking_rate': 0.5}, 'mean_NRMSEs': {'200': 2.963672659242853e-06, '400': 2.7102273945674023e-06, '600': 3.044986834666208e-06, '800': 4.138491374409624e-06, '1000': 4.329609198520695e-06}, 'std_NRMSEs': {'200': 7.394072137875332e-07, '400': 5.811266182847053e-07, '600': 1.6638581027789164e-06, '800': 5.991691959066826e-06, '1000': 5.607687260770061e-06}}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search class:  33%|███▎      | 2/6 [07:21<13:36, 204.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'dataset': 'lorenz', 'model': 'MCI3D', 'params': {'cycle_weight': 0.8, 'connect_weight': 0.6, 'input_scale': 0.7, 'leaking_rate': 0.9, 'combine_factor': 0.2, 'ridge_alpha': 1e-07}, 'mean_NRMSEs': {'200': 5.885546831183074e-07, '400': 5.514558305882226e-07, '600': 5.531620676476583e-07, '800': 5.688490925415523e-07, '1000': 5.776327538695476e-07}, 'std_NRMSEs': {'200': 1.3134327583697039e-07, '400': 1.1715810081932573e-07, '600': 1.0456284961343161e-07, '800': 1.1264062671632396e-07, '1000': 1.1405013176659152e-07}}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search class:  50%|█████     | 3/6 [07:55<06:20, 126.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'dataset': 'lorenz', 'model': 'CR3D', 'params': {'spectral_radius': 0.92, 'input_scale': 1.0, 'ridge_alpha': 1e-08, 'leaking_rate': 0.6}, 'mean_NRMSEs': {'200': 5.642197329175448e-07, '400': 5.126801724410421e-07, '600': 5.588242916622169e-07, '800': 6.304621880986062e-07, '1000': 6.856444739747566e-07}, 'std_NRMSEs': {'200': 1.6390745983835812e-07, '400': 1.0643896760748682e-07, '600': 1.9979346892188922e-07, '800': 4.160024077053741e-07, '1000': 4.593429014569352e-07}}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search class:  67%|██████▋   | 4/6 [08:24<02:56, 88.33s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'dataset': 'lorenz', 'model': 'CRJ3D', 'params': {'spectral_radius': 0.98, 'jump': 15, 'input_scale': 1.0, 'ridge_alpha': 1e-07, 'leaking_rate': 0.7}, 'mean_NRMSEs': {'200': 1.584391584305436e-06, '400': 1.4586764284030212e-06, '600': 1.4762878553997032e-06, '800': 1.5487697605568086e-06, '1000': 1.5609036466187957e-06}, 'std_NRMSEs': {'200': 4.0646591507765023e-07, '400': 2.8681994326913914e-07, '600': 2.9068175354350135e-07, '800': 3.749369707461538e-07, '1000': 3.5483058660940745e-07}}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search class:  83%|████████▎ | 5/6 [08:54<01:07, 67.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'dataset': 'lorenz', 'model': 'SparseESN3D', 'params': {'spectral_radius': 0.98, 'connectivity': 0.05, 'input_scale': 1.0, 'ridge_alpha': 1e-07, 'leaking_rate': 0.9}, 'mean_NRMSEs': {'200': 1.3082136704972425e-06, '400': 1.2172570808844313e-06, '600': 1.2089596204118861e-06, '800': 1.2364537922031852e-06, '1000': 1.2467556767633794e-06}, 'std_NRMSEs': {'200': 2.3647849455067346e-07, '400': 1.915489212431979e-07, '600': 1.7302767113766803e-07, '800': 1.7856184744066308e-07, '1000': 1.7967533879036147e-07}}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search class: 100%|██████████| 6/6 [09:49<00:00, 98.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'dataset': 'lorenz', 'model': 'HFRRes3D', 'params': {'cells_per_level': [5, 10, 15, 20, 25, 35, 45, 50, 95], 'spectral_radius': 0.92, 'input_scale': 1, 'leaking_rate': 0.9, 'ridge_alpha': 1e-08}, 'mean_NRMSEs': {'200': 5.984864144204063e-07, '400': 5.524417468895569e-07, '600': 5.611077349086822e-07, '800': 5.974385192106466e-07, '1000': 6.029750915255971e-07}, 'std_NRMSEs': {'200': 1.312887882249226e-07, '400': 1.0358961399786052e-07, '600': 1.1424024644842606e-07, '800': 1.9439894113509418e-07, '1000': 1.8370901814908683e-07}}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search class:  17%|█▋        | 1/6 [05:08<25:41, 308.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'dataset': 'chen', 'model': 'DeepESN3D', 'params': {'spectral_radius': 0.85, 'connectivity': 0.001, 'input_scale': 0.6, 'ridge_alpha': 1e-07, 'leaking_rate': 0.9}, 'mean_NRMSEs': {'200': 6.030059021100808e-06, '400': 2.568903252865403e-05, '600': 2.2089010497087996e-05, '800': 1.997287750101234e-05, '1000': 3.158975092086715e-05}, 'std_NRMSEs': {'200': 2.3830916839051306e-06, '400': 5.867859357720859e-05, '600': 4.804579150842202e-05, '800': 4.231104679765771e-05, '1000': 5.1085157652851924e-05}}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search class:  33%|███▎      | 2/6 [07:17<13:32, 203.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'dataset': 'chen', 'model': 'MCI3D', 'params': {'cycle_weight': 0.4, 'connect_weight': 0.6, 'input_scale': 0.7, 'leaking_rate': 0.9, 'combine_factor': 0.6, 'ridge_alpha': 1e-07}, 'mean_NRMSEs': {'200': 1.7910870609843126e-06, '400': 3.773943453044265e-06, '600': 3.3833339674890823e-06, '800': 3.1481653720872642e-06, '1000': 4.271590538344777e-06}, 'std_NRMSEs': {'200': 3.2992961318103155e-07, '400': 5.572729509875678e-06, '600': 4.508561273908034e-06, '800': 3.935220802580664e-06, '1000': 4.684028803932206e-06}}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search class:  50%|█████     | 3/6 [07:52<06:18, 126.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'dataset': 'chen', 'model': 'CR3D', 'params': {'spectral_radius': 0.65, 'input_scale': 1.0, 'ridge_alpha': 1e-08, 'leaking_rate': 0.7}, 'mean_NRMSEs': {'200': 1.8757846779964001e-06, '400': 5.8036551437026626e-06, '600': 5.062533830553411e-06, '800': 4.602376912001431e-06, '1000': 6.9545669784148544e-06}, 'std_NRMSEs': {'200': 5.815594486053856e-07, '400': 1.1540703042502002e-05, '600': 9.414341924016517e-06, '800': 8.276268295818171e-06, '1000': 9.909584992464827e-06}}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search class:  67%|██████▋   | 4/6 [08:21<02:55, 87.79s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'dataset': 'chen', 'model': 'CRJ3D', 'params': {'spectral_radius': 0.92, 'jump': 5, 'input_scale': 1.0, 'ridge_alpha': 1e-07, 'leaking_rate': 0.9}, 'mean_NRMSEs': {'200': 5.02658621752544e-06, '400': 1.2571338120983854e-05, '600': 1.1118422998949625e-05, '800': 1.016994781297796e-05, '1000': 1.4726695437165582e-05}, 'std_NRMSEs': {'200': 1.6273887359735362e-06, '400': 2.221237827251052e-05, '600': 1.80535247350817e-05, '800': 1.584151274093816e-05, '1000': 1.887605276501034e-05}}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search class:  83%|████████▎ | 5/6 [08:51<01:06, 67.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'dataset': 'chen', 'model': 'SparseESN3D', 'params': {'spectral_radius': 0.92, 'connectivity': 0.2, 'input_scale': 1.0, 'ridge_alpha': 1e-07, 'leaking_rate': 0.9}, 'mean_NRMSEs': {'200': 5.668767261305453e-06, '400': 1.8035317968077137e-05, '600': 1.5657040783587024e-05, '800': 1.4249950724348735e-05, '1000': 2.161262073877113e-05}, 'std_NRMSEs': {'200': 1.9792301823936163e-06, '400': 3.5764634571305996e-05, '600': 2.920338320802714e-05, '800': 2.5669842931039724e-05, '1000': 3.070015466994653e-05}}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search class: 100%|██████████| 6/6 [09:39<00:00, 96.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'dataset': 'chen', 'model': 'HFRRes3D', 'params': {'cells_per_level': [5, 10, 60, 225], 'spectral_radius': 0.92, 'input_scale': 1, 'leaking_rate': 0.9, 'ridge_alpha': 1e-08}, 'mean_NRMSEs': {'200': 1.565459634568357e-06, '400': 5.293225713077626e-06, '600': 4.5897774825907885e-06, '800': 4.175604554272621e-06, '1000': 6.002801459686266e-06}, 'std_NRMSEs': {'200': 5.660437305744331e-07, '400': 1.0726242435387287e-05, '600': 8.76085886499342e-06, '800': 7.701960810538498e-06, '1000': 8.48190045529461e-06}}]\n",
      "\n",
      "All results saved to `results.json`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Suppose these are your function and class lists\n",
    "functions = [generate_rossler_data, generate_lorenz_data, generate_chen_data]\n",
    "classes = [ DeepESN3D,MCI3D, CR3D, CRJ3D, SparseESN3D, HFRRes3D]\n",
    "\n",
    "# You can use dictionaries to specify 'a' for each function and 'b' for each class\n",
    "fracs ={\n",
    "    generate_lorenz_data: [0.7,0.75,0.8],\n",
    "    generate_rossler_data: [0.3,0.35,0.4],\n",
    "    generate_chen_data: [0.7,0.75,0.8]\n",
    "}\n",
    "\n",
    "# Combine all results into one dictionary\n",
    "combined_result = []\n",
    "\n",
    "for func in functions:\n",
    "    for cls in tqdm(classes, desc=\"Grid Search class\"):\n",
    "        result = run_grid_search(func, cls, grid[func][cls], \"mci\",fracs[func])\n",
    "        combined_result.append(result)  # merges all dictionaries\n",
    "\n",
    "# Now `combined_result` contains everything\n",
    "output_path=\"results.json\"\n",
    "with open(output_path, \"w\") as f:\n",
    "    json.dump(combined_result, f, indent=2)\n",
    "print(f\"\\nAll results saved to `{output_path}`\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T19:26:51.008380Z",
     "iopub.status.busy": "2025-06-07T19:26:51.008086Z",
     "iopub.status.idle": "2025-06-07T19:26:51.023353Z",
     "shell.execute_reply": "2025-06-07T19:26:51.022211Z",
     "shell.execute_reply.started": "2025-06-07T19:26:51.008359Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'dataset': 'rossler',\n",
       "   'model': 'DeepESN3D',\n",
       "   'params': {'spectral_radius': 0.88,\n",
       "    'connectivity': 0.001,\n",
       "    'input_scale': 0.4,\n",
       "    'ridge_alpha': 1e-07,\n",
       "    'leaking_rate': 0.5},\n",
       "   'mean_NRMSEs': {'200': 1.3939054535449893e-05,\n",
       "    '400': 2.1023997965808694e-05,\n",
       "    '600': 6.414302000461885e-05,\n",
       "    '800': 6.725186643245913e-05,\n",
       "    '1000': 6.295839945185456e-05},\n",
       "   'std_NRMSEs': {'200': 1.4791827417299545e-05,\n",
       "    '400': 2.907114838085992e-05,\n",
       "    '600': 0.00013557662739626942,\n",
       "    '800': 0.0001294791596085803,\n",
       "    '1000': 0.00012103950059932257}}],\n",
       " [{'dataset': 'rossler',\n",
       "   'model': 'MCI3D',\n",
       "   'params': {'cycle_weight': 0.8,\n",
       "    'connect_weight': 1,\n",
       "    'input_scale': 0.7,\n",
       "    'leaking_rate': 0.9,\n",
       "    'combine_factor': 0.8,\n",
       "    'ridge_alpha': 1e-07},\n",
       "   'mean_NRMSEs': {'200': 4.5515294118464235e-06,\n",
       "    '400': 1.115541882879383e-05,\n",
       "    '600': 5.226558217505906e-05,\n",
       "    '800': 5.414477779545703e-05,\n",
       "    '1000': 5.0971154912126235e-05},\n",
       "   'std_NRMSEs': {'200': 4.949412055871319e-06,\n",
       "    '400': 1.7738153701609998e-05,\n",
       "    '600': 0.00012025545878571151,\n",
       "    '800': 0.0001145264744326394,\n",
       "    '1000': 0.000107005196505032}}],\n",
       " [{'dataset': 'rossler',\n",
       "   'model': 'CR3D',\n",
       "   'params': {'spectral_radius': 0.85,\n",
       "    'input_scale': 1.0,\n",
       "    'ridge_alpha': 1e-08,\n",
       "    'leaking_rate': 0.05},\n",
       "   'mean_NRMSEs': {'200': 0.00024058605812449615,\n",
       "    '400': 0.0002645674813399867,\n",
       "    '600': 0.0003112973727871301,\n",
       "    '800': 0.00029179748792673786,\n",
       "    '1000': 0.0003118167012444516},\n",
       "   'std_NRMSEs': {'200': 0.0004837465587795319,\n",
       "    '400': 0.0004697212308467063,\n",
       "    '600': 0.00041153055698618993,\n",
       "    '800': 0.0003606390667685025,\n",
       "    '1000': 0.000411155494064371}}],\n",
       " [{'dataset': 'rossler',\n",
       "   'model': 'CRJ3D',\n",
       "   'params': {'spectral_radius': 0.92,\n",
       "    'jump': 10,\n",
       "    'input_scale': 0.6,\n",
       "    'ridge_alpha': 1e-07,\n",
       "    'leaking_rate': 0.9},\n",
       "   'mean_NRMSEs': {'200': 5.857901340586898e-06,\n",
       "    '400': 8.734033189101012e-06,\n",
       "    '600': 2.7959389089878936e-05,\n",
       "    '800': 2.8455739094670066e-05,\n",
       "    '1000': 2.6662696648585417e-05},\n",
       "   'std_NRMSEs': {'200': 5.616453713134303e-06,\n",
       "    '400': 1.0803553185898816e-05,\n",
       "    '600': 5.8651405172099245e-05,\n",
       "    '800': 5.606008204593169e-05,\n",
       "    '1000': 5.242560746264099e-05}}],\n",
       " [{'dataset': 'rossler',\n",
       "   'model': 'SparseESN3D',\n",
       "   'params': {'spectral_radius': 0.92,\n",
       "    'connectivity': 0.3,\n",
       "    'input_scale': 0.5,\n",
       "    'ridge_alpha': 1e-07,\n",
       "    'leaking_rate': 0.9},\n",
       "   'mean_NRMSEs': {'200': 5.14048549788965e-06,\n",
       "    '400': 8.323572425693124e-06,\n",
       "    '600': 2.933010925845956e-05,\n",
       "    '800': 3.003865251243186e-05,\n",
       "    '1000': 2.8122474482086253e-05},\n",
       "   'std_NRMSEs': {'200': 4.010572407480985e-06,\n",
       "    '400': 1.0724834520048001e-05,\n",
       "    '600': 6.849854600720692e-05,\n",
       "    '800': 6.544135272021859e-05,\n",
       "    '1000': 6.121329770782816e-05}}],\n",
       " [{'dataset': 'rossler',\n",
       "   'model': 'HFRRes3D',\n",
       "   'params': {'cells_per_level': [5, 35, 105, 155],\n",
       "    'spectral_radius': 0.92,\n",
       "    'input_scale': 0.3,\n",
       "    'leaking_rate': 0.8,\n",
       "    'ridge_alpha': 1e-08},\n",
       "   'mean_NRMSEs': {'200': 5.553419095877834e-06,\n",
       "    '400': 7.861558646553292e-06,\n",
       "    '600': 2.105251194651262e-05,\n",
       "    '800': 2.1717780924341857e-05,\n",
       "    '1000': 2.03765098807574e-05},\n",
       "   'std_NRMSEs': {'200': 6.598306015410157e-06,\n",
       "    '400': 9.395735241601716e-06,\n",
       "    '600': 4.175656821703861e-05,\n",
       "    '800': 3.9874393927300235e-05,\n",
       "    '1000': 3.73187474641881e-05}}],\n",
       " [{'dataset': 'lorenz',\n",
       "   'model': 'DeepESN3D',\n",
       "   'params': {'spectral_radius': 0.92,\n",
       "    'connectivity': 0.01,\n",
       "    'input_scale': 0.6,\n",
       "    'ridge_alpha': 1e-07,\n",
       "    'leaking_rate': 0.5},\n",
       "   'mean_NRMSEs': {'200': 2.963672659242853e-06,\n",
       "    '400': 2.7102273945674023e-06,\n",
       "    '600': 3.044986834666208e-06,\n",
       "    '800': 4.138491374409624e-06,\n",
       "    '1000': 4.329609198520695e-06},\n",
       "   'std_NRMSEs': {'200': 7.394072137875332e-07,\n",
       "    '400': 5.811266182847053e-07,\n",
       "    '600': 1.6638581027789164e-06,\n",
       "    '800': 5.991691959066826e-06,\n",
       "    '1000': 5.607687260770061e-06}}],\n",
       " [{'dataset': 'lorenz',\n",
       "   'model': 'MCI3D',\n",
       "   'params': {'cycle_weight': 0.8,\n",
       "    'connect_weight': 0.6,\n",
       "    'input_scale': 0.7,\n",
       "    'leaking_rate': 0.9,\n",
       "    'combine_factor': 0.2,\n",
       "    'ridge_alpha': 1e-07},\n",
       "   'mean_NRMSEs': {'200': 5.885546831183074e-07,\n",
       "    '400': 5.514558305882226e-07,\n",
       "    '600': 5.531620676476583e-07,\n",
       "    '800': 5.688490925415523e-07,\n",
       "    '1000': 5.776327538695476e-07},\n",
       "   'std_NRMSEs': {'200': 1.3134327583697039e-07,\n",
       "    '400': 1.1715810081932573e-07,\n",
       "    '600': 1.0456284961343161e-07,\n",
       "    '800': 1.1264062671632396e-07,\n",
       "    '1000': 1.1405013176659152e-07}}],\n",
       " [{'dataset': 'lorenz',\n",
       "   'model': 'CR3D',\n",
       "   'params': {'spectral_radius': 0.92,\n",
       "    'input_scale': 1.0,\n",
       "    'ridge_alpha': 1e-08,\n",
       "    'leaking_rate': 0.6},\n",
       "   'mean_NRMSEs': {'200': 5.642197329175448e-07,\n",
       "    '400': 5.126801724410421e-07,\n",
       "    '600': 5.588242916622169e-07,\n",
       "    '800': 6.304621880986062e-07,\n",
       "    '1000': 6.856444739747566e-07},\n",
       "   'std_NRMSEs': {'200': 1.6390745983835812e-07,\n",
       "    '400': 1.0643896760748682e-07,\n",
       "    '600': 1.9979346892188922e-07,\n",
       "    '800': 4.160024077053741e-07,\n",
       "    '1000': 4.593429014569352e-07}}],\n",
       " [{'dataset': 'lorenz',\n",
       "   'model': 'CRJ3D',\n",
       "   'params': {'spectral_radius': 0.98,\n",
       "    'jump': 15,\n",
       "    'input_scale': 1.0,\n",
       "    'ridge_alpha': 1e-07,\n",
       "    'leaking_rate': 0.7},\n",
       "   'mean_NRMSEs': {'200': 1.584391584305436e-06,\n",
       "    '400': 1.4586764284030212e-06,\n",
       "    '600': 1.4762878553997032e-06,\n",
       "    '800': 1.5487697605568086e-06,\n",
       "    '1000': 1.5609036466187957e-06},\n",
       "   'std_NRMSEs': {'200': 4.0646591507765023e-07,\n",
       "    '400': 2.8681994326913914e-07,\n",
       "    '600': 2.9068175354350135e-07,\n",
       "    '800': 3.749369707461538e-07,\n",
       "    '1000': 3.5483058660940745e-07}}],\n",
       " [{'dataset': 'lorenz',\n",
       "   'model': 'SparseESN3D',\n",
       "   'params': {'spectral_radius': 0.98,\n",
       "    'connectivity': 0.05,\n",
       "    'input_scale': 1.0,\n",
       "    'ridge_alpha': 1e-07,\n",
       "    'leaking_rate': 0.9},\n",
       "   'mean_NRMSEs': {'200': 1.3082136704972425e-06,\n",
       "    '400': 1.2172570808844313e-06,\n",
       "    '600': 1.2089596204118861e-06,\n",
       "    '800': 1.2364537922031852e-06,\n",
       "    '1000': 1.2467556767633794e-06},\n",
       "   'std_NRMSEs': {'200': 2.3647849455067346e-07,\n",
       "    '400': 1.915489212431979e-07,\n",
       "    '600': 1.7302767113766803e-07,\n",
       "    '800': 1.7856184744066308e-07,\n",
       "    '1000': 1.7967533879036147e-07}}],\n",
       " [{'dataset': 'lorenz',\n",
       "   'model': 'HFRRes3D',\n",
       "   'params': {'cells_per_level': [5, 10, 15, 20, 25, 35, 45, 50, 95],\n",
       "    'spectral_radius': 0.92,\n",
       "    'input_scale': 1,\n",
       "    'leaking_rate': 0.9,\n",
       "    'ridge_alpha': 1e-08},\n",
       "   'mean_NRMSEs': {'200': 5.984864144204063e-07,\n",
       "    '400': 5.524417468895569e-07,\n",
       "    '600': 5.611077349086822e-07,\n",
       "    '800': 5.974385192106466e-07,\n",
       "    '1000': 6.029750915255971e-07},\n",
       "   'std_NRMSEs': {'200': 1.312887882249226e-07,\n",
       "    '400': 1.0358961399786052e-07,\n",
       "    '600': 1.1424024644842606e-07,\n",
       "    '800': 1.9439894113509418e-07,\n",
       "    '1000': 1.8370901814908683e-07}}],\n",
       " [{'dataset': 'chen',\n",
       "   'model': 'DeepESN3D',\n",
       "   'params': {'spectral_radius': 0.85,\n",
       "    'connectivity': 0.001,\n",
       "    'input_scale': 0.6,\n",
       "    'ridge_alpha': 1e-07,\n",
       "    'leaking_rate': 0.9},\n",
       "   'mean_NRMSEs': {'200': 6.030059021100808e-06,\n",
       "    '400': 2.568903252865403e-05,\n",
       "    '600': 2.2089010497087996e-05,\n",
       "    '800': 1.997287750101234e-05,\n",
       "    '1000': 3.158975092086715e-05},\n",
       "   'std_NRMSEs': {'200': 2.3830916839051306e-06,\n",
       "    '400': 5.867859357720859e-05,\n",
       "    '600': 4.804579150842202e-05,\n",
       "    '800': 4.231104679765771e-05,\n",
       "    '1000': 5.1085157652851924e-05}}],\n",
       " [{'dataset': 'chen',\n",
       "   'model': 'MCI3D',\n",
       "   'params': {'cycle_weight': 0.4,\n",
       "    'connect_weight': 0.6,\n",
       "    'input_scale': 0.7,\n",
       "    'leaking_rate': 0.9,\n",
       "    'combine_factor': 0.6,\n",
       "    'ridge_alpha': 1e-07},\n",
       "   'mean_NRMSEs': {'200': 1.7910870609843126e-06,\n",
       "    '400': 3.773943453044265e-06,\n",
       "    '600': 3.3833339674890823e-06,\n",
       "    '800': 3.1481653720872642e-06,\n",
       "    '1000': 4.271590538344777e-06},\n",
       "   'std_NRMSEs': {'200': 3.2992961318103155e-07,\n",
       "    '400': 5.572729509875678e-06,\n",
       "    '600': 4.508561273908034e-06,\n",
       "    '800': 3.935220802580664e-06,\n",
       "    '1000': 4.684028803932206e-06}}],\n",
       " [{'dataset': 'chen',\n",
       "   'model': 'CR3D',\n",
       "   'params': {'spectral_radius': 0.65,\n",
       "    'input_scale': 1.0,\n",
       "    'ridge_alpha': 1e-08,\n",
       "    'leaking_rate': 0.7},\n",
       "   'mean_NRMSEs': {'200': 1.8757846779964001e-06,\n",
       "    '400': 5.8036551437026626e-06,\n",
       "    '600': 5.062533830553411e-06,\n",
       "    '800': 4.602376912001431e-06,\n",
       "    '1000': 6.9545669784148544e-06},\n",
       "   'std_NRMSEs': {'200': 5.815594486053856e-07,\n",
       "    '400': 1.1540703042502002e-05,\n",
       "    '600': 9.414341924016517e-06,\n",
       "    '800': 8.276268295818171e-06,\n",
       "    '1000': 9.909584992464827e-06}}],\n",
       " [{'dataset': 'chen',\n",
       "   'model': 'CRJ3D',\n",
       "   'params': {'spectral_radius': 0.92,\n",
       "    'jump': 5,\n",
       "    'input_scale': 1.0,\n",
       "    'ridge_alpha': 1e-07,\n",
       "    'leaking_rate': 0.9},\n",
       "   'mean_NRMSEs': {'200': 5.02658621752544e-06,\n",
       "    '400': 1.2571338120983854e-05,\n",
       "    '600': 1.1118422998949625e-05,\n",
       "    '800': 1.016994781297796e-05,\n",
       "    '1000': 1.4726695437165582e-05},\n",
       "   'std_NRMSEs': {'200': 1.6273887359735362e-06,\n",
       "    '400': 2.221237827251052e-05,\n",
       "    '600': 1.80535247350817e-05,\n",
       "    '800': 1.584151274093816e-05,\n",
       "    '1000': 1.887605276501034e-05}}],\n",
       " [{'dataset': 'chen',\n",
       "   'model': 'SparseESN3D',\n",
       "   'params': {'spectral_radius': 0.92,\n",
       "    'connectivity': 0.2,\n",
       "    'input_scale': 1.0,\n",
       "    'ridge_alpha': 1e-07,\n",
       "    'leaking_rate': 0.9},\n",
       "   'mean_NRMSEs': {'200': 5.668767261305453e-06,\n",
       "    '400': 1.8035317968077137e-05,\n",
       "    '600': 1.5657040783587024e-05,\n",
       "    '800': 1.4249950724348735e-05,\n",
       "    '1000': 2.161262073877113e-05},\n",
       "   'std_NRMSEs': {'200': 1.9792301823936163e-06,\n",
       "    '400': 3.5764634571305996e-05,\n",
       "    '600': 2.920338320802714e-05,\n",
       "    '800': 2.5669842931039724e-05,\n",
       "    '1000': 3.070015466994653e-05}}],\n",
       " [{'dataset': 'chen',\n",
       "   'model': 'HFRRes3D',\n",
       "   'params': {'cells_per_level': [5, 10, 60, 225],\n",
       "    'spectral_radius': 0.92,\n",
       "    'input_scale': 1,\n",
       "    'leaking_rate': 0.9,\n",
       "    'ridge_alpha': 1e-08},\n",
       "   'mean_NRMSEs': {'200': 1.565459634568357e-06,\n",
       "    '400': 5.293225713077626e-06,\n",
       "    '600': 4.5897774825907885e-06,\n",
       "    '800': 4.175604554272621e-06,\n",
       "    '1000': 6.002801459686266e-06},\n",
       "   'std_NRMSEs': {'200': 5.660437305744331e-07,\n",
       "    '400': 1.0726242435387287e-05,\n",
       "    '600': 8.76085886499342e-06,\n",
       "    '800': 7.701960810538498e-06,\n",
       "    '1000': 8.48190045529461e-06}}]]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
