{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2a722d1",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e605f985",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.integrate import odeint\n",
    "from sklearn.linear_model import Ridge\n",
    "from matplotlib.colors import Normalize\n",
    "import networkx as nx\n",
    "from scipy.signal import welch\n",
    "import matplotlib.cm as cm\n",
    "import seaborn as sns\n",
    "from collections import defaultdict\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba69c65",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4984ec68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_spectral_radius(W, target_radius=0.95):\n",
    "    eigvals = np.linalg.eigvals(W)\n",
    "    radius = np.max(np.abs(eigvals))\n",
    "    if radius == 0:\n",
    "        return W\n",
    "    return (W / radius) * target_radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a8929f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperbolic_distance_poincare(u, v):\n",
    "    \"\"\"\n",
    "    Compute the hyperbolic distance d(u, v) in the Poincaré disk model (2D).\n",
    "    Both u, v in R^2 with ||u|| < 1, ||v|| < 1.\n",
    "    Formula: \n",
    "      d(u,v) = arcosh(1 + 2 * ||u - v||^2 / ((1 - ||u||^2)*(1 - ||v||^2)))\n",
    "    If either point is near radius=1, numerical instability might occur. \n",
    "    \"\"\"\n",
    "\n",
    "    norm_u_squared = np.dot(u, u)\n",
    "    norm_v_squared = np.dot(v, v)\n",
    "    \n",
    "    # clamp to avoid negative denominators if norms ~1\n",
    "    eps = 1e-14\n",
    "    one_minus_u = max(eps, 1.0 - norm_u_squared)\n",
    "    one_minus_v = max(eps, 1.0 - norm_v_squared)\n",
    "    \n",
    "    diff = u - v\n",
    "    diff_squared = np.dot(diff, diff)  # Euclidean squared\n",
    "    \n",
    "    arg = 1.0 + 2.0 * diff_squared / (one_minus_u * one_minus_v)\n",
    "    if arg < 1.0:\n",
    "        arg = 1.0\n",
    "    return np.arccosh(arg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8eb161f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_poincare_geodesic(p, q, ax, n_points=200, **kw):\n",
    "    \"\"\"\n",
    "    Plot a geodesic between two points p and q on the Poincaré disk.\n",
    "    \n",
    "    Parameters:\n",
    "    - p, q: np.array of shape (2,), points in the Poincaré disk\n",
    "    - ax: matplotlib axis to plot on\n",
    "    - n_points: number of points to use for the geodesic arc\n",
    "    - **kw: keyword arguments passed to ax.plot\n",
    "    \n",
    "    Returns:\n",
    "    - None, plots the geodesic on the given axis\n",
    "    \"\"\"\n",
    "    \n",
    "    # Ensure points are within the disk\n",
    "    p_norm = np.linalg.norm(p)\n",
    "    q_norm = np.linalg.norm(q)\n",
    "    if p_norm >= 1.0 or q_norm >= 1.0:\n",
    "        raise ValueError(\"Points must be within the unit disk\")\n",
    "    \n",
    "    # Check if points are on a diameter (geodesic is a straight line)\n",
    "    if np.isclose(np.linalg.norm(np.cross(np.append(p, 0), np.append(q, 0))), 0):\n",
    "        ax.plot([p[0], q[0]], [p[1], q[1]], **kw)\n",
    "        return\n",
    "    \n",
    "    # For non-diametric geodesics, we need to find the circle\n",
    "    # orthogonal to the unit circle and passing through p and q\n",
    "    \n",
    "    # Möbius transformation approach\n",
    "    x1, y1 = p\n",
    "    x2, y2 = q\n",
    "    \n",
    "    # Calculate circle parameters\n",
    "    # We're looking for a circle that is orthogonal to the unit circle\n",
    "    # and passes through p and q\n",
    "    \n",
    "    # This is a circle with center c and radius r such that:\n",
    "    # |c|^2 - r^2 = 1 (orthogonality condition)\n",
    "    # |p - c|^2 = r^2 and |q - c|^2 = r^2 (p and q are on the circle)\n",
    "    \n",
    "    # Set up the linear system for finding the center\n",
    "    A = np.array([\n",
    "        [2*(x2 - x1), 2*(y2 - y1)],\n",
    "        [2*x1, 2*y1]\n",
    "    ])\n",
    "    \n",
    "    b = np.array([\n",
    "        x2**2 + y2**2 - x1**2 - y1**2,\n",
    "        1 + x1**2 + y1**2\n",
    "    ])\n",
    "    \n",
    "    # Solve for the center c\n",
    "    try:\n",
    "        c = np.linalg.solve(A, b)\n",
    "    except np.linalg.LinAlgError:\n",
    "        # If the system is singular, the points are on a straight line through the origin\n",
    "        ax.plot([p[0], q[0]], [p[1], q[1]], **kw)\n",
    "        return\n",
    "    \n",
    "    # Calculate radius\n",
    "    r = np.sqrt(np.sum((p - c)**2))\n",
    "    \n",
    "    # Determine the angles for the arc\n",
    "    theta1 = np.arctan2(p[1] - c[1], p[0] - c[0])\n",
    "    theta2 = np.arctan2(q[1] - c[1], q[0] - c[0])\n",
    "    \n",
    "    # Ensure we take the shortest path (the arc that stays within the disk)\n",
    "    # The key insight: we want the arc that stays inside the unit disk\n",
    "    delta_theta = (theta2 - theta1) % (2 * np.pi)\n",
    "    if delta_theta > np.pi:\n",
    "        delta_theta = delta_theta - 2 * np.pi\n",
    "    \n",
    "    # If the center is far away, we might need to reverse the direction\n",
    "    # to ensure we stay inside the unit disk\n",
    "    mid_theta = theta1 + delta_theta/2\n",
    "    mid_point = c + r * np.array([np.cos(mid_theta), np.sin(mid_theta)])\n",
    "    if np.linalg.norm(mid_point) > 1:\n",
    "        delta_theta = -delta_theta\n",
    "    \n",
    "    # Generate points along the arc\n",
    "    thetas = np.linspace(theta1, theta1 + delta_theta, n_points)\n",
    "    arc_points = c.reshape(2, 1) + r * np.vstack([np.cos(thetas), np.sin(thetas)])\n",
    "    \n",
    "    # Filter points to ensure they're within the unit disk\n",
    "    mask = (arc_points[0]**2 + arc_points[1]**2) < 1 - 1e-10\n",
    "    \n",
    "    # Plot the geodesic arc\n",
    "    ax.plot(arc_points[0, mask], arc_points[1, mask], **kw)\n",
    "    \n",
    "    return arc_points[:, mask]\n",
    "\n",
    "\n",
    "def draw_hyperbolic_reservoir(positions, W, save_path=\"Figures/hyperbolic_reservoir.png\"):\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    ax.set_xlim(-1, 1)\n",
    "    ax.set_ylim(-1, 1)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_aspect('equal')\n",
    "    ax.set_frame_on(False)\n",
    "    ax.add_patch(plt.Circle((0, 0), 1, color='black', fill=False, linestyle='dashed'))\n",
    "\n",
    "    radial_distances = np.linalg.norm(positions, axis=1)\n",
    "    norm = Normalize(vmin=0, vmax=np.max(radial_distances))\n",
    "    cmap = plt.get_cmap(\"twilight_r\")\n",
    "\n",
    "    G = nx.Graph()\n",
    "    N = len(positions)\n",
    "    for i in range(N):\n",
    "        G.add_node(i, pos=positions[i])\n",
    "    \n",
    "    \n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            if W[i, j] > 0:\n",
    "                # Use _plot_geodesic to draw hyperbolic geodesic path\n",
    "                p = positions[i]\n",
    "                q = positions[j]\n",
    "                plot_poincare_geodesic(p, q, ax, color=(0, 49/255, 83/255, min(W[i, j]*300.0, 1.0)))\n",
    "\n",
    "    for i in range(N):\n",
    "        ax.scatter(positions[i, 0], positions[i, 1], color=cmap(0.97), s=50, edgecolors='k', linewidth=0.5, zorder=2)\n",
    "\n",
    "    # sm = ScalarMappable(cmap=cmap, norm=norm)\n",
    "    # sm.set_array([])\n",
    "    # cbar = plt.colorbar(sm, ax=ax, fraction=0.046, pad=0.04)\n",
    "    # cbar.set_label(\"Radial Distance\")\n",
    "    \n",
    "    plt.savefig(save_path, dpi=600, bbox_inches='tight')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67175bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pca_projection3d(states):\n",
    "    # Apply PCA for 3D visualization\n",
    "    pca = PCA(n_components=3)\n",
    "    proj = pca.fit_transform(states)\n",
    "\n",
    "    sns.set_theme(style=\"white\")\n",
    "    fig = plt.figure(figsize=(12, 9))  # Increased width for padding\n",
    "    ax = plt.axes(projection='3d')\n",
    "\n",
    "    # Scatter plot\n",
    "    p = ax.scatter(proj[:, 0], proj[:, 1], proj[:, 2], \n",
    "                   c=np.arange(len(proj)), cmap='viridis', s=2.5)\n",
    "\n",
    "    # Axis labels with padding\n",
    "    ax.set_xlabel(\"PC1\")\n",
    "    ax.set_ylabel(\"PC2\")\n",
    "    ax.set_zlabel(\"PC3\")\n",
    "\n",
    "    cbar = fig.colorbar(p, ax=ax, shrink=0.6, pad=0.1)\n",
    "    cbar.set_label(\"Index progression\")\n",
    "    \n",
    "    plt.savefig('Figures/PCA_projection_2d_rossler_hyper.png', dpi=600)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b897f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pca_projection2d(states):\n",
    "    # Apply PCA for 3D visualization\n",
    "    pca = PCA(n_components=2)\n",
    "    proj = pca.fit_transform(states)\n",
    "\n",
    "    sns.set_theme(style=\"white\")\n",
    "    fig = plt.figure(figsize=(10, 7))\n",
    "    ax = fig.add_subplot(111)\n",
    "    p = ax.scatter(proj[:, 0], proj[:, 1], c=np.arange(len(proj)), cmap='plasma', s=2.5)\n",
    "\n",
    "    ax.set_xlabel(\"PC1\")\n",
    "    ax.set_ylabel(\"PC2\")\n",
    "    plt.savefig('Figures/PCA_projection_3d_rossler_hyper.png', dpi=600)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c033d558",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.colors as colors\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "def visualize_sparsity(matrix1, matrix2):\n",
    "        combined = np.stack([matrix1, matrix2])\n",
    "        min_nonzero = np.min(combined[combined > 0])\n",
    "        small_value = min_nonzero / 1000\n",
    "        vmax = np.max(combined)\n",
    "        norm = colors.LogNorm(vmin=small_value, vmax=vmax)\n",
    "\n",
    "        # Setup figure and gridspec\n",
    "        fig = plt.figure(figsize=(20, 8))\n",
    "        gs = gridspec.GridSpec(1, 3, width_ratios=[1, 1, 0.05], wspace=0.05)\n",
    "\n",
    "        ax1 = plt.subplot(gs[0])\n",
    "        ax2 = plt.subplot(gs[1])\n",
    "        cbar_ax = plt.subplot(gs[2])  # This will span the full vertical height\n",
    "\n",
    "        # Plot first matrix\n",
    "        sns.heatmap(matrix1, cmap='twilight', ax=ax1, norm=norm, mask=(matrix1 == 0), cbar=False)\n",
    "        ax1.axis('off')\n",
    "\n",
    "        # Plot second matrix\n",
    "        sns.heatmap(matrix2, cmap='twilight', ax=ax2, norm=norm, mask=(matrix2 == 0),\n",
    "                        cbar=True, cbar_ax=cbar_ax)\n",
    "        ax2.axis('off')\n",
    "        plt.savefig('Figures/Sparsity Visualization.png', dpi=600)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9023f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_delay_embedding(signal, embed_dim):\n",
    "    L = len(signal) - embed_dim + 1\n",
    "    emb = np.zeros((L, embed_dim))\n",
    "    for i in range(L):\n",
    "        emb[i, :] = signal[i:i+embed_dim]\n",
    "    return emb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ac8933",
   "metadata": {},
   "source": [
    "# Baselines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a500e05",
   "metadata": {},
   "source": [
    "### Baseline ESN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b84b674e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaselineESN3D:\n",
    "    \"\"\"\n",
    "    A baseline Echo State Network that handles:\n",
    "        - 3D input (x,y,z)\n",
    "        - 3D output (x(t+1), y(t+1), z(t+1))\"\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 reservoir_size=400,\n",
    "                 spectral_radius=0.95,\n",
    "                 connectivity=0.1,\n",
    "                 input_scale=1.0,\n",
    "                 leaking_rate=0.8,\n",
    "                 ridge_alpha=1e-6,\n",
    "                 activation_choices=('tanh','relu','sin','linear'),\n",
    "                 seed=42):\n",
    "        self.reservoir_size = reservoir_size\n",
    "        self.spectral_radius = spectral_radius\n",
    "        self.connectivity = connectivity\n",
    "        self.input_scale = input_scale\n",
    "        self.leaking_rate = leaking_rate\n",
    "        self.ridge_alpha = ridge_alpha\n",
    "        self.activation_choices = activation_choices\n",
    "        self.seed = seed\n",
    "\n",
    "        np.random.seed(self.seed)\n",
    "        # Initialize W with small random values (mean=0, variance=0.01)\n",
    "        W = np.random.randn(reservoir_size, reservoir_size) * 0.1\n",
    "        # Create a boolean sparsity mask\n",
    "        mask = (np.random.rand(reservoir_size, reservoir_size) < self.connectivity)\n",
    "        W = W * mask\n",
    "        W = scale_spectral_radius(W, self.spectral_radius)\n",
    "        self.W = W\n",
    "\n",
    "        np.random.seed(self.seed + 100)\n",
    "        # Initialize input weights in range [-input_scale, input_scale]\n",
    "        self.W_in = (np.random.rand(self.reservoir_size, 3) - 0.5) * 2.0 * self.input_scale\n",
    "\n",
    "        np.random.seed(self.seed + 200)\n",
    "        self.node_activations = np.random.choice(self.activation_choices, size=self.reservoir_size)\n",
    "\n",
    "        # Readout: shape (3, reservoir_size+1) -> 3D output\n",
    "        self.W_out = None\n",
    "        self.reset_state()\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.x = np.zeros(self.reservoir_size)\n",
    "\n",
    "    def _apply_activation(self, act_type, val):\n",
    "        return np.tanh(val)\n",
    "        # if act_type=='tanh':\n",
    "        #     return np.tanh(val)\n",
    "        # elif act_type=='relu':\n",
    "        #     return max(0.0, val)\n",
    "        # elif act_type=='sin':\n",
    "        #     return np.sin(val)\n",
    "        # elif act_type=='linear':\n",
    "        #     return val\n",
    "        # else:\n",
    "        #     return np.tanh(val)\n",
    "\n",
    "    def _update(self, u):\n",
    "        \"\"\"\n",
    "        x(t+1) = (1-alpha)*x(t) + alpha*[ node-by-node activation( W*x(t)+W_in*u ) ]\n",
    "        \"\"\"\n",
    "        pre_activations = self.W @ self.x + self.W_in @ u\n",
    "        x_new = np.zeros_like(self.x)\n",
    "        for i in range(self.reservoir_size):\n",
    "            activation = self.node_activations[i]\n",
    "            x_new[i] = self._apply_activation(activation, pre_activations[i])\n",
    "        alpha = self.leaking_rate\n",
    "        self.x = (1.0 - alpha)*self.x + alpha*x_new\n",
    "        \n",
    "    def collect_states(self, inputs, discard=100):\n",
    "        \"\"\"\n",
    "        Run reservoir on 'inputs' (shape [T, 3]), discarding the first 'discard' steps.\n",
    "        Returns: states [T-discard, reservoir_size]\n",
    "        \"\"\"\n",
    "        self.reset_state()\n",
    "        states = []\n",
    "        for t in range(len(inputs)):\n",
    "            self._update(inputs[t])\n",
    "            states.append(self.x.copy())\n",
    "        states = np.array(states)\n",
    "        return states[discard:], states[:discard]\n",
    "    \n",
    "\n",
    "    def fit_readout(self, train_input, train_target, discard=100):\n",
    "        \"\"\"\n",
    "        Teacher forcing for single-step:\n",
    "            - input(t) = [x(t), y(t), z(t)]\n",
    "            - target(t) = [x(t+1), y(t+1), z(t+1)]\n",
    "        We collect states(t), then solve a multi-output linear ridge regression:\n",
    "            W_out * [x(t); 1] ~ target(t+1).\n",
    "        For quadratic readout:\n",
    "            W_out * [x(t); x²(t); 1] ~ target(t+1).\n",
    "        \"\"\"\n",
    "        states_use, _ = self.collect_states(train_input, discard=discard)\n",
    "        targets_use = train_target[discard:]  # shape [T-discard, 3]\n",
    "\n",
    "        # Augment states with bias\n",
    "        # X_aug = np.hstack([states_use, np.ones((states_use.shape[0], 1))])  # shape [T-discard, N+1]\n",
    "\n",
    "        # Quadratic readout\n",
    "        # Build augmented matrix [ x, x^2, 1 ]\n",
    "        X_list = []\n",
    "        for s in states_use:\n",
    "            X_list.append( np.concatenate([s, s**2, [1.0]]) )\n",
    "        X_aug = np.array(X_list)                                # shape [T-discard, 2N+1]\n",
    "\n",
    "        ridge_reg = Ridge(alpha=self.ridge_alpha, fit_intercept=False)\n",
    "        ridge_reg.fit(X_aug, targets_use)\n",
    "        self.W_out = ridge_reg.coef_\n",
    "\n",
    "    def predict(self, inputs):\n",
    "        \"\"\"\n",
    "        Single-step-ahead inference on test data:\n",
    "        For each inputs[t], we update reservoir, then read out 3D prediction.\n",
    "        \"\"\"\n",
    "        preds = []\n",
    "        for t in range(len(inputs)):\n",
    "            self._update(inputs[t])\n",
    "            # x_aug = np.concatenate([self.x, [1.0]])\n",
    "            x_aug = np.concatenate([self.x, (self.x)**2, [1.0]])  # For quadrartic readout\n",
    "            out = self.W_out @ x_aug\n",
    "            preds.append(out)\n",
    "        return np.array(preds)\n",
    "    \n",
    "    def autoregressive_predict(self, initial_input, num_steps):\n",
    "        \"\"\"\n",
    "        Autoregressive multi-step forecasting for num_steps\n",
    "        \"\"\"\n",
    "        preds = []\n",
    "        current_input = initial_input.copy()\n",
    "      \n",
    "        for _ in range(num_steps):\n",
    "            self._update(current_input)\n",
    "            # x_aug = np.concatenate([self.x, [1.0]])\n",
    "            x_aug = np.concatenate([self.x, (self.x)**2, [1.0]])  # For quadratic readout\n",
    "            out = self.W_out @ x_aug\n",
    "            preds.append(out)\n",
    "            current_input = out\n",
    "        \n",
    "        return np.array(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085ffac6",
   "metadata": {},
   "source": [
    "### SCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "36365c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CycleReservoir3D(BaselineESN3D):\n",
    "    \"\"\"\n",
    "    Cyclic Reservoir for 3D -> 3D Lorenz.\n",
    "    - reservoir_size, spectral_radius, input_scale, leaking_rate, ridge_alpha as in baseline\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 reservoir_size=400,\n",
    "                 spectral_radius=0.95,\n",
    "                 cycle_weight = 0.8,\n",
    "                 input_scale=1.0,\n",
    "                 leaking_rate=0.8,\n",
    "                 ridge_alpha=1e-6,\n",
    "                 activation_choices=('tanh','relu','sin','linear'),\n",
    "                 seed=42):\n",
    "        \n",
    "        self.reservoir_size = reservoir_size\n",
    "        self.spectral_radius = spectral_radius\n",
    "        self.cycle_weight = cycle_weight\n",
    "        self.input_scale = input_scale\n",
    "        self.leaking_rate = leaking_rate\n",
    "        self.ridge_alpha = ridge_alpha\n",
    "        self.activation_choices = activation_choices\n",
    "        self.seed = seed\n",
    "\n",
    "        np.random.seed(self.seed)\n",
    "        # Build cycle adjacency: W[i,(i+1)%N] = 1\n",
    "        W = np.zeros((reservoir_size, reservoir_size))\n",
    "        for i in range(reservoir_size):\n",
    "            j = (i+1) % reservoir_size\n",
    "            W[i, j] = cycle_weight\n",
    "\n",
    "        W = scale_spectral_radius(W, self.spectral_radius)\n",
    "        self.W = W\n",
    "\n",
    "        np.random.seed(self.seed + 100)\n",
    "        # Initialize input weights in range [-input_scale, input_scale]\n",
    "        self.W_in = (np.random.rand(self.reservoir_size, 3) - 0.5) * 2.0 * self.input_scale\n",
    "\n",
    "        np.random.seed(self.seed + 200)\n",
    "        self.node_activations = np.random.choice(self.activation_choices, size=self.reservoir_size)\n",
    "\n",
    "        # Readout: shape (3, reservoir_size+1) -> 3D output\n",
    "        self.W_out = None\n",
    "        self.reset_state()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b01cc9a",
   "metadata": {},
   "source": [
    "### CRJ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "deb13644",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CRJRes3D(BaselineESN3D):\n",
    "    def __init__(self,\n",
    "                 reservoir_size=300,\n",
    "                 edge_weight = 0.8,\n",
    "                 jump=10,\n",
    "                 spectral_radius=0.95,\n",
    "                 input_scale=1.0,\n",
    "                 leaking_rate=1.0,\n",
    "                 ridge_alpha=1e-6,\n",
    "                 activation_choices=('tanh','relu','sin','linear'),\n",
    "                 seed=42):\n",
    "        \n",
    "        self.reservoir_size = reservoir_size\n",
    "        self.edge_weight = edge_weight\n",
    "        self.jump = jump\n",
    "        self.spectral_radius = spectral_radius\n",
    "        self.input_scale = input_scale\n",
    "        self.leaking_rate = leaking_rate\n",
    "        self.ridge_alpha = ridge_alpha\n",
    "        self.activation_choices = activation_choices\n",
    "        self.seed = seed\n",
    "\n",
    "        np.random.seed(self.seed)\n",
    "        W = np.zeros((reservoir_size, reservoir_size))\n",
    "        for i in range(reservoir_size):\n",
    "            W[i, (i+1) % reservoir_size] = edge_weight              # Cycle edge\n",
    "            W[i, (i + self.jump) % reservoir_size] = edge_weight    # Jump edge\n",
    "\n",
    "        W = scale_spectral_radius(W, self.spectral_radius)\n",
    "        self.W = W\n",
    "\n",
    "        np.random.seed(self.seed+100)\n",
    "        self.W_in = (np.random.rand(self.reservoir_size, 3) - 0.5) * 2.0 * self.input_scale\n",
    "\n",
    "        np.random.seed(self.seed + 200)\n",
    "        self.node_activations = np.random.choice(self.activation_choices, size=self.reservoir_size)\n",
    "\n",
    "        # Readout: shape (3, reservoir_size+1) -> 3D output\n",
    "        self.W_out = None\n",
    "        self.reset_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e8a8e0",
   "metadata": {},
   "source": [
    "### Small-World Res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d8ea5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SWRes3D(BaselineESN3D):\n",
    "    \"\"\"\n",
    "    Small-World (SW) Reservoir for 3D->3D single-step prediction using the Watts-Strogatz (WS) method.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 reservoir_size=300,\n",
    "                 rewiring_prob=0.1,\n",
    "                 degree=6,\n",
    "                 spectral_radius=0.95,\n",
    "                 input_scale=1.0,\n",
    "                 leaking_rate=1.0,\n",
    "                 ridge_alpha=1e-6,\n",
    "                 activation_choices=('tanh','relu','sin','linear'),\n",
    "                 seed=42):\n",
    "\n",
    "        self.reservoir_size = reservoir_size\n",
    "        self.spectral_radius = spectral_radius\n",
    "        self.rewiring_prob = rewiring_prob\n",
    "        self.degree = degree\n",
    "        self.input_scale = input_scale\n",
    "        self.leaking_rate = leaking_rate\n",
    "        self.ridge_alpha = ridge_alpha\n",
    "        self.activation_choices = activation_choices\n",
    "        self.seed = seed\n",
    "\n",
    "        np.random.seed(self.seed)\n",
    "        # Create a Watts-Strogatz small-world graph\n",
    "        ws_graph = nx.watts_strogatz_graph(n=reservoir_size, k=self.degree, p=self.rewiring_prob, seed=self.seed)\n",
    "        adjacency_matrix = nx.to_numpy_array(ws_graph)\n",
    "        \n",
    "        # Initialize reservoir weights\n",
    "        W = adjacency_matrix * np.random.uniform(-1, 1, (reservoir_size, reservoir_size))\n",
    "        W = scale_spectral_radius(W, spectral_radius)\n",
    "        self.W = W\n",
    "\n",
    "        np.random.seed(self.seed+100)\n",
    "        self.W_in = (np.random.rand(reservoir_size, 3) - 0.5) * 2.0 * input_scale\n",
    "\n",
    "        np.random.seed(self.seed + 200)\n",
    "        self.node_activations = np.random.choice(self.activation_choices, size=self.reservoir_size)\n",
    "\n",
    "        self.W_out = None\n",
    "        self.reset_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82cfc0d",
   "metadata": {},
   "source": [
    "### MCI-ESN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5a28cfbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCIESN3D:\n",
    "    def __init__(self,\n",
    "                 reservoir_size=300,\n",
    "                 cycle_weight=0.8,\n",
    "                 connect_weight=0.8,\n",
    "                 combine_factor=0.5,\n",
    "                 v1=0.6,\n",
    "                 v2=0.6,\n",
    "                 spectral_radius=0.95,\n",
    "                 leaking_rate=1.0,\n",
    "                 ridge_alpha=1e-6,\n",
    "                 seed=42\n",
    "                 ):\n",
    "        self.reservoir_size = reservoir_size\n",
    "        self.cycle_weight = cycle_weight\n",
    "        self.connect_weight = connect_weight\n",
    "        self.combine_factor = combine_factor\n",
    "        self.v1 = v1\n",
    "        self.v2 = v2\n",
    "        self.spectral_radius = spectral_radius\n",
    "        self.leaking_rate = leaking_rate\n",
    "        self.ridge_alpha = ridge_alpha\n",
    "        self.seed = seed\n",
    "\n",
    "        np.random.seed(self.seed)\n",
    "        W_res = np.zeros((reservoir_size, reservoir_size))\n",
    "        for i in range(reservoir_size):\n",
    "            j = (i+1) % reservoir_size\n",
    "            W_res[j, i] = self.cycle_weight\n",
    "\n",
    "        W_res = scale_spectral_radius(W_res, spectral_radius)\n",
    "        self.W_res = W_res                      # shared by both sub-reservoirs\n",
    "\n",
    "        np.random.seed(self.seed + 100)\n",
    "        W_cn = np.zeros((reservoir_size, reservoir_size))\n",
    "        W_cn[0, reservoir_size-1] = self.connect_weight\n",
    "        W_cn[reservoir_size-1, 0] = self.connect_weight\n",
    "        self.W_cn = W_cn\n",
    "\n",
    "        np.random.seed(self.seed+200)\n",
    "\n",
    "        sign_V1 = np.random.choice([-1, 1], size=(reservoir_size, 3))\n",
    "        sign_V2 = np.random.choice([-1, 1], size=(reservoir_size, 3))\n",
    "\n",
    "        V1 = self.v1 * sign_V1\n",
    "        V2 = self.v2 * sign_V2\n",
    "\n",
    "        self.W_in1 = V1 - V2\n",
    "        self.W_in2 = V1 + V2\n",
    "        \n",
    "        self.W_out = None\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.x1 = np.zeros(self.reservoir_size)\n",
    "        self.x2 = np.zeros(self.reservoir_size)\n",
    "\n",
    "    def _update(self, u):\n",
    "        \"\"\"\n",
    "        Single-step reservoir update.\n",
    "        x1(t+1) = cos( Win1*u(t+1) + W_res*x1(t) + W_cn*x2(t) )\n",
    "        x2(t+1) = sin( Win2*u(t+1) + W_res*x2(t) + W_cn*x1(t) )\n",
    "        Then x(t+1)= h*x1(t+1) + (1-h)* x2(t+1).\n",
    "        \"\"\"\n",
    "        # pre activation for reservoir1\n",
    "        pre_activation1 = self.W_in1 @ u + self.W_res @ self.x1 + self.W_cn @ self.x2\n",
    "        # reservoir1 uses cos\n",
    "        x1_new = np.cos(pre_activation1)\n",
    "\n",
    "        # reservoir2 uses sin\n",
    "        pre_activation2 = self.W_in2 @ u + self.W_res @ self.x2 + self.W_cn @ self.x1\n",
    "        x2_new = np.sin(pre_activation2)\n",
    "\n",
    "        alpha = self.leaking_rate\n",
    "        self.x1 = (1.0 - alpha)*self.x1 + alpha*x1_new\n",
    "        self.x2 = (1.0 - alpha)*self.x2 + alpha*x2_new\n",
    "\n",
    "    def _combine_state(self):\n",
    "        \"\"\"\n",
    "        Combine x1(t), x2(t) => x(t) = h*x1(t) + (1-h)*x2(t)\n",
    "        \"\"\"\n",
    "        h = self.combine_factor\n",
    "        return h*self.x1 + (1.0 - h)*self.x2\n",
    "    \n",
    "    def collect_states(self, inputs, discard=100):\n",
    "        self.reset_state()\n",
    "        states = []\n",
    "        for t in range(len(inputs)):\n",
    "            self._update(inputs[t])\n",
    "            combined = self._combine_state()\n",
    "            states.append(combined.copy())\n",
    "        states = np.array(states)\n",
    "        return states[discard:], states[:discard]\n",
    "    \n",
    "    def fit_readout(self, train_input, train_target, discard=100):\n",
    "        states_use, _ = self.collect_states(train_input, discard=discard)\n",
    "        targets_use = train_target[discard:]\n",
    "\n",
    "        # Augment states with bias\n",
    "        # X_aug = np.hstack([states_use, np.ones((states_use.shape[0], 1))])  # shape [T-discard, N+1]\n",
    "\n",
    "        # Quadratic readout\n",
    "        # Build augmented matrix [ x, x^2, 1 ]\n",
    "        X_list = []\n",
    "        for s in states_use:\n",
    "            X_list.append( np.concatenate([s, s**2, [1.0]]) )\n",
    "        X_aug = np.array(X_list)                                # shape [T-discard, 2N+1]\n",
    "\n",
    "        ridge_reg = Ridge(alpha=self.ridge_alpha, fit_intercept=False)\n",
    "        ridge_reg.fit(X_aug, targets_use)\n",
    "        self.W_out = ridge_reg.coef_\n",
    "\n",
    "    def predict(self, inputs):\n",
    "        preds = []\n",
    "        for t in range(len(inputs)):\n",
    "            self._update(inputs[t])\n",
    "            combined = self._combine_state()\n",
    "            # x_aug = np.concatenate([self.x, [1.0]])\n",
    "            x_aug = np.concatenate([combined, combined**2, [1.0]])  # For quadrartic readout\n",
    "            out = self.W_out @ x_aug\n",
    "            preds.append(out)\n",
    "        return np.array(preds)\n",
    "    \n",
    "    def autoregressive_predict(self, initial_input, num_steps):\n",
    "        preds = []\n",
    "        current_input = initial_input.copy()\n",
    "      \n",
    "        for _ in range(num_steps):\n",
    "            self._update(current_input)\n",
    "            combined = self._combine_state()\n",
    "            # x_aug = np.concatenate([self.x, [1.0]])\n",
    "            x_aug = np.concatenate([combined, combined**2, [1.0]])  # For quadratic readout\n",
    "            out = self.W_out @ x_aug\n",
    "            preds.append(out)\n",
    "            current_input = out\n",
    "        \n",
    "        return np.array(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea2e53a",
   "metadata": {},
   "source": [
    "### DeepESN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3cc3e873",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepESN3D:\n",
    "    \"\"\"\n",
    "    Deep Echo State Network (DeepESN) for multi-layered reservoir computing.\n",
    "    Each layer has its own reservoir, and the states are propagated through layers.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 num_layers=3,\n",
    "                 reservoir_size=100,\n",
    "                 spectral_radius=0.95,\n",
    "                 connectivity=0.1,\n",
    "                 input_scale=1.0,\n",
    "                 leaking_rate=1.0,\n",
    "                 ridge_alpha=1e-6,\n",
    "                 activation_choices=('tanh','relu','sin','linear'),\n",
    "                 seed=42):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        - num_layers: Number of reservoir layers.\n",
    "        - reservoir_size: Number of neurons in each reservoir layer.\n",
    "        \"\"\"\n",
    "        self.num_layers = num_layers\n",
    "        self.reservoir_size = reservoir_size\n",
    "        self.spectral_radius = spectral_radius\n",
    "        self.connectivity = connectivity\n",
    "        self.input_scale = input_scale\n",
    "        self.leaking_rate = leaking_rate\n",
    "        self.ridge_alpha = ridge_alpha\n",
    "        self.activation_choices = activation_choices\n",
    "        self.seed = seed\n",
    "\n",
    "        # Initialize reservoirs and input weights for each layer\n",
    "        self.reservoirs = []\n",
    "        self.input_weights = []\n",
    "        self.states = []\n",
    "\n",
    "        np.random.seed(self.seed)\n",
    "        for layer in range(num_layers):\n",
    "            np.random.seed(seed + layer)\n",
    "            W = np.random.randn(reservoir_size, reservoir_size) * 0.1\n",
    "            mask = (np.random.rand(reservoir_size, reservoir_size) < self.connectivity)\n",
    "            W = W * mask\n",
    "            W = scale_spectral_radius(W, spectral_radius)\n",
    "            self.reservoirs.append(W)\n",
    "\n",
    "            if layer == 0 : \n",
    "                W_in = (np.random.rand(reservoir_size, 3) - 0.5) * 2.0 * input_scale\n",
    "            else:\n",
    "                W_in = (np.random.rand(reservoir_size, reservoir_size) - 0.5) * 2.0 * input_scale\n",
    "            self.input_weights.append(W_in)\n",
    "\n",
    "        np.random.seed(self.seed + 200)\n",
    "        self.node_activations = np.random.choice(self.activation_choices, size=self.reservoir_size)\n",
    "        \n",
    "        self.W_out = None\n",
    "        self.reset_state()\n",
    "\n",
    "    def reset_state(self):\n",
    "        \"\"\"\n",
    "        Reset the states of all reservoir layers.\n",
    "        \"\"\"\n",
    "        self.states = [np.zeros(self.reservoir_size) for _ in range(self.num_layers)]\n",
    "\n",
    "    def _apply_activation(self, act_type, val):\n",
    "        return np.tanh(val)\n",
    "        # if act_type=='tanh':\n",
    "        #     return np.tanh(val)\n",
    "        # elif act_type=='relu':\n",
    "        #     return max(0.0, val)\n",
    "        # elif act_type=='sin':\n",
    "        #     return np.sin(val)\n",
    "        # elif act_type=='linear':\n",
    "        #     return val\n",
    "        # else:\n",
    "        #     return np.tanh(val)\n",
    "\n",
    "    def _update_layer(self, layer_idx, u):\n",
    "        \"\"\"\n",
    "        Update a single reservoir layer.\n",
    "        \"\"\"\n",
    "        pre_activation = self.reservoirs[layer_idx] @ self.states[layer_idx]\n",
    "        if layer_idx == 0:\n",
    "            pre_activation += self.input_weights[layer_idx] @ u\n",
    "        else:\n",
    "            pre_activation += self.input_weights[layer_idx] @ self.states[layer_idx - 1]\n",
    "\n",
    "        x_new = np.zeros_like(pre_activation)\n",
    "        for i in range(self.reservoir_size):\n",
    "            activation = self.node_activations[i]\n",
    "            x_new[i] = self._apply_activation(activation, pre_activation[i])\n",
    "        alpha = self.leaking_rate\n",
    "        self.states[layer_idx] = (1.0 - alpha) * self.states[layer_idx] + alpha * x_new\n",
    "\n",
    "    def collect_states(self, inputs, discard=100):\n",
    "        self.reset_state()\n",
    "        all_states = []\n",
    "        for u in inputs:\n",
    "            for layer_idx in range(self.num_layers):\n",
    "                self._update_layer(layer_idx, u)\n",
    "            all_states.append(np.concatenate(self.states))\n",
    "        all_states = np.array(all_states)\n",
    "        return all_states[discard:], all_states[:discard]\n",
    "\n",
    "    def fit_readout(self, train_input, train_target, discard=100):\n",
    "        \"\"\"\n",
    "        Train the readout layer using ridge regression.\n",
    "        \"\"\"\n",
    "        states_use, _ = self.collect_states(train_input, discard=discard)\n",
    "        targets_use = train_target[discard:]\n",
    "\n",
    "        # Augment states with bias\n",
    "        # X_aug = np.hstack([states_use, np.ones((states_use.shape[0], 1))])  # shape [T-discard, N*L+1]\n",
    "\n",
    "        # Quadratic readout\n",
    "        # Build augmented matrix [ x, x^2, 1 ]\n",
    "        X_list = []\n",
    "        for s in states_use:\n",
    "            X_list.append( np.concatenate([s, s**2, [1.0]]) )\n",
    "        X_aug = np.array(X_list)                                    # shape [T-discard, 2N*L+1]\n",
    "\n",
    "        reg = Ridge(alpha=self.ridge_alpha, fit_intercept=False)\n",
    "        reg.fit(X_aug, targets_use)\n",
    "        self.W_out = reg.coef_\n",
    "\n",
    "    def predict(self, inputs):\n",
    "        \"\"\"\n",
    "        Single-step-ahead inference on test data.\n",
    "        \"\"\"\n",
    "        preds = []\n",
    "        for u in inputs:\n",
    "            for layer_idx in range(self.num_layers):\n",
    "                self._update_layer(layer_idx, u)\n",
    "            state = np.concatenate(self.states)\n",
    "            # x_aug = np.concatenate([state, [1.0]])\n",
    "            x_aug = np.concatenate([state, (state)**2, [1.0]])  # For quadrartic readout\n",
    "            out = self.W_out @ x_aug\n",
    "            preds.append(out)\n",
    "        return np.array(preds)\n",
    "\n",
    "    def autoregressive_predict(self, initial_input, num_steps):\n",
    "        \"\"\"\n",
    "        Autoregressive multi-step forecasting for num_steps\n",
    "        \"\"\"\n",
    "        preds = []\n",
    "        current_input = initial_input.copy()\n",
    "\n",
    "        for _ in range(num_steps):\n",
    "            for layer_idx in range(self.num_layers):\n",
    "                self._update_layer(layer_idx, current_input)\n",
    "            state = np.concatenate(self.states)\n",
    "            # x_aug = np.concatenate([state, [1.0]])\n",
    "            x_aug = np.concatenate([state, (state)**2, [1.0]])  # For quadrartic readout\n",
    "            out = self.W_out @ x_aug\n",
    "            preds.append(out)\n",
    "            current_input = out\n",
    "        \n",
    "        return np.array(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4741c6",
   "metadata": {},
   "source": [
    "# HypER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "817c595b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HypER3D(BaselineESN3D):\n",
    "    \"\"\"\n",
    "    Hyperbolic Embedding Reservoir (HER) for 3D->3D Lorenz,\n",
    "    using the Poincaré disc model:\n",
    "      1) Sample each node from the unit Poincaré disc. \n",
    "      2) Compute Hyperbolic Distance dist(u_i, u_j).\n",
    "      3) Adjacency W_ij = exp( - dist(u_i, u_j)/ sigma ), or 0 to enforce row-sparsity beyond top_k or fraction.\n",
    "      4) Scale spectral radius to optimum value.\n",
    "      5) Leaky ESN update with [x, x^2, 1] readout.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 reservoir_size=300,\n",
    "                 disk_radius=0.99,              # max radius inside the Poincaré disk (slightly < 1 to avoid boundary\n",
    "                 sigma=0.5,                     # kernel width for adjacency\n",
    "                 top_k=0,                       # if >0, keep only top_k largest entries in each row\n",
    "                 activation_choices=('tanh','relu','sin','linear'),\n",
    "                 spectral_radius=0.95,\n",
    "                 input_scale=1.0, \n",
    "                 leaking_rate=1.0,\n",
    "                 ridge_alpha=1e-6,\n",
    "                 seed=42):\n",
    "        \"\"\"\n",
    "        reservoir_size      : number of nodes\n",
    "        disk_radius         : we sample node positions r<disk_radius < 1 for Poincaré disk\n",
    "        sigma               : kernel width used in adjacency\n",
    "        top_k               : if >0, keep only top_k in each row, else 0\n",
    "        activation_choices  : set of activation types to randomly assign\n",
    "        spectral_radius     : final adjacency scale\n",
    "        input_scale         : scale for W_in\n",
    "        leaking_rate        : ESN leak factor\n",
    "        ridge_alpha         : readout ridge penalty\n",
    "        seed                : random seed\n",
    "        \"\"\"\n",
    "\n",
    "        self.reservoir_size = reservoir_size\n",
    "        self.disk_radius = disk_radius\n",
    "        self.sigma = sigma\n",
    "        self.top_k = top_k\n",
    "        self.activation_choices = activation_choices\n",
    "        self.spectral_radius = spectral_radius\n",
    "        self.input_scale = input_scale\n",
    "        self.leaking_rate = leaking_rate\n",
    "        self.ridge_alpha = ridge_alpha\n",
    "        self.seed = seed\n",
    "        \n",
    "        np.random.seed(self.seed)\n",
    "        # Pick angle ~ Uniform (0,2*pi)\n",
    "        angles = 2.0 * np.pi * np.random.rand(self.reservoir_size)\n",
    "        # Convert the Euclidean boundary radius to hyperbolic radius\n",
    "        hyperbolic_radius = 2 * np.arctanh(self.disk_radius)\n",
    "        # r_unif = np.sqrt(np.random.rand(self.reservoir_size)) * self.disk_radius\n",
    "        r_unif = np.arccosh(np.random.rand(self.reservoir_size) * (np.cosh(hyperbolic_radius) - 1) + 1)\n",
    "        positions = np.zeros((self.reservoir_size, 2))\n",
    "        for i in range(self.reservoir_size):\n",
    "            # positions[i,0] = r_unif[i] * np.cos(angles[i])\n",
    "            # positions[i,1] = r_unif[i] * np.sin(angles[i])\n",
    "\n",
    "            positions[i,0] = np.tanh(r_unif[i]/2) * np.cos(angles[i])\n",
    "            positions[i,1] = np.tanh(r_unif[i]/2) * np.sin(angles[i])\n",
    "        self.positions = positions\n",
    "\n",
    "\n",
    "        # Build adjacency with hyperbolic_distance_poincare + kernel\n",
    "        W = np.zeros((self.reservoir_size, self.reservoir_size))\n",
    "        for i in range(self.reservoir_size):\n",
    "            for j in range(self.reservoir_size):\n",
    "                if i == j:\n",
    "                    continue\n",
    "                d_ij = hyperbolic_distance_poincare(self.positions[i], self.positions[j])\n",
    "                val = np.exp(- d_ij / self.sigma)\n",
    "                W[i, j] = val\n",
    "\n",
    "        # W1 = W.copy()\n",
    "        # Row-level sparsity\n",
    "        if self.top_k > 0:\n",
    "            for i in range(self.reservoir_size):\n",
    "                row = W[i,:]\n",
    "                idx_sorted = np.argsort(row)[::-1]\n",
    "                keep_count = min(self.top_k, self.reservoir_size)\n",
    "                row_mask = np.zeros(self.reservoir_size, dtype=bool)\n",
    "                row_mask[idx_sorted[:keep_count]] = True\n",
    "                W[i, ~row_mask] = 0.0\n",
    "\n",
    "        # visualize_sparsity(W1, W)\n",
    "        # Scale spectral radius\n",
    "        W = scale_spectral_radius(W, self.spectral_radius)\n",
    "        self.W = W\n",
    "\n",
    "        # draw_hyperbolic_reservoir(self.positions, W)\n",
    "\n",
    "        np.random.seed(self.seed + 100)\n",
    "        # Initialize input weights in range [-input_scale, input_scale]\n",
    "        self.W_in = (np.random.rand(self.reservoir_size, 3) - 0.5) * 2.0 * self.input_scale\n",
    "\n",
    "        np.random.seed(self.seed + 200)\n",
    "        self.node_activations = np.random.choice(self.activation_choices, size=self.reservoir_size)\n",
    "\n",
    "        # Readout: shape (3, reservoir_size+1) -> 3D output\n",
    "        self.W_out = None\n",
    "        self.reset_state()\n",
    "\n",
    "    def _apply_activation(self, act_type, val):\n",
    "        if act_type=='tanh':\n",
    "            return np.tanh(val)\n",
    "        elif act_type=='relu':\n",
    "            return max(0.0, val)\n",
    "        elif act_type=='sin':\n",
    "            return np.sin(val)\n",
    "        elif act_type=='linear':\n",
    "            return val\n",
    "        else:\n",
    "            return np.tanh(val)\n",
    "\n",
    "    def _update(self, u):\n",
    "        \"\"\"\n",
    "        x(t+1) = (1-alpha)*x(t) + alpha*[ node-by-node activation( W*x(t)+W_in*u ) ]\n",
    "        \"\"\"\n",
    "        pre_activations = self.W @ self.x + self.W_in @ u\n",
    "        x_new = np.zeros_like(self.x)\n",
    "        for i in range(self.reservoir_size):\n",
    "            activation = self.node_activations[i]\n",
    "            x_new[i] = self._apply_activation(activation, pre_activations[i])\n",
    "        alpha = self.leaking_rate\n",
    "        self.x = (1.0 - alpha)*self.x + alpha*x_new\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5489becf",
   "metadata": {},
   "source": [
    "### HFR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "839cec7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_spectral_radius(W, target_radius=0.95):\n",
    "    \"\"\"\n",
    "    Scales a matrix W so that its largest eigenvalue magnitude = target_radius.\n",
    "    \"\"\"\n",
    "    eigvals = np.linalg.eigvals(W)\n",
    "    radius = np.max(np.abs(eigvals))\n",
    "    if radius == 0:\n",
    "        return W\n",
    "    return (W / radius) * target_radius\n",
    "\n",
    "def augment_state_with_squares(x):\n",
    "    \"\"\"\n",
    "    Given state vector x in R^N, return [ x, x^2, 1 ] in R^(2N+1).\n",
    "    We'll use this for both training and prediction.\n",
    "    \"\"\"\n",
    "    x_sq = x**2\n",
    "    return np.concatenate([x, x_sq, [1.0]])  # shape: 2N+1\n",
    "\n",
    "class HFRRes3D:\n",
    "    \"\"\"\n",
    "    Hierarchical Fractal Reservoir (HFR) for 3D chaotic systems.\n",
    "    \n",
    "    This novel reservoir architecture partitions the chaotic attractor at multiple\n",
    "    hierarchical scales, combining them in a fractal-like adjacency structure.\n",
    "    The method is model-free, relying solely on the observed trajectory in R^3,\n",
    "    and does not require knowledge of any system parameters such as sigma, rho, beta\n",
    "    for Lorenz63. \n",
    "    \n",
    "    Key Idea:\n",
    "     1) Define multiple 'scales' of partition of the data's bounding region.\n",
    "     2) Each scale is subdivided into a certain number of cells (regions).\n",
    "     3) Each cell at level l has links to both:\n",
    "        - other cells at the same level (horizontal adjacency),\n",
    "        - 'child' cells at the finer level l+1 (vertical adjacency).\n",
    "     4) We gather all cells across levels => a multi-level fractal graph => adjacency => W.\n",
    "     5) We build a typical ESN from this adjacency, feed data with W_in, run leaky tanh updates,\n",
    "        then do a polynomial readout for 3D next-step prediction.\n",
    "\n",
    "    This approach is suitable for chaotic systems whose attractors often exhibit fractal\n",
    "    self-similarity, thus capturing multi-scale structures in a single reservoir.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 n_levels=3,             # number of hierarchical levels\n",
    "                 cells_per_level=None,   # list of number of cells at each level, e.g. [8, 32, 128]\n",
    "                 spectral_radius=0.95,\n",
    "                 input_scale=1.0,\n",
    "                 leaking_rate=1.0,\n",
    "                 ridge_alpha=1e-6,\n",
    "                 seed=42):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_levels       : int, number of hierarchical scales\n",
    "        cells_per_level: list[int], the number of partitions/cells at each level\n",
    "                         if None, we auto-generate e.g. 2^(level+2)\n",
    "        spectral_radius: final scaling for adjacency\n",
    "        input_scale    : random input scale W_in\n",
    "        leaking_rate   : ESN leaky alpha\n",
    "        ridge_alpha    : readout ridge penalty\n",
    "        seed           : random seed\n",
    "        \"\"\"\n",
    "        self.n_levels        = n_levels\n",
    "        self.cells_per_level = cells_per_level\n",
    "        self.spectral_radius = spectral_radius\n",
    "        self.input_scale     = input_scale\n",
    "        self.leaking_rate    = leaking_rate\n",
    "        self.ridge_alpha     = ridge_alpha\n",
    "        self.seed            = seed\n",
    "\n",
    "        if self.cells_per_level is None:\n",
    "            # default scheme e.g. 8, 16, 32 for 3 levels\n",
    "            self.cells_per_level = [8*(2**i) for i in range(n_levels)]\n",
    "\n",
    "        # We'll store adjacency W, input W_in, readout W_out, reservoir state x\n",
    "        self.W     = None\n",
    "        self.W_in  = None\n",
    "        self.W_out = None\n",
    "        self.x     = None\n",
    "        self.n_levels = len(self.cells_per_level)\n",
    "\n",
    "        # We'll define a total number of nodes = sum(cells_per_level)\n",
    "        self.n_nodes = sum(self.cells_per_level)\n",
    "\n",
    "    def _build_partitions(self, data_3d):\n",
    "        \"\"\"\n",
    "        Build hierarchical partitions for each level.\n",
    "        We'll store the bounding box for data_3d, then for each level l in [0..n_levels-1]\n",
    "        run e.g. k-means with K = cells_per_level[l], each point gets a label => we track transitions.\n",
    "\n",
    "        Return: \n",
    "          partitions => list of arrays, partitions[l] => shape (N, ) cluster assignment in [0..cells_per_level[l]-1]\n",
    "        \"\"\"\n",
    "        from sklearn.cluster import KMeans\n",
    "        N = len(data_3d)\n",
    "        partitions = []\n",
    "\n",
    "        for level in range(self.n_levels):\n",
    "            k = self.cells_per_level[level]\n",
    "            # cluster\n",
    "            kmeans = KMeans(n_clusters=k, random_state=self.seed+10*level, n_init='auto')\n",
    "            kmeans.fit(data_3d)\n",
    "            labels = kmeans.predict(data_3d)\n",
    "            partitions.append(labels)\n",
    "\n",
    "        return partitions\n",
    "\n",
    "    def _build_hierarchical_adjacency(self, data_3d):\n",
    "        \"\"\"\n",
    "        Build a block adjacency with cross-level links, then scale spectral radius.\n",
    "        Steps:\n",
    "          1) Build partitions for each level => partitions[l] in [0..cells_per_level[l]-1]\n",
    "          2) For each level l, build a transition matrix T_l of shape (cells_per_level[l], cells_per_level[l]).\n",
    "          3) Link scale l to scale l+1 by figuring out which cluster i at scale l maps to which cluster j at scale l+1\n",
    "             for each sample t => link i-> j if data_3d[t] is in i at scale l and j at scale l+1.\n",
    "          4) Combine all transitions in one big adjacency W in R^(n_nodes x n_nodes).\n",
    "          5) row-normalize W => scale largest eigenvalue => spectral_radius\n",
    "        \"\"\"\n",
    "        partitions = self._build_partitions(data_3d)\n",
    "        N = len(data_3d)\n",
    "\n",
    "        # offsets for each level => to index big W\n",
    "        offsets = []\n",
    "        running = 0\n",
    "        for level in range(self.n_levels):\n",
    "            offsets.append(running)\n",
    "            running += self.cells_per_level[level]\n",
    "\n",
    "        # total nodes\n",
    "        n_tot = self.n_nodes\n",
    "        # initialize adjacency\n",
    "        A = np.zeros((n_tot, n_tot))\n",
    "\n",
    "        # 1) horizontal adjacency in each level\n",
    "        for level in range(self.n_levels):\n",
    "            k = self.cells_per_level[level]\n",
    "            labels = partitions[level]\n",
    "            # T_l => shape (k, k)\n",
    "            T_l = np.zeros((k, k))\n",
    "            for t in range(N-1):\n",
    "                i = labels[t]\n",
    "                j = labels[t+1]\n",
    "                T_l[i,j]+=1\n",
    "            # row normalize\n",
    "            row_sum = T_l.sum(axis=1, keepdims=True)\n",
    "            row_sum[row_sum==0.0] = 1.0\n",
    "            T_l /= row_sum\n",
    "            # place T_l into big A\n",
    "            off = offsets[level]\n",
    "            A[off:off+k, off:off+k] = T_l\n",
    "\n",
    "        # 2) vertical adjacency between scale l and l+1\n",
    "        for level in range(self.n_levels-1):\n",
    "            k_l   = self.cells_per_level[level]\n",
    "            k_lp1 = self.cells_per_level[level+1]\n",
    "            labels_l   = partitions[level]\n",
    "            labels_lp1 = partitions[level+1]\n",
    "            # we define adjacency from i in [0..k_l-1] to j in [0..k_lp1-1] if the same sample t belongs to i at level l and j at l+1\n",
    "            # Count how many times\n",
    "            Xvert1 = np.zeros((k_l, k_lp1))\n",
    "            for t in range(N):\n",
    "                i = labels_l[t]\n",
    "                j = labels_lp1[t]\n",
    "                Xvert1[i,j]+=1\n",
    "            # row normalize\n",
    "            row_sum = Xvert1.sum(axis=1, keepdims=True)\n",
    "            row_sum[row_sum==0.0] = 1.0\n",
    "            Xvert = Xvert1/row_sum\n",
    "            # place in big A\n",
    "            off_l   = offsets[level]\n",
    "            off_lp1 = offsets[level+1]\n",
    "            A[off_l:off_l+k_l, off_lp1:off_lp1+k_lp1] = Xvert\n",
    "            # tentative idea, we could also define adjacency from l+1 -> l (parent link), if desired\n",
    "            # we do the same for the 'child -> parent' link or skip it if we only want forward adjacency\n",
    "            # For now, let's do symmetrical\n",
    "            Yvert = Xvert1.T\n",
    "            col_sum = Yvert.sum(axis=1, keepdims=True)\n",
    "            col_sum[col_sum==0.0] = 1.0\n",
    "            Yvert /= col_sum\n",
    "            A[off_lp1:off_lp1+k_lp1, off_l:off_l+k_l] = Yvert\n",
    "\n",
    "        # now we have a big adjacency => row normalize again, then scale spectral radius\n",
    "        row_sum = A.sum(axis=1, keepdims=True)\n",
    "        row_sum[row_sum==0.0] = 1.0\n",
    "        A /= row_sum\n",
    "\n",
    "        A = scale_spectral_radius(A, self.spectral_radius)\n",
    "        return A\n",
    "\n",
    "    def fit_readout(self, train_input, train_target, discard=100):\n",
    "        \"\"\"\n",
    "        Main training routine:\n",
    "          1) Build hierarchical adjacency from fractal partition => self.W\n",
    "          2) define W_in => shape(n_nodes, 3)\n",
    "          3) teacher forcing => polynomial readout => solve => self.W_out\n",
    "        \"\"\"\n",
    "        np.random.seed(self.seed)\n",
    "        # Build adjacency\n",
    "        W_big = self._build_hierarchical_adjacency(train_input)\n",
    "        self.W = W_big\n",
    "\n",
    "        # define W_in => shape(n_nodes,3)\n",
    "        self.n_nodes = W_big.shape[0]\n",
    "        self.W_in = (np.random.rand(self.n_nodes,3)-0.5)*2.0*self.input_scale\n",
    "\n",
    "        # define reservoir state\n",
    "        self.x = np.zeros(self.n_nodes)\n",
    "\n",
    "        # gather states => teacher forcing => polynomial => readout\n",
    "        states_use, _ = self.collect_states(train_input, discard=discard)\n",
    "        target_use = train_target[discard:]\n",
    "        X_list= []\n",
    "        for s in states_use:\n",
    "            X_list.append( augment_state_with_squares(s) )\n",
    "        X_aug= np.array(X_list)\n",
    "\n",
    "        reg= Ridge(alpha=self.ridge_alpha, fit_intercept=False)\n",
    "        reg.fit(X_aug, target_use)\n",
    "        self.W_out= reg.coef_\n",
    "\n",
    "    def collect_states(self, inputs, discard=100):\n",
    "        \"\"\"\n",
    "        Teacher forcing => feed real 3D => gather states => shape => [T-discard, n_nodes].\n",
    "        returns (states_after_discard, states_discarded).\n",
    "        \"\"\"\n",
    "        self.reset_state()\n",
    "        states= []\n",
    "        for val in inputs:\n",
    "            self._update(val)\n",
    "            states.append(self.x.copy())\n",
    "        states= np.array(states)\n",
    "        return states[discard:], states[:discard]\n",
    "\n",
    "    def reset_state(self):\n",
    "        if self.x is not None:\n",
    "            self.x.fill(0.0)\n",
    "\n",
    "    def _update(self, u):\n",
    "        \"\"\"\n",
    "        x(t+1)= (1-alpha)x(t)+ alpha tanh( W*x(t)+ W_in*u(t) ).\n",
    "        \"\"\"\n",
    "        alpha= self.leaking_rate\n",
    "        pre_acts= self.W@self.x + self.W_in@u\n",
    "        x_new= np.tanh(pre_acts)\n",
    "        self.x= (1.0- alpha)*self.x+ alpha*x_new\n",
    "\n",
    "    def predict_autoregressive(self, initial_input, n_steps):\n",
    "        \"\"\"\n",
    "        fully autonomous => feed last predicted => next input\n",
    "        \"\"\"\n",
    "        preds= []\n",
    "        #self.reset_state()\n",
    "        current_in= np.array(initial_input)\n",
    "        for _ in range(n_steps):\n",
    "            self._update(current_in)\n",
    "            big_x= augment_state_with_squares(self.x)\n",
    "            out= self.W_out@big_x\n",
    "            preds.append(out)\n",
    "            current_in= out\n",
    "        return np.array(preds)\n",
    "    \n",
    "    def predict_open_loop(self, test_input):\n",
    "        preds = []\n",
    "        for true_input in test_input:\n",
    "            self._update(true_input)\n",
    "            x_aug = augment_state_with_squares(self.x)\n",
    "            out = self.W_out @ x_aug\n",
    "            preds.append(out)\n",
    "        return np.array(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587f6038",
   "metadata": {},
   "source": [
    "### NRMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b55e0383",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_nrmse(all_preds, test_target, horizons):\n",
    "    \"\"\"\n",
    "    Evaluate model performance over multiple prediction horizons for Teacher-forced Single-step Forecasting\n",
    "    \"\"\"\n",
    "    horizon_nrmse = {}\n",
    "    \n",
    "    for horizon in horizons:\n",
    "        preds = all_preds[:horizon]\n",
    "        targets = test_target[:horizon]\n",
    "        squared_errors = (preds - targets)**2\n",
    "        variance = np.var(targets, axis=0)\n",
    "        nrmse = np.sqrt(np.sum(squared_errors) / (horizon * variance))\n",
    "        horizon_nrmse[horizon] = nrmse\n",
    "\n",
    "    return horizon_nrmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb9a21c",
   "metadata": {},
   "source": [
    "### VPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "193a03f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_valid_prediction_time(y_true, y_pred, test_time, lyapunov_time, threshold=0.4):\n",
    "    y_mean = np.mean(y_true, axis=0)\n",
    "    y_centered = y_true - y_mean\n",
    "    denom = np.mean(np.sum(y_centered**2, axis=1))\n",
    "\n",
    "    error = y_true - y_pred\n",
    "    squared_error = np.sum(error**2, axis=1)\n",
    "    delta = squared_error / denom\n",
    "\n",
    "    idx_exceed = np.where(delta > threshold)[0]\n",
    "    if len(idx_exceed) == 0:\n",
    "        # never exceeds threshold => set T_VPT to the final time\n",
    "        T_VPT = test_time[-1]\n",
    "    else:\n",
    "        T_VPT = test_time[idx_exceed[0]]\n",
    "\n",
    "    ratio = T_VPT / lyapunov_time\n",
    "\n",
    "    return T_VPT, ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4e8e78",
   "metadata": {},
   "source": [
    "### ADev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "38f84534",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_attractor_deviation(predictions, targets, cube_size=(0.1, 0.1, 0.1)):\n",
    "    \"\"\"\n",
    "    Compute the Attractor Deviation (ADev) metric.\n",
    "\n",
    "    Parameters:\n",
    "        predictions (numpy.ndarray): Predicted trajectories of shape (n, 3).\n",
    "        targets (numpy.ndarray): True trajectories of shape (n, 3).\n",
    "        cube_size (tuple): Dimensions of the cube (dx, dy, dz).\n",
    "\n",
    "    Returns:\n",
    "        float: The ADev metric.\n",
    "    \"\"\"\n",
    "    # Define the cube grid based on the range of the data and cube size\n",
    "    min_coords = np.min(np.vstack((predictions, targets)), axis=0)\n",
    "    max_coords = np.max(np.vstack((predictions, targets)), axis=0)\n",
    "\n",
    "    # Create a grid of cubes\n",
    "    grid_shape = ((max_coords - min_coords) / cube_size).astype(int) + 1\n",
    "\n",
    "    # Initialize the cube occupancy arrays\n",
    "    pred_cubes = np.zeros(grid_shape, dtype=int)\n",
    "    target_cubes = np.zeros(grid_shape, dtype=int)\n",
    "\n",
    "    # Map trajectories to cubes\n",
    "    pred_indices = ((predictions - min_coords) / cube_size).astype(int)\n",
    "    target_indices = ((targets - min_coords) / cube_size).astype(int)\n",
    "\n",
    "    # Mark cubes visited by predictions and targets\n",
    "    for idx in pred_indices:\n",
    "        pred_cubes[tuple(idx)] = 1\n",
    "    for idx in target_indices:\n",
    "        target_cubes[tuple(idx)] = 1\n",
    "\n",
    "    # Compute the ADev metric\n",
    "    adev = np.sum(np.abs(pred_cubes - target_cubes))\n",
    "    return adev"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825c2de7",
   "metadata": {},
   "source": [
    "### PSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "402a5c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_psd(y, dt=0.01):\n",
    "    z = y[:, 2]  # Extract Z-component\n",
    "    \n",
    "    # Compute PSD using Welch’s method\n",
    "    freqs, psd = welch(z, fs=1/dt, window='hamming', nperseg=len(z))  # Using Hamming window\n",
    "    \n",
    "    return freqs, psd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8719c3c",
   "metadata": {},
   "source": [
    "# MIT-BIH Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "54b46a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wfdb\n",
    "\n",
    "# Download and load record and annotations for patient #100\n",
    "record = wfdb.rdrecord('100', sampfrom=0, sampto=25002, pn_dir='mitdb')  # first 20,000 samples\n",
    "annotation = wfdb.rdann('100', 'atr', sampfrom=0, sampto=25002, pn_dir='mitdb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7a0e8cf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.145, -0.145, -0.145, ..., -0.41 , -0.415, -0.425],\n",
       "      shape=(25002,))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get input signal u(t) from the first channel\n",
    "u = record.p_signal[:, 0] \n",
    "u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "93538ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize input\n",
    "u_min = np.min(u)\n",
    "u_max = np.max(u)\n",
    "u_norm = (u - u_min) / (u_max - u_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6dfcd0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = record.fs  # sampling frequency (should be 360 Hz)\n",
    "t_vals = np.arange(len(u_norm)) / fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ef734865",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_dim = 3\n",
    "# inputs = u_norm\n",
    "inputs = create_delay_embedding(u_norm, emb_dim)\n",
    "\n",
    "# Create target array (heartbeat locations)\n",
    "targets = np.zeros(len(u_norm))\n",
    "targets[annotation.sample] = 1  # mark annotations as 1 (heartbeat)\n",
    "targets = create_delay_embedding(targets, emb_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "938389fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 25000, train size: 15000, test size: 9999\n"
     ]
    }
   ],
   "source": [
    "data_size = len(inputs)\n",
    "train_size = 15000\n",
    "train_input = inputs[:train_size]\n",
    "train_target = targets[:train_size]\n",
    "test_input = inputs[train_size+1:]\n",
    "test_target = targets[train_size+1:]\n",
    "test_size = len(test_input)\n",
    "print(f\"Total samples: {data_size}, train size: {train_size}, test size: {test_size}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f2f85de1",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 103\u001b[39m\n\u001b[32m     93\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m seed \u001b[38;5;129;01min\u001b[39;00m seeds:\n\u001b[32m     94\u001b[39m     deepesn = DeepESN3D(\n\u001b[32m     95\u001b[39m         num_layers=\u001b[32m5\u001b[39m,\n\u001b[32m     96\u001b[39m         reservoir_size=\u001b[32m100\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    101\u001b[39m         seed=seed\n\u001b[32m    102\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m     \u001b[43mdeepesn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit_readout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_target\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiscard\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    104\u001b[39m     deepesn_preds = deepesn.predict(test_input)\n\u001b[32m    105\u001b[39m     deepesn_nrmse = evaluate_nrmse(deepesn_preds, test_target, all_horizons)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 108\u001b[39m, in \u001b[36mDeepESN3D.fit_readout\u001b[39m\u001b[34m(self, train_input, train_target, discard)\u001b[39m\n\u001b[32m    104\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfit_readout\u001b[39m(\u001b[38;5;28mself\u001b[39m, train_input, train_target, discard=\u001b[32m100\u001b[39m):\n\u001b[32m    105\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    106\u001b[39m \u001b[33;03m    Train the readout layer using ridge regression.\u001b[39;00m\n\u001b[32m    107\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m108\u001b[39m     states_use, _ = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcollect_states\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiscard\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdiscard\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    109\u001b[39m     targets_use = train_target[discard:]\n\u001b[32m    111\u001b[39m     \u001b[38;5;66;03m# Augment states with bias\u001b[39;00m\n\u001b[32m    112\u001b[39m     \u001b[38;5;66;03m# X_aug = np.hstack([states_use, np.ones((states_use.shape[0], 1))])  # shape [T-discard, N*L+1]\u001b[39;00m\n\u001b[32m    113\u001b[39m \n\u001b[32m    114\u001b[39m     \u001b[38;5;66;03m# Quadratic readout\u001b[39;00m\n\u001b[32m    115\u001b[39m     \u001b[38;5;66;03m# Build augmented matrix [ x, x^2, 1 ]\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 99\u001b[39m, in \u001b[36mDeepESN3D.collect_states\u001b[39m\u001b[34m(self, inputs, discard)\u001b[39m\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m u \u001b[38;5;129;01min\u001b[39;00m inputs:\n\u001b[32m     98\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m layer_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m.num_layers):\n\u001b[32m---> \u001b[39m\u001b[32m99\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_update_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayer_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mu\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    100\u001b[39m     all_states.append(np.concatenate(\u001b[38;5;28mself\u001b[39m.states))\n\u001b[32m    101\u001b[39m all_states = np.array(all_states)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 90\u001b[39m, in \u001b[36mDeepESN3D._update_layer\u001b[39m\u001b[34m(self, layer_idx, u)\u001b[39m\n\u001b[32m     88\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m.reservoir_size):\n\u001b[32m     89\u001b[39m     activation = \u001b[38;5;28mself\u001b[39m.node_activations[i]\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m     x_new[i] = \u001b[38;5;28mself\u001b[39m._apply_activation(activation, pre_activation[i])\n\u001b[32m     91\u001b[39m alpha = \u001b[38;5;28mself\u001b[39m.leaking_rate\n\u001b[32m     92\u001b[39m \u001b[38;5;28mself\u001b[39m.states[layer_idx] = (\u001b[32m1.0\u001b[39m - alpha) * \u001b[38;5;28mself\u001b[39m.states[layer_idx] + alpha * x_new\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "all_horizons = [1000]\n",
    "\n",
    "\n",
    "nrmse_dict = defaultdict(list)\n",
    "seeds = range(995, 1025)\n",
    "\n",
    "\n",
    "for seed in seeds:\n",
    "    esn = BaselineESN3D(\n",
    "        reservoir_size=500,\n",
    "        spectral_radius=0.99,\n",
    "        connectivity=0.05,\n",
    "        input_scale=0.2,\n",
    "        leaking_rate=0.8,\n",
    "        ridge_alpha=1e-6,\n",
    "        seed=seed\n",
    "    )\n",
    "    esn.fit_readout(train_input, train_target, discard=5000)\n",
    "    esn_preds = esn.predict(test_input)\n",
    "    esn_nrmse = evaluate_nrmse(esn_preds, test_target, all_horizons)\n",
    "    nrmse_dict['ESN'].append(esn_nrmse)\n",
    "\n",
    "\n",
    "for seed in seeds:\n",
    "    cycle_res = CycleReservoir3D(\n",
    "        reservoir_size=500,\n",
    "        cycle_weight = 0.8,\n",
    "        spectral_radius=0.99,\n",
    "        input_scale=0.2,\n",
    "        leaking_rate=0.8,\n",
    "        ridge_alpha=1e-6,\n",
    "        seed=seed\n",
    "    )\n",
    "    cycle_res.fit_readout(train_input, train_target, discard=5000)\n",
    "    cycle_res_preds = cycle_res.predict(test_input)\n",
    "    cycle_res_nrmse = evaluate_nrmse(cycle_res_preds, test_target, all_horizons)\n",
    "    nrmse_dict['SCR'].append(cycle_res_nrmse)\n",
    "\n",
    "\n",
    "for seed in seeds:\n",
    "    crj = CRJRes3D(\n",
    "        reservoir_size=500,\n",
    "        edge_weight=0.8,\n",
    "        jump=15,\n",
    "        spectral_radius=0.99,\n",
    "        input_scale=0.2,\n",
    "        leaking_rate=0.8,\n",
    "        ridge_alpha=1e-6,\n",
    "        seed=seed\n",
    "    )\n",
    "    crj.fit_readout(train_input, train_target, discard=5000)\n",
    "    crj_preds = crj.predict(test_input)\n",
    "    crj_nrmse = evaluate_nrmse(crj_preds, test_target, all_horizons)\n",
    "    nrmse_dict['CRJ'].append(crj_nrmse)\n",
    "\n",
    "\n",
    "# for seed in seeds:\n",
    "#     sw_esn = SWRes3D(\n",
    "#         reservoir_size=500,\n",
    "#         rewiring_prob=0.1,\n",
    "#         degree=6,\n",
    "#         spectral_radius=0.99,\n",
    "#         input_scale=0.2,\n",
    "#         leaking_rate=0.8,\n",
    "#         ridge_alpha=1e-6,\n",
    "#         seed=seed\n",
    "#     )\n",
    "#     sw_esn.fit_readout(train_input, train_target, discard=5000)\n",
    "#     sw_esn_preds = sw_esn.predict(test_input)\n",
    "#     sw_esn_nrmse = evaluate_nrmse(sw_esn_preds, test_target, all_horizons)\n",
    "#     nrmse_dict['SW-ESN'].append(sw_esn_nrmse)\n",
    "\n",
    "\n",
    "for seed in seeds:\n",
    "    mci_esn = MCIESN3D(\n",
    "        reservoir_size=500,\n",
    "        cycle_weight=0.8,\n",
    "        connect_weight=0.8,\n",
    "        combine_factor=0.1,\n",
    "        v1=0.03,\n",
    "        v2=0.03,\n",
    "        spectral_radius=0.99,\n",
    "        leaking_rate=0.8,\n",
    "        ridge_alpha=1e-6,\n",
    "        seed=seed\n",
    "    )\n",
    "    mci_esn.fit_readout(train_input, train_target, discard=5000)\n",
    "    mci_esn_preds = mci_esn.predict(test_input)\n",
    "    mci_esn_nrmse = evaluate_nrmse(mci_esn_preds, test_target, all_horizons)\n",
    "    nrmse_dict['MCI-ESN'].append(mci_esn_nrmse)\n",
    "\n",
    "\n",
    "for seed in seeds:\n",
    "    deepesn = DeepESN3D(\n",
    "        num_layers=5,\n",
    "        reservoir_size=100,\n",
    "        spectral_radius=0.99,\n",
    "        input_scale=0.2,\n",
    "        leaking_rate=0.8,\n",
    "        ridge_alpha=1e-6,\n",
    "        seed=seed\n",
    "    )\n",
    "    deepesn.fit_readout(train_input, train_target, discard=5000)\n",
    "    deepesn_preds = deepesn.predict(test_input)\n",
    "    deepesn_nrmse = evaluate_nrmse(deepesn_preds, test_target, all_horizons)\n",
    "    nrmse_dict['DeepESN'].append(deepesn_nrmse)\n",
    "\n",
    "\n",
    "# for seed in seeds:\n",
    "#     hypER = HypER3D(\n",
    "#             reservoir_size=500,\n",
    "#             disk_radius=0.99, \n",
    "#             sigma=0.4,\n",
    "#             top_k=20,\n",
    "#             spectral_radius=0.99,\n",
    "#             input_scale=0.2,\n",
    "#             leaking_rate=0.8,\n",
    "#             ridge_alpha=1e-6,\n",
    "#             seed=seed\n",
    "#         )\n",
    "#     hypER.fit_readout(train_input, train_target, discard=5000)\n",
    "#     hypER_preds = hypER.predict(test_input)\n",
    "#     hypER_nrmse = evaluate_nrmse(hypER_preds, test_target, all_horizons)\n",
    "#     nrmse_dict['HypER'].append(hypER_nrmse)\n",
    "\n",
    "for seed in seeds:\n",
    "    hfr = HFRRes3D(\n",
    "        n_levels=8,      \n",
    "        cells_per_level=[5, 10, 20, 25, 30, 35, 40, 60, 75, 90, 110],\n",
    "        spectral_radius=0.01,\n",
    "        input_scale=1.5,\n",
    "        leaking_rate=0.5,\n",
    "        ridge_alpha=1e-8,\n",
    "        seed=seed\n",
    "    )\n",
    "    hfr.fit_readout(train_input, train_target, discard=5000)\n",
    "    hfr_preds = hfr.predict_open_loop(test_input)\n",
    "    hfr_nrmse = evaluate_nrmse(hfr_preds, test_target, all_horizons)\n",
    "    nrmse_dict['HFR'].append(hfr_nrmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45beceb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seaborn style\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Assuming `nrmse_dict` already exists from your evaluation loop\n",
    "# Each entry: nrmse_dict[model_name] = list of dicts like [{'1000': val}, ...]\n",
    "\n",
    "# Flatten values from each seed's output at horizon 1000\n",
    "horizon = \"1000\"\n",
    "model_names = list(nrmse_dict.keys())\n",
    "flattened_nrmse_data = {\n",
    "    model: [entry[horizon] for entry in nrmse_dict[model]]\n",
    "    for model in model_names\n",
    "}\n",
    "\n",
    "# Create boxplot\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(data=[flattened_nrmse_data[model] for model in model_names],\n",
    "            orient=\"v\", showfliers=False)\n",
    "\n",
    "plt.xticks(ticks=range(len(model_names)), labels=model_names, rotation=15)\n",
    "plt.ylabel(\"NRMSE @ Horizon = 1000\")\n",
    "plt.title(\"Model Comparison: NRMSE Distribution at Horizon 1000\")\n",
    "\n",
    "# Save high-res version\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"box_ecg_1000.png\", dpi=250)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337c012a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NRMSE for Different Prediction Horizons:\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Horizon    ESN               SCR               CRJ               SW-ESN            MCI-ESN           DeepESN           HypER            \n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "1000       1.4987 ± 0.2916   1.3069 ± 0.1143   1.2053 ± 0.1060   1.3972 ± 0.1451   1.1230 ± 0.0121   1.6553 ± 0.2547   0.7492 ± 0.1166   \n"
     ]
    }
   ],
   "source": [
    "print(\"\\nNRMSE for Different Prediction Horizons:\")\n",
    "print(\"-\" * 140)\n",
    "print(f\"{'Horizon':<10} {'ESN':<17} {'SCR':<17} {'CRJ':<17} {'MCI-ESN':<17} {'DeepESN':<17} {'HFR':<17}\")\n",
    "print(\"-\" * 140)\n",
    "\n",
    "\n",
    "for horizon in all_horizons:\n",
    "    esn_vals = [np.mean(esn_nrmse[horizon]) for esn_nrmse in nrmse_dict['ESN']]\n",
    "    scr_vals = [np.mean(cycle_res_nrmse[horizon]) for cycle_res_nrmse in nrmse_dict['SCR']]\n",
    "    crj_vals = [np.mean(crj_nrmse[horizon]) for crj_nrmse in nrmse_dict['CRJ']]\n",
    "    # sw_vals  = [np.mean(sw_esn_nrmse[horizon]) for sw_esn_nrmse in nrmse_dict['SW-ESN']]\n",
    "    mci_vals = [np.mean(mci_esn_nrmse[horizon]) for mci_esn_nrmse in nrmse_dict['MCI-ESN']]\n",
    "    deep_vals = [np.mean(deepesn_nrmse[horizon]) for deepesn_nrmse in nrmse_dict['DeepESN']]\n",
    "    # hypER_vals = [np.mean(hypER_nrmse[horizon]) for hypER_nrmse in nrmse_dict['HypER']]\n",
    "    hfr_vals = [np.mean(hfr_nrmse[horizon]) for hfr_nrmse in nrmse_dict['HFR']]\n",
    "\n",
    "    print(f\"{horizon:<10}\", end=\" \")\n",
    "    for vals in [esn_vals, scr_vals, crj_vals, mci_vals, deep_vals, hfr_vals]:\n",
    "        mean = np.mean(vals)\n",
    "        std = np.std(vals)\n",
    "        print(f\"{mean:.4f} ± {std:.4f}\".ljust(18), end=\"\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39c1e20",
   "metadata": {},
   "source": [
    "# Sunspot Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3232502c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1749</td>\n",
       "      <td>1</td>\n",
       "      <td>1749.042</td>\n",
       "      <td>96.7</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1749</td>\n",
       "      <td>2</td>\n",
       "      <td>1749.123</td>\n",
       "      <td>104.3</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1749</td>\n",
       "      <td>3</td>\n",
       "      <td>1749.204</td>\n",
       "      <td>116.7</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1749</td>\n",
       "      <td>4</td>\n",
       "      <td>1749.288</td>\n",
       "      <td>92.8</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1749</td>\n",
       "      <td>5</td>\n",
       "      <td>1749.371</td>\n",
       "      <td>141.7</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3310</th>\n",
       "      <td>2024</td>\n",
       "      <td>11</td>\n",
       "      <td>2024.873</td>\n",
       "      <td>152.5</td>\n",
       "      <td>20.9</td>\n",
       "      <td>681</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3311</th>\n",
       "      <td>2024</td>\n",
       "      <td>12</td>\n",
       "      <td>2024.958</td>\n",
       "      <td>154.5</td>\n",
       "      <td>25.6</td>\n",
       "      <td>572</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3312</th>\n",
       "      <td>2025</td>\n",
       "      <td>1</td>\n",
       "      <td>2025.042</td>\n",
       "      <td>137.0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>670</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3313</th>\n",
       "      <td>2025</td>\n",
       "      <td>2</td>\n",
       "      <td>2025.122</td>\n",
       "      <td>154.6</td>\n",
       "      <td>23.3</td>\n",
       "      <td>655</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3314</th>\n",
       "      <td>2025</td>\n",
       "      <td>3</td>\n",
       "      <td>2025.204</td>\n",
       "      <td>134.2</td>\n",
       "      <td>20.4</td>\n",
       "      <td>1011</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3315 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0   1         2      3     4     5  6\n",
       "0     1749   1  1749.042   96.7  -1.0    -1  1\n",
       "1     1749   2  1749.123  104.3  -1.0    -1  1\n",
       "2     1749   3  1749.204  116.7  -1.0    -1  1\n",
       "3     1749   4  1749.288   92.8  -1.0    -1  1\n",
       "4     1749   5  1749.371  141.7  -1.0    -1  1\n",
       "...    ...  ..       ...    ...   ...   ... ..\n",
       "3310  2024  11  2024.873  152.5  20.9   681  0\n",
       "3311  2024  12  2024.958  154.5  25.6   572  0\n",
       "3312  2025   1  2025.042  137.0  23.3   670  0\n",
       "3313  2025   2  2025.122  154.6  23.3   655  0\n",
       "3314  2025   3  2025.204  134.2  20.4  1011  0\n",
       "\n",
       "[3315 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "file_path = 'dataset/SN_m_tot_V2.0.csv'\n",
    "\n",
    "df = pd.read_csv(file_path, sep=';', header = None)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f8602b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 3315\n",
      "Train size: 2000\n",
      "Test size: 1312\n"
     ]
    }
   ],
   "source": [
    "data = df.iloc[:, 3].values\n",
    "dt = 1\n",
    "dataset_size = len(data)\n",
    "data = create_delay_embedding(data, 3)\n",
    "print(f\"Dataset size: {dataset_size}\")\n",
    "\n",
    "# Train/Test Split\n",
    "train_end = 2000\n",
    "train_input  = data[:train_end]\n",
    "train_target = data[1:train_end+1]\n",
    "test_input   = data[train_end:-1]\n",
    "test_target  = data[train_end+1:]\n",
    "y_test = test_target\n",
    "n_test_steps = len(test_target)\n",
    "time_test = np.arange(n_test_steps) * dt\n",
    "\n",
    "print(f\"Train size: {len(train_input)}\\nTest size: {len(test_input)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7684b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_horizons = list(range(10, 1001, 10))\n",
    "horizons = [200, 500, 1000]\n",
    "\n",
    "nrmse_dict = defaultdict(list)\n",
    "seeds = range(995, 1025)\n",
    "\n",
    "\n",
    "for seed in seeds:\n",
    "    esn = BaselineESN3D(\n",
    "        reservoir_size=300,\n",
    "        spectral_radius=0.95,\n",
    "        connectivity=0.05,\n",
    "        input_scale=0.1,\n",
    "        leaking_rate=0.8,\n",
    "        ridge_alpha=1e-4,\n",
    "        seed=seed\n",
    "    )\n",
    "    esn.fit_readout(train_input, train_target, discard=100)\n",
    "    esn_preds = esn.predict(test_input)\n",
    "    esn_nrmse = evaluate_nrmse(esn_preds, test_target, all_horizons)\n",
    "    nrmse_dict['ESN'].append(esn_nrmse)\n",
    "\n",
    "\n",
    "for seed in seeds:\n",
    "    cycle_res = CycleReservoir3D(\n",
    "        reservoir_size=300,\n",
    "        cycle_weight = 0.8,\n",
    "        spectral_radius=0.95,\n",
    "        input_scale=0.4,\n",
    "        leaking_rate=0.8,\n",
    "        ridge_alpha=1e-4,\n",
    "        seed=seed\n",
    "    )\n",
    "    cycle_res.fit_readout(train_input, train_target, discard=100)\n",
    "    cycle_res_preds = cycle_res.predict(test_input)\n",
    "    cycle_res_nrmse = evaluate_nrmse(cycle_res_preds, test_target, all_horizons)\n",
    "    nrmse_dict['SCR'].append(cycle_res_nrmse)\n",
    "\n",
    "\n",
    "for seed in seeds:\n",
    "    crj = CRJRes3D(\n",
    "        reservoir_size=300,\n",
    "        edge_weight=0.8,\n",
    "        jump=5,\n",
    "        spectral_radius=0.95,\n",
    "        input_scale=0.4,\n",
    "        leaking_rate=0.8,\n",
    "        ridge_alpha=1e-4,\n",
    "        seed=seed\n",
    "    )\n",
    "    crj.fit_readout(train_input, train_target, discard=100)\n",
    "    crj_preds = crj.predict(test_input)\n",
    "    crj_nrmse = evaluate_nrmse(crj_preds, test_target, all_horizons)\n",
    "    nrmse_dict['CRJ'].append(crj_nrmse)\n",
    "\n",
    "\n",
    "# for seed in seeds:\n",
    "#     sw_esn = SWRes3D(\n",
    "#         reservoir_size=300,\n",
    "#         rewiring_prob=0.2,\n",
    "#         degree=6,\n",
    "#         spectral_radius=0.95,\n",
    "#         input_scale=0.3,\n",
    "#         leaking_rate=0.8,\n",
    "#         ridge_alpha=1e-4,\n",
    "#         seed=seed\n",
    "#     )\n",
    "#     sw_esn.fit_readout(train_input, train_target, discard=100)\n",
    "#     sw_esn_preds = sw_esn.predict(test_input)\n",
    "#     sw_esn_nrmse = evaluate_nrmse(sw_esn_preds, test_target, all_horizons)\n",
    "#     nrmse_dict['SW-ESN'].append(sw_esn_nrmse)\n",
    "\n",
    "\n",
    "for seed in seeds:\n",
    "    mci_esn = MCIESN3D(\n",
    "        reservoir_size=300,\n",
    "        cycle_weight=0.01,\n",
    "        connect_weight=0.1,\n",
    "        combine_factor=0.1,\n",
    "        v1=0.0003,\n",
    "        v2=0.0003,\n",
    "        spectral_radius=0.95,\n",
    "        leaking_rate=0.8,\n",
    "        ridge_alpha=1e-4,\n",
    "        seed=seed\n",
    "    )\n",
    "    mci_esn.fit_readout(train_input, train_target, discard=100)\n",
    "    mci_esn_preds = mci_esn.predict(test_input)\n",
    "    mci_esn_nrmse = evaluate_nrmse(mci_esn_preds, test_target, all_horizons)\n",
    "    nrmse_dict['MCI-ESN'].append(mci_esn_nrmse)\n",
    "\n",
    "\n",
    "for seed in seeds:\n",
    "    deepesn = DeepESN3D(\n",
    "        num_layers=3,\n",
    "        reservoir_size=100,\n",
    "        spectral_radius=0.95,\n",
    "        input_scale=0.1,\n",
    "        leaking_rate=0.6,\n",
    "        ridge_alpha=1e-4,\n",
    "        seed=seed\n",
    "    )\n",
    "    deepesn.fit_readout(train_input, train_target, discard=100)\n",
    "    deepesn_preds = deepesn.predict(test_input)\n",
    "    deepesn_nrmse = evaluate_nrmse(deepesn_preds, test_target, all_horizons)\n",
    "    nrmse_dict['DeepESN'].append(deepesn_nrmse)\n",
    "\n",
    "\n",
    "# for seed in seeds:\n",
    "#     hypER = HypER3D(\n",
    "#             reservoir_size=300,\n",
    "#             disk_radius=0.99, \n",
    "#             sigma=0.1,\n",
    "#             top_k=10,\n",
    "#             spectral_radius=0.95,\n",
    "#             input_scale=0.2,\n",
    "#             leaking_rate=0.8,\n",
    "#             ridge_alpha=1e-4,\n",
    "#             seed=seed\n",
    "#         )\n",
    "#     hypER.fit_readout(train_input, train_target, discard=100)\n",
    "#     hypER_preds = hypER.predict(test_input)\n",
    "#     hypER_nrmse = evaluate_nrmse(hypER_preds, test_target, all_horizons)\n",
    "#     nrmse_dict['HypER'].append(hypER_nrmse)\n",
    "\n",
    "for seed in seeds:\n",
    "    hfr = HFRRes3D(\n",
    "        n_levels=8,      \n",
    "        cells_per_level=[5, 10, 20, 25, 30, 35, 40, 60, 75, 90, 110],\n",
    "        spectral_radius=0.01,\n",
    "        input_scale=1.5,\n",
    "        leaking_rate=0.5,\n",
    "        ridge_alpha=1e-8,\n",
    "        seed=seed\n",
    "    )\n",
    "    hfr.fit_readout(train_input, train_target, discard=100)\n",
    "    hfr_preds = hfr.predict_open_loop(test_input)\n",
    "    hfr_nrmse = evaluate_nrmse(hfr_preds, test_target, all_horizons)\n",
    "    nrmse_dict['HFR'].append(hfr_nrmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5034e5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seaborn style\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Assuming `nrmse_dict` already exists from your evaluation loop\n",
    "# Each entry: nrmse_dict[model_name] = list of dicts like [{'1000': val}, ...]\n",
    "\n",
    "# Flatten values from each seed's output at horizon 1000\n",
    "horizon = \"1000\"\n",
    "model_names = list(nrmse_dict.keys())\n",
    "flattened_nrmse_data = {\n",
    "    model: [entry[horizon] for entry in nrmse_dict[model]]\n",
    "    for model in model_names\n",
    "}\n",
    "\n",
    "# Create boxplot\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(data=[flattened_nrmse_data[model] for model in model_names],\n",
    "            orient=\"v\", showfliers=False)\n",
    "\n",
    "plt.xticks(ticks=range(len(model_names)), labels=model_names, rotation=15)\n",
    "plt.ylabel(\"NRMSE @ Horizon = 1000\")\n",
    "plt.title(\"Model Comparison: NRMSE Distribution at Horizon 1000\")\n",
    "\n",
    "# Save high-res version\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"box_ecg_1000.png\", dpi=250)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daaef00f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NRMSE for Different Prediction Horizons:\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "Horizon    ESN               SCR               CRJ               SW-ESN            MCI-ESN           DeepESN           HypER            \n",
      "--------------------------------------------------------------------------------------------------------------------------------------------\n",
      "200        5.1681 ± 2.5483   6.0723 ± 1.1326   4.8475 ± 1.4909   4.2787 ± 1.0273   2.4635 ± 0.1145   1.3174 ± 0.1826   0.8515 ± 0.1008   \n",
      "400        5.0651 ± 1.3399   5.6918 ± 0.5887   4.2263 ± 1.2638   3.3983 ± 0.6059   2.0151 ± 0.0702   1.1023 ± 0.1138   0.6964 ± 0.0424   \n",
      "600        4.7200 ± 1.0571   6.4209 ± 1.6932   4.0023 ± 0.6231   3.3421 ± 0.6611   1.8867 ± 0.0466   1.0375 ± 0.1171   0.6130 ± 0.0343   \n",
      "800        4.1884 ± 0.9370   5.6912 ± 1.4899   3.5737 ± 0.5606   2.9863 ± 0.5822   1.9369 ± 0.0502   0.9951 ± 0.1003   0.6037 ± 0.0296   \n",
      "1000       3.9800 ± 0.8973   5.3847 ± 1.4046   3.4826 ± 0.5519   2.9242 ± 0.5561   1.9062 ± 0.0513   0.9936 ± 0.0993   0.5956 ± 0.0277   \n"
     ]
    }
   ],
   "source": [
    "print(\"\\nNRMSE for Different Prediction Horizons:\")\n",
    "print(\"-\" * 140)\n",
    "print(f\"{'Horizon':<10} {'ESN':<17} {'SCR':<17} {'CRJ':<17} {'MCI-ESN':<17} {'DeepESN':<17} {'HFR':<17}\")\n",
    "print(\"-\" * 140)\n",
    "\n",
    "\n",
    "for horizon in horizons:\n",
    "    esn_vals = [np.mean(esn_nrmse[horizon]) for esn_nrmse in nrmse_dict['ESN']]\n",
    "    scr_vals = [np.mean(cycle_res_nrmse[horizon]) for cycle_res_nrmse in nrmse_dict['SCR']]\n",
    "    crj_vals = [np.mean(crj_nrmse[horizon]) for crj_nrmse in nrmse_dict['CRJ']]\n",
    "    # sw_vals  = [np.mean(sw_esn_nrmse[horizon]) for sw_esn_nrmse in nrmse_dict['SW-ESN']]\n",
    "    mci_vals = [np.mean(mci_esn_nrmse[horizon]) for mci_esn_nrmse in nrmse_dict['MCI-ESN']]\n",
    "    deep_vals = [np.mean(deepesn_nrmse[horizon]) for deepesn_nrmse in nrmse_dict['DeepESN']]\n",
    "    # hypER_vals = [np.mean(hypER_nrmse[horizon]) for hypER_nrmse in nrmse_dict['HypER']]\n",
    "    hfr_vals = [np.mean(hfr_nrmse[horizon]) for hfr_nrmse in nrmse_dict['HFR']]\n",
    "\n",
    "    print(f\"{horizon:<10}\", end=\" \")\n",
    "    for vals in [esn_vals, scr_vals, crj_vals, mci_vals, deep_vals, hfr_vals]:\n",
    "        mean = np.mean(vals)\n",
    "        std = np.std(vals)\n",
    "        print(f\"{mean:.4f} ± {std:.4f}\".ljust(18), end=\"\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e6ee32",
   "metadata": {},
   "source": [
    "# Sante Fe Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2407cfd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = 'dataset/santa-fe-time-series/b1.txt'\n",
    "\n",
    "df = pd.read_csv(file_path, header=None, sep=' ')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5624624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the first column (column 0) of the DataFrame\n",
    "df[0] = (df[0] - df[0].min()) / (df[0].max() - df[0].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5bf803",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.iloc[:7503, 0].values\n",
    "chosen_system = \"SantaFe\"\n",
    "dt = 1\n",
    "T_data = len(data)\n",
    "data = create_delay_embedding(data, 3)\n",
    "print(f\"Data length: {T_data}.\")\n",
    "\n",
    "# Train/Test Split\n",
    "train_end = 4500\n",
    "train_input  = data[:train_end]\n",
    "train_target = data[1:train_end+1]\n",
    "test_input   = data[train_end:-1]\n",
    "test_target  = data[train_end+1:]\n",
    "y_test = test_target\n",
    "n_test_steps = len(test_target)\n",
    "time_test = np.arange(n_test_steps) * dt\n",
    "\n",
    "print(f\"Train size: {len(train_input)}  \\nTest size: {len(test_input)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5900d956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_horizons = list(range(10, 1001, 10))\n",
    "horizons = [200, 500, 1000]\n",
    "\n",
    "nrmse_dict = defaultdict(list)\n",
    "seeds = range(995, 1025)\n",
    "\n",
    "for seed in seeds:\n",
    "    esn = BaselineESN3D(\n",
    "        reservoir_size=300,\n",
    "        spectral_radius=0.95,\n",
    "        connectivity=0.05,\n",
    "        input_scale=0.1,\n",
    "        leaking_rate=0.8,\n",
    "        ridge_alpha=1e-4,\n",
    "        seed=seed\n",
    "    )\n",
    "    esn.fit_readout(train_input, train_target, discard=100)\n",
    "    esn_preds = esn.predict(test_input)\n",
    "    esn_nrmse = evaluate_nrmse(esn_preds, test_target, all_horizons)\n",
    "    nrmse_dict['ESN'].append(esn_nrmse)\n",
    "\n",
    "\n",
    "for seed in seeds:\n",
    "    cycle_res = CycleReservoir3D(\n",
    "        reservoir_size=300,\n",
    "        cycle_weight = 0.8,\n",
    "        spectral_radius=0.99,\n",
    "        input_scale=0.4,\n",
    "        leaking_rate=0.8,\n",
    "        ridge_alpha=1e-4,\n",
    "        seed=seed\n",
    "    )\n",
    "    cycle_res.fit_readout(train_input, train_target, discard=100)\n",
    "    cycle_res_preds = cycle_res.predict(test_input)\n",
    "    cycle_res_nrmse = evaluate_nrmse(cycle_res_preds, test_target, all_horizons)\n",
    "    nrmse_dict['SCR'].append(cycle_res_nrmse)\n",
    "\n",
    "\n",
    "for seed in seeds:\n",
    "    crj = CRJRes3D(\n",
    "        reservoir_size=300,\n",
    "        edge_weight=0.8,\n",
    "        jump=5,\n",
    "        spectral_radius=0.95,\n",
    "        input_scale=0.4,\n",
    "        leaking_rate=0.8,\n",
    "        ridge_alpha=1e-4,\n",
    "        seed=seed\n",
    "    )\n",
    "    crj.fit_readout(train_input, train_target, discard=100)\n",
    "    crj_preds = crj.predict(test_input)\n",
    "    crj_nrmse = evaluate_nrmse(crj_preds, test_target, all_horizons)\n",
    "    nrmse_dict['CRJ'].append(crj_nrmse)\n",
    "\n",
    "\n",
    "for seed in seeds:\n",
    "    sw_esn = SWRes3D(\n",
    "        reservoir_size=300,\n",
    "        rewiring_prob=0.2,\n",
    "        degree=6,\n",
    "        spectral_radius=0.95,\n",
    "        input_scale=0.3,\n",
    "        leaking_rate=0.8,\n",
    "        ridge_alpha=1e-4,\n",
    "        seed=seed\n",
    "    )\n",
    "    sw_esn.fit_readout(train_input, train_target, discard=100)\n",
    "    sw_esn_preds = sw_esn.predict(test_input)\n",
    "    sw_esn_nrmse = evaluate_nrmse(sw_esn_preds, test_target, all_horizons)\n",
    "    nrmse_dict['SW-ESN'].append(sw_esn_nrmse)\n",
    "\n",
    "\n",
    "for seed in seeds:\n",
    "    mci_esn = MCIESN3D(\n",
    "        reservoir_size=300,\n",
    "        cycle_weight=0.01,\n",
    "        connect_weight=0.1,\n",
    "        combine_factor=0.1,\n",
    "        v1=0.003,\n",
    "        v2=0.003,\n",
    "        spectral_radius=0.95,\n",
    "        leaking_rate=0.8,\n",
    "        ridge_alpha=1e-4,\n",
    "        seed=seed\n",
    "    )\n",
    "    mci_esn.fit_readout(train_input, train_target, discard=100)\n",
    "    mci_esn_preds = mci_esn.predict(test_input)\n",
    "    mci_esn_nrmse = evaluate_nrmse(mci_esn_preds, test_target, all_horizons)\n",
    "    nrmse_dict['MCI-ESN'].append(mci_esn_nrmse)\n",
    "\n",
    "\n",
    "for seed in seeds:\n",
    "    deepesn = DeepESN3D(\n",
    "        num_layers=3,\n",
    "        reservoir_size=100,\n",
    "        spectral_radius=0.85,\n",
    "        input_scale=0.2,\n",
    "        leaking_rate=0.9,\n",
    "        ridge_alpha=1e-4,\n",
    "        seed=seed\n",
    "    )\n",
    "    deepesn.fit_readout(train_input, train_target, discard=100)\n",
    "    deepesn_preds = deepesn.predict(test_input)\n",
    "    deepesn_nrmse = evaluate_nrmse(deepesn_preds, test_target, all_horizons)\n",
    "    nrmse_dict['DeepESN'].append(deepesn_nrmse)\n",
    "\n",
    "\n",
    "for seed in seeds:\n",
    "    hypER = HypER3D(\n",
    "            reservoir_size=300,\n",
    "            disk_radius=0.99, \n",
    "            sigma=0.1,\n",
    "            top_k=15,\n",
    "            spectral_radius=0.95,\n",
    "            input_scale=0.2,\n",
    "            leaking_rate=0.8,\n",
    "            ridge_alpha=1e-6,\n",
    "            seed=seed\n",
    "        )\n",
    "    hypER.fit_readout(train_input, train_target, discard=100)\n",
    "    hypER_preds = hypER.predict(test_input)\n",
    "    hypER_nrmse = evaluate_nrmse(hypER_preds, test_target, all_horizons)\n",
    "    nrmse_dict['HypER'].append(hypER_nrmse)\n",
    "\n",
    "for seed in seeds:\n",
    "    hfr = HFRRes3D(\n",
    "        n_levels=8,      \n",
    "        cells_per_level=[5, 10, 20, 25, 30, 35, 40, 60, 75, 90, 110],\n",
    "        spectral_radius=0.01,\n",
    "        input_scale=1.5,\n",
    "        leaking_rate=0.5,\n",
    "        ridge_alpha=1e-8,\n",
    "        seed=seed\n",
    "    )\n",
    "    hfr.fit_readout(train_input, train_target, discard=5000)\n",
    "    hfr_preds = hfr.predict_open_loop(test_input)\n",
    "    hfr_nrmse = evaluate_nrmse(hfr_preds, test_target, all_horizons)\n",
    "    nrmse_dict['HFR'].append(hfr_nrmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5ee9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seaborn style\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Assuming `nrmse_dict` already exists from your evaluation loop\n",
    "# Each entry: nrmse_dict[model_name] = list of dicts like [{'1000': val}, ...]\n",
    "\n",
    "# Flatten values from each seed's output at horizon 1000\n",
    "horizon = \"1000\"\n",
    "model_names = list(nrmse_dict.keys())\n",
    "flattened_nrmse_data = {\n",
    "    model: [entry[horizon] for entry in nrmse_dict[model]]\n",
    "    for model in model_names\n",
    "}\n",
    "\n",
    "# Create boxplot\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(data=[flattened_nrmse_data[model] for model in model_names],\n",
    "            orient=\"v\", showfliers=False)\n",
    "\n",
    "plt.xticks(ticks=range(len(model_names)), labels=model_names, rotation=15)\n",
    "plt.ylabel(\"NRMSE @ Horizon = 1000\")\n",
    "plt.title(\"Model Comparison: NRMSE Distribution at Horizon 1000\")\n",
    "\n",
    "# Save high-res version\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"box_ecg_1000.png\", dpi=250)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a243d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nNRMSE for Different Prediction Horizons:\")\n",
    "print(\"-\" * 140)\n",
    "print(f\"{'Horizon':<10} {'ESN':<17} {'SCR':<17} {'CRJ':<17} {'SW-ESN':<17} {'MCI-ESN':<17} {'DeepESN':<17} {'HypER':<17}\")\n",
    "print(\"-\" * 140)\n",
    "\n",
    "\n",
    "for horizon in horizons:\n",
    "    esn_vals = [np.mean(esn_nrmse[horizon]) for esn_nrmse in nrmse_dict['ESN']]\n",
    "    scr_vals = [np.mean(cycle_res_nrmse[horizon]) for cycle_res_nrmse in nrmse_dict['SCR']]\n",
    "    crj_vals = [np.mean(crj_nrmse[horizon]) for crj_nrmse in nrmse_dict['CRJ']]\n",
    "    sw_vals  = [np.mean(sw_esn_nrmse[horizon]) for sw_esn_nrmse in nrmse_dict['SW-ESN']]\n",
    "    mci_vals = [np.mean(mci_esn_nrmse[horizon]) for mci_esn_nrmse in nrmse_dict['MCI-ESN']]\n",
    "    deep_vals = [np.mean(deepesn_nrmse[horizon]) for deepesn_nrmse in nrmse_dict['DeepESN']]\n",
    "    hypER_vals = [np.mean(hypER_nrmse[horizon]) for hypER_nrmse in nrmse_dict['HypER']]\n",
    "\n",
    "    print(f\"{horizon:<10}\", end=\" \")\n",
    "    for vals in [esn_vals, scr_vals, crj_vals, sw_vals, mci_vals, deep_vals, hypER_vals]:\n",
    "        mean = np.mean(vals)\n",
    "        std = np.std(vals)\n",
    "        print(f\"{mean:.4f} ± {std:.4f}\".ljust(18), end=\"\")\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
